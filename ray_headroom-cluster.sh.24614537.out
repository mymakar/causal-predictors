â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     tableshift              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator         â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler â”‚
â”‚ Number of trials                 50                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/rjsingh/ray_results/tableshift
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-04-25_15-30-00_555465_3211563/artifacts/2025-04-25_15-30-19/tableshift/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-04-25 15:30:20. Total running time: 0s
Logical resource usage: 0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   PENDING               0.000164587                        8                  31.1567             0.795395                    6                  0.72302                 0.925513               11.443             0.0032299 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8b81c0c2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8b81c0c2 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.925513 â”‚
â”‚ params/colsample_bytree                       0.72302 â”‚
â”‚ params/learning_rate                      0.000164587 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                       31.1567 â”‚
â”‚ params/reg_alpha                               11.443 â”‚
â”‚ params/reg_lambda                           0.0032299 â”‚
â”‚ params/subsample                             0.795395 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8a157d87 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a157d87 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.91828 â”‚
â”‚ params/colsample_bytree                      0.963194 â”‚
â”‚ params/learning_rate                      0.000121064 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       88.6536 â”‚
â”‚ params/reg_alpha                          3.15908e-05 â”‚
â”‚ params/reg_lambda                          1.9731e-05 â”‚
â”‚ params/subsample                             0.995723 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 2 RUNNING
Current time: 2025-04-25 15:30:50. Total running time: 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING
Current time: 2025-04-25 15:31:20. Total running time: 1min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING
Current time: 2025-04-25 15:31:50. Total running time: 1min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING
Current time: 2025-04-25 15:32:20. Total running time: 2min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING
Current time: 2025-04-25 15:32:50. Total running time: 2min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING
Current time: 2025-04-25 15:33:20. Total running time: 3min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045404 seconds.
[36m(RayTrainWorker pid=3214731)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3214731)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 21x across cluster][0m
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 21x across cluster][0m
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042604 seconds.
[36m(RayTrainWorker pid=3215811)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3215811)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3214731)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 2 RUNNING
Current time: 2025-04-25 15:33:50. Total running time: 3min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   RUNNING               0.000164587                        8                  31.1567             0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299         2            204.063               0.401213      0.698438                 0.58886                  0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   RUNNING               0.000121064                        4                  88.6536             0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05        1            198.616               0.401213      0.691923                 0.578257                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8b81c0c2 completed after 10 iterations at 2025-04-25 15:33:55. Total running time: 3min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8b81c0c2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                      0.504 â”‚
â”‚ time_total_s                                      207.81526 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_fc51d1bb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fc51d1bb config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.995475 â”‚
â”‚ params/colsample_bytree                      0.890752 â”‚
â”‚ params/learning_rate                         0.285296 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    1.5737e-05 â”‚
â”‚ params/reg_alpha                          0.000468379 â”‚
â”‚ params/reg_lambda                             2.79121 â”‚
â”‚ params/subsample                             0.799768 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8a157d87 completed after 10 iterations at 2025-04-25 15:33:56. Total running time: 3min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a157d87 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46907 â”‚
â”‚ time_total_s                                      202.89273 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3b27c720 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b27c720 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.903575 â”‚
â”‚ params/colsample_bytree                      0.841159 â”‚
â”‚ params/learning_rate                      0.000988995 â”‚
â”‚ params/max_depth                                    5 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                    0.00324906 â”‚
â”‚ params/reg_alpha                           5.8573e-05 â”‚
â”‚ params/reg_lambda                         0.000552809 â”‚
â”‚ params/subsample                             0.652433 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3215811)[0m [LightGBM] [Info] Start training from score -0.400412

Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:34:20. Total running time: 4min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:34:50. Total running time: 4min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:35:20. Total running time: 5min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:35:50. Total running time: 5min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:36:20. Total running time: 6min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043290 seconds.
[36m(RayTrainWorker pid=3230002)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3230002)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 2 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:36:50. Total running time: 6min 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fc51d1bb   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_3b27c720   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3230002)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046311 seconds.
[36m(RayTrainWorker pid=3229644)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3229644)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] Total Bins 368
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 8x across cluster][0m

Trial LightGBMTrainer_3b27c720 completed after 10 iterations at 2025-04-25 15:36:58. Total running time: 6min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b27c720 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46899 â”‚
â”‚ time_total_s                                       180.1331 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bd7233de started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd7233de config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.815193 â”‚
â”‚ params/colsample_bytree                    0.657187 â”‚
â”‚ params/learning_rate                      0.0415284 â”‚
â”‚ params/max_depth                                 17 â”‚
â”‚ params/min_child_samples                         32 â”‚
â”‚ params/min_child_weight                     5054.73 â”‚
â”‚ params/reg_alpha                            22.4911 â”‚
â”‚ params/reg_lambda                           3.52364 â”‚
â”‚ params/subsample                           0.570107 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=3229644)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m

Trial LightGBMTrainer_fc51d1bb completed after 10 iterations at 2025-04-25 15:37:13. Total running time: 6min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fc51d1bb result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    1.69851 â”‚
â”‚ time_total_s                                      195.58754 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ddfaed8a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ddfaed8a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.998595 â”‚
â”‚ params/colsample_bytree                      0.846572 â”‚
â”‚ params/learning_rate                      0.000408737 â”‚
â”‚ params/max_depth                                   16 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0240841 â”‚
â”‚ params/reg_alpha                          7.19007e-06 â”‚
â”‚ params/reg_lambda                         2.22449e-06 â”‚
â”‚ params/subsample                             0.902369 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:37:20. Total running time: 7min 0s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:37:51. Total running time: 7min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:38:21. Total running time: 8min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:38:51. Total running time: 8min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:39:21. Total running time: 9min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043239 seconds.
[36m(RayTrainWorker pid=3234599)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3234599)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3234599)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 4 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:39:51. Total running time: 9min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd7233de   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_ddfaed8a   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043101 seconds.
[36m(RayTrainWorker pid=3235810)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3235810)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_bd7233de completed after 10 iterations at 2025-04-25 15:39:56. Total running time: 9min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd7233de result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46118 â”‚
â”‚ time_total_s                                      177.01074 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_1a0be928 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1a0be928 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.667537 â”‚
â”‚ params/colsample_bytree                      0.541613 â”‚
â”‚ params/learning_rate                      0.000722629 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                     0.0899496 â”‚
â”‚ params/reg_alpha                          3.73583e-05 â”‚
â”‚ params/reg_lambda                         1.60174e-05 â”‚
â”‚ params/subsample                             0.997766 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ddfaed8a completed after 10 iterations at 2025-04-25 15:40:02. Total running time: 9min 42s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ddfaed8a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.60177 â”‚
â”‚ time_total_s                                      167.71297 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ef5c58d4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ef5c58d4 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.760773 â”‚
â”‚ params/colsample_bytree                     0.771388 â”‚
â”‚ params/learning_rate                        0.173267 â”‚
â”‚ params/max_depth                                   7 â”‚
â”‚ params/min_child_samples                           1 â”‚
â”‚ params/min_child_weight                   0.00108024 â”‚
â”‚ params/reg_alpha                             6.15976 â”‚
â”‚ params/reg_lambda                            3.35489 â”‚
â”‚ params/subsample                            0.618161 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=3235810)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:40:21. Total running time: 10min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:40:51. Total running time: 10min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:41:21. Total running time: 11min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:41:51. Total running time: 11min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:42:21. Total running time: 12min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043313 seconds.
[36m(RayTrainWorker pid=3245126)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3245126)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3245126)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 6 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:42:51. Total running time: 12min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1a0be928   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        6            173.166               0.401213      0.702113                 0.593972                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_1a0be928 completed after 10 iterations at 2025-04-25 15:42:58. Total running time: 12min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1a0be928 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45553 â”‚
â”‚ time_total_s                                      179.52464 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_17d4b55e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_17d4b55e config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.646288 â”‚
â”‚ params/colsample_bytree                      0.967027 â”‚
â”‚ params/learning_rate                         0.659853 â”‚
â”‚ params/max_depth                                   12 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000106202 â”‚
â”‚ params/reg_alpha                             0.558068 â”‚
â”‚ params/reg_lambda                         8.42149e-07 â”‚
â”‚ params/subsample                             0.696157 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 7 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:43:21. Total running time: 13min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ef5c58d4   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046428 seconds.
[36m(RayTrainWorker pid=3245208)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3245208)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3245208)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_ef5c58d4 completed after 10 iterations at 2025-04-25 15:43:39. Total running time: 13min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ef5c58d4 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    1.00316 â”‚
â”‚ time_total_s                                      214.68239 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3fef2789 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3fef2789 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.935438 â”‚
â”‚ params/colsample_bytree                      0.984963 â”‚
â”‚ params/learning_rate                         0.620081 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                   2.24559e-06 â”‚
â”‚ params/reg_alpha                          3.40549e-08 â”‚
â”‚ params/reg_lambda                          2.1901e-06 â”‚
â”‚ params/subsample                             0.611725 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 8 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:43:51. Total running time: 13min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:44:21. Total running time: 14min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:44:51. Total running time: 14min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:45:21. Total running time: 15min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042748 seconds.
[36m(RayTrainWorker pid=3248345)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3248345)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3248345)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 8 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:45:51. Total running time: 15min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_17d4b55e   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_17d4b55e completed after 10 iterations at 2025-04-25 15:45:52. Total running time: 15min 32s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_17d4b55e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46119 â”‚
â”‚ time_total_s                                      173.28729 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_86413810 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_86413810 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.768668 â”‚
â”‚ params/colsample_bytree                      0.553555 â”‚
â”‚ params/learning_rate                        0.0126689 â”‚
â”‚ params/max_depth                                   17 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   6.10817e-06 â”‚
â”‚ params/reg_alpha                          4.03624e-07 â”‚
â”‚ params/reg_lambda                         5.15125e-07 â”‚
â”‚ params/subsample                             0.643136 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 9 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:46:21. Total running time: 16min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3fef2789   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_86413810   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046628 seconds.
[36m(RayTrainWorker pid=3250201)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3250201)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3250201)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_3fef2789 completed after 10 iterations at 2025-04-25 15:46:41. Total running time: 16min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3fef2789 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.58813 â”‚
â”‚ time_total_s                                      180.47527 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5b1f3996 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5b1f3996 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.596556 â”‚
â”‚ params/colsample_bytree                      0.729611 â”‚
â”‚ params/learning_rate                      0.000556346 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   5.41365e-06 â”‚
â”‚ params/reg_alpha                          5.19352e-06 â”‚
â”‚ params/reg_lambda                         1.21963e-08 â”‚
â”‚ params/subsample                              0.74617 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 10 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:46:51. Total running time: 16min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_86413810   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:47:21. Total running time: 17min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_86413810   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:47:51. Total running time: 17min 31s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_86413810   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:48:21. Total running time: 18min 1s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_86413810   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044378 seconds.
[36m(RayTrainWorker pid=3260628)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3260628)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3260628)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_86413810 completed after 10 iterations at 2025-04-25 15:48:46. Total running time: 18min 26s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_86413810 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46855 â”‚
â”‚ time_total_s                                      171.46704 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_22460414 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_22460414 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.811766 â”‚
â”‚ params/colsample_bytree                    0.983905 â”‚
â”‚ params/learning_rate                      0.0355334 â”‚
â”‚ params/max_depth                                  7 â”‚
â”‚ params/min_child_samples                          8 â”‚
â”‚ params/min_child_weight                     41339.5 â”‚
â”‚ params/reg_alpha                          0.0912562 â”‚
â”‚ params/reg_lambda                         0.0032698 â”‚
â”‚ params/subsample                           0.627821 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 11 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:48:52. Total running time: 18min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 11 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:49:22. Total running time: 19min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5b1f3996   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121392 seconds.
[36m(RayTrainWorker pid=3262162)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3262162)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3262162)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_5b1f3996 completed after 10 iterations at 2025-04-25 15:49:41. Total running time: 19min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5b1f3996 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50493 â”‚
â”‚ time_total_s                                      178.20138 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_489a88af started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_489a88af config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.722537 â”‚
â”‚ params/colsample_bytree                      0.551055 â”‚
â”‚ params/learning_rate                        0.0466036 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                         41181 â”‚
â”‚ params/reg_alpha                          0.000152476 â”‚
â”‚ params/reg_lambda                            0.527264 â”‚
â”‚ params/subsample                             0.517158 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 12 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:49:52. Total running time: 19min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:50:22. Total running time: 20min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:50:52. Total running time: 20min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:51:22. Total running time: 21min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_22460414   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.199632 seconds.
[36m(RayTrainWorker pid=3267362)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3267362)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3267362)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_22460414 completed after 10 iterations at 2025-04-25 15:51:48. Total running time: 21min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_22460414 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.47886 â”‚
â”‚ time_total_s                                      181.06096 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_26857256 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_26857256 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.53918 â”‚
â”‚ params/colsample_bytree                      0.705943 â”‚
â”‚ params/learning_rate                       0.00106088 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                     0.0172776 â”‚
â”‚ params/reg_alpha                          3.50454e-06 â”‚
â”‚ params/reg_lambda                         0.000103861 â”‚
â”‚ params/subsample                             0.741189 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 13 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:51:52. Total running time: 21min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 13 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:52:22. Total running time: 22min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_489a88af   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043141 seconds.
[36m(RayTrainWorker pid=3273981)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3273981)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3273981)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_489a88af completed after 10 iterations at 2025-04-25 15:52:39. Total running time: 22min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_489a88af result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.52523 â”‚
â”‚ time_total_s                                      176.00063 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_031c3829 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_031c3829 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.803075 â”‚
â”‚ params/colsample_bytree                       0.71708 â”‚
â”‚ params/learning_rate                      0.000306402 â”‚
â”‚ params/max_depth                                   14 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0131405 â”‚
â”‚ params/reg_alpha                           0.00116657 â”‚
â”‚ params/reg_lambda                         1.41736e-07 â”‚
â”‚ params/subsample                             0.703283 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 14 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:52:52. Total running time: 22min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 14 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:53:22. Total running time: 23min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 14 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:53:52. Total running time: 23min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 14 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:54:22. Total running time: 24min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044120 seconds.
[36m(RayTrainWorker pid=3275944)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3275944)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3275944)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 14 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:54:52. Total running time: 24min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26857256   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            183.55                0.401213      0.700944                 0.589393                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_26857256 completed after 10 iterations at 2025-04-25 15:54:56. Total running time: 24min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_26857256 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46963 â”‚
â”‚ time_total_s                                      186.44053 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b3369e05 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b3369e05 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.703184 â”‚
â”‚ params/colsample_bytree                      0.687447 â”‚
â”‚ params/learning_rate                         0.038339 â”‚
â”‚ params/max_depth                                   21 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                        197.21 â”‚
â”‚ params/reg_alpha                          8.53002e-06 â”‚
â”‚ params/reg_lambda                         3.04949e-08 â”‚
â”‚ params/subsample                             0.993056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 15 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:55:22. Total running time: 25min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_031c3829   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043045 seconds.
[36m(RayTrainWorker pid=3277522)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3277522)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3277522)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_031c3829 completed after 10 iterations at 2025-04-25 15:55:46. Total running time: 25min 26s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_031c3829 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.5048 â”‚
â”‚ time_total_s                                      185.31771 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_9c447241 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_9c447241 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.604319 â”‚
â”‚ params/colsample_bytree                      0.621564 â”‚
â”‚ params/learning_rate                      2.58761e-05 â”‚
â”‚ params/max_depth                                   24 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.22199e-08 â”‚
â”‚ params/reg_alpha                          1.17838e-06 â”‚
â”‚ params/reg_lambda                          0.00859442 â”‚
â”‚ params/subsample                             0.953705 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 16 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:55:52. Total running time: 25min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:56:22. Total running time: 26min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:56:52. Total running time: 26min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:57:22. Total running time: 27min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043479 seconds.
[36m(RayTrainWorker pid=3288295)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3288295)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3288295)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 16 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:57:52. Total running time: 27min 32s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b3369e05   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08        3            175.424               0.401213      0.700342                 0.588848                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b3369e05 completed after 10 iterations at 2025-04-25 15:57:57. Total running time: 27min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b3369e05 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.59152 â”‚
â”‚ time_total_s                                       178.7545 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_65f0175b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_65f0175b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.637239 â”‚
â”‚ params/colsample_bytree                      0.691992 â”‚
â”‚ params/learning_rate                      0.000406627 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                      0.223195 â”‚
â”‚ params/reg_alpha                            0.0096948 â”‚
â”‚ params/reg_lambda                         2.09777e-08 â”‚
â”‚ params/subsample                             0.621653 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 17 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:58:23. Total running time: 28min 2s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_9c447241   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205448 seconds.
[36m(RayTrainWorker pid=3289629)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3289629)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3289629)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_9c447241 completed after 10 iterations at 2025-04-25 15:58:47. Total running time: 28min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_9c447241 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.5133 â”‚
â”‚ time_total_s                                      179.59693 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6222560e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6222560e config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.733572 â”‚
â”‚ params/colsample_bytree                      0.819417 â”‚
â”‚ params/learning_rate                       5.2365e-05 â”‚
â”‚ params/max_depth                                   13 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.97276e-08 â”‚
â”‚ params/reg_alpha                          4.79278e-07 â”‚
â”‚ params/reg_lambda                             1.41961 â”‚
â”‚ params/subsample                             0.882547 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 18 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:58:53. Total running time: 28min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 18 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:59:23. Total running time: 29min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 18 TERMINATED | 2 RUNNING
Current time: 2025-04-25 15:59:53. Total running time: 29min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 18 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:00:23. Total running time: 30min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044103 seconds.
[36m(RayTrainWorker pid=3291446)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3291446)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 18 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:00:53. Total running time: 30min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_65f0175b   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3291446)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_65f0175b completed after 10 iterations at 2025-04-25 16:01:03. Total running time: 30min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_65f0175b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45947 â”‚
â”‚ time_total_s                                      183.91735 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_32c608b6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_32c608b6 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.893064 â”‚
â”‚ params/colsample_bytree                      0.921792 â”‚
â”‚ params/learning_rate                      1.08027e-05 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       7.43684 â”‚
â”‚ params/reg_alpha                            1.811e-08 â”‚
â”‚ params/reg_lambda                           0.0916407 â”‚
â”‚ params/subsample                             0.837436 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 19 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:01:23. Total running time: 31min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6222560e   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4              7.43684                 0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
14 more TERMINATED
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051475 seconds.
[36m(RayTrainWorker pid=3296435)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3296435)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3296435)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_6222560e completed after 10 iterations at 2025-04-25 16:01:42. Total running time: 31min 22s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6222560e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50274 â”‚
â”‚ time_total_s                                      173.33694 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_2c7400dc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2c7400dc config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.946168 â”‚
â”‚ params/colsample_bytree                      0.783473 â”‚
â”‚ params/learning_rate                      9.80991e-05 â”‚
â”‚ params/max_depth                                    4 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       11.0146 â”‚
â”‚ params/reg_alpha                           0.00771771 â”‚
â”‚ params/reg_lambda                             44.9291 â”‚
â”‚ params/subsample                              0.93083 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 20 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:01:53. Total running time: 31min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4               7.43684                0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:02:23. Total running time: 32min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4               7.43684                0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:02:53. Total running time: 32min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4               7.43684                0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:03:23. Total running time: 33min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4               7.43684                0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:03:53. Total running time: 33min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_32c608b6   RUNNING                 1.08027e-05                        4               7.43684                0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407                                                                                                                      â”‚
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043247 seconds.
[36m(RayTrainWorker pid=3303254)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3303254)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3303254)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_32c608b6 completed after 10 iterations at 2025-04-25 16:04:16. Total running time: 33min 56s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_32c608b6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45393 â”‚
â”‚ time_total_s                                       191.3693 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_301b2b78 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_301b2b78 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.868694 â”‚
â”‚ params/colsample_bytree                      0.612485 â”‚
â”‚ params/learning_rate                       0.00275329 â”‚
â”‚ params/max_depth                                   18 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       473.221 â”‚
â”‚ params/reg_alpha                              1.32289 â”‚
â”‚ params/reg_lambda                         5.07964e-05 â”‚
â”‚ params/subsample                             0.829227 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 21 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:04:23. Total running time: 34min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2c7400dc   RUNNING                 9.80991e-05                        4              11.0146                 0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291                                                                                                                         â”‚
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
16 more TERMINATED
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080503 seconds.
[36m(RayTrainWorker pid=3304599)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3304599)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_2c7400dc completed after 10 iterations at 2025-04-25 16:04:47. Total running time: 34min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2c7400dc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.52233 â”‚
â”‚ time_total_s                                       183.2686 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3b699802 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b699802 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.956108 â”‚
â”‚ params/colsample_bytree                      0.915119 â”‚
â”‚ params/learning_rate                      0.000113117 â”‚
â”‚ params/max_depth                                   15 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                       4.34465 â”‚
â”‚ params/reg_alpha                           0.00642446 â”‚
â”‚ params/reg_lambda                           0.0308342 â”‚
â”‚ params/subsample                             0.787782 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 22 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:04:53. Total running time: 34min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
Trial status: 22 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:05:23. Total running time: 35min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
Trial status: 22 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:05:53. Total running time: 35min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
Trial status: 22 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:06:23. Total running time: 36min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
Trial status: 22 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:06:53. Total running time: 36min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_301b2b78   RUNNING                 0.00275329                         4             473.221                  0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043225 seconds.
[36m(RayTrainWorker pid=3314157)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3314157)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3314157)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_301b2b78 completed after 10 iterations at 2025-04-25 16:07:19. Total running time: 36min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_301b2b78 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50849 â”‚
â”‚ time_total_s                                      181.91454 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d7cf3973 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d7cf3973 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.859736 â”‚
â”‚ params/colsample_bytree                      0.806699 â”‚
â”‚ params/learning_rate                        2.416e-05 â”‚
â”‚ params/max_depth                                   -1 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                       198.491 â”‚
â”‚ params/reg_alpha                               90.627 â”‚
â”‚ params/reg_lambda                         0.000373607 â”‚
â”‚ params/subsample                             0.866313 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 23 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:07:23. Total running time: 37min 3s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075612 seconds.
[36m(RayTrainWorker pid=3316080)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3316080)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 23 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:07:53. Total running time: 37min 33s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3b699802   RUNNING                 0.000113117                        8               4.34465                0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342          5            185.935               0.401213      0.701193                 0.594433                 0.522494 â”‚
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED

Trial LightGBMTrainer_3b699802 completed after 10 iterations at 2025-04-25 16:08:00. Total running time: 37min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b699802 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.55278 â”‚
â”‚ time_total_s                                      191.70698 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d94608c9 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d94608c9 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.970751 â”‚
â”‚ params/colsample_bytree                       0.75575 â”‚
â”‚ params/learning_rate                      0.000139049 â”‚
â”‚ params/max_depth                                   20 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       2248.57 â”‚
â”‚ params/reg_alpha                            0.0454263 â”‚
â”‚ params/reg_lambda                         9.12876e-06 â”‚
â”‚ params/subsample                             0.502257 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 24 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:08:24. Total running time: 38min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:08:54. Total running time: 38min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:09:24. Total running time: 39min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:09:54. Total running time: 39min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7cf3973   RUNNING                 2.416e-05                         32             198.491                  0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607                                                                                                                    â”‚
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043234 seconds.
[36m(RayTrainWorker pid=3321831)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3321831)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3321831)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d7cf3973 completed after 10 iterations at 2025-04-25 16:10:15. Total running time: 39min 55s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d7cf3973 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.4786 â”‚
â”‚ time_total_s                                      174.04797 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5ac96151 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5ac96151 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.840217 â”‚
â”‚ params/colsample_bytree                      0.620445 â”‚
â”‚ params/learning_rate                      1.00054e-05 â”‚
â”‚ params/max_depth                                    1 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                      0.878472 â”‚
â”‚ params/reg_alpha                           0.00104969 â”‚
â”‚ params/reg_lambda                          0.00322462 â”‚
â”‚ params/subsample                             0.956884 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 25 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:10:24. Total running time: 40min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
20 more TERMINATED
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043557 seconds.
[36m(RayTrainWorker pid=3323201)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3323201)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 25 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:10:54. Total running time: 40min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d94608c9   RUNNING                 0.000139049                        4            2248.57                   0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
20 more TERMINATED
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3323201)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d94608c9 completed after 10 iterations at 2025-04-25 16:11:10. Total running time: 40min 50s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d94608c9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.55902 â”‚
â”‚ time_total_s                                      188.17522 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_189af84a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_189af84a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.909213 â”‚
â”‚ params/colsample_bytree                      0.870271 â”‚
â”‚ params/learning_rate                       0.00308779 â”‚
â”‚ params/max_depth                                   23 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                       30.6802 â”‚
â”‚ params/reg_alpha                             0.128728 â”‚
â”‚ params/reg_lambda                         0.000137752 â”‚
â”‚ params/subsample                             0.787888 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 26 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:11:24. Total running time: 41min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
21 more TERMINATED
Trial status: 26 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:11:54. Total running time: 41min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
21 more TERMINATED
Trial status: 26 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:12:24. Total running time: 42min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
21 more TERMINATED
Trial status: 26 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:12:54. Total running time: 42min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ac96151   RUNNING                 1.00054e-05                        4               0.878472               0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462                                                                                                                     â”‚
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
21 more TERMINATED
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052558 seconds.
[36m(RayTrainWorker pid=3332781)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3332781)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3332781)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_5ac96151 completed after 10 iterations at 2025-04-25 16:13:19. Total running time: 42min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5ac96151 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.4522 â”‚
â”‚ time_total_s                                      181.79647 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70494 â”‚
â”‚ id_test-average_precision                           0.59906 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70573 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68892 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68892 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67679 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66486 â”‚
â”‚ ood_test_3-average_precision                        0.77783 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70114 â”‚
â”‚ validation-average_precision                        0.59528 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_574995bd started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_574995bd config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.998232 â”‚
â”‚ params/colsample_bytree                       0.94091 â”‚
â”‚ params/learning_rate                       0.00839989 â”‚
â”‚ params/max_depth                                   28 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                      0.709055 â”‚
â”‚ params/reg_alpha                          7.64164e-08 â”‚
â”‚ params/reg_lambda                           0.0597149 â”‚
â”‚ params/subsample                              0.83532 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 27 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:13:24. Total running time: 43min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
Trial status: 27 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:13:54. Total running time: 43min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752                                                                                                                    â”‚
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042837 seconds.
[36m(RayTrainWorker pid=3334176)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3334176)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3334176)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 27 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:14:24. Total running time: 44min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_189af84a   RUNNING                 0.00308779                         8              30.6802                 0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752        8            193.081               0.401213      0.701749                 0.59495                  0.522494 â”‚
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED

Trial LightGBMTrainer_189af84a completed after 10 iterations at 2025-04-25 16:14:28. Total running time: 44min 8s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_189af84a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.5011 â”‚
â”‚ time_total_s                                       196.3653 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_877005e3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_877005e3 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.968986 â”‚
â”‚ params/colsample_bytree                      0.886995 â”‚
â”‚ params/learning_rate                        3.897e-05 â”‚
â”‚ params/max_depth                                   30 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                       6376.65 â”‚
â”‚ params/reg_alpha                          0.000177373 â”‚
â”‚ params/reg_lambda                         1.29028e-05 â”‚
â”‚ params/subsample                              0.55223 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 28 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:14:54. Total running time: 44min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
Trial status: 28 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:15:24. Total running time: 45min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
Trial status: 28 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:15:54. Total running time: 45min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_574995bd   RUNNING                 0.00839989                         8               0.709055               0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149                                                                                                                      â”‚
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043561 seconds.
[36m(RayTrainWorker pid=3336387)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3336387)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3336387)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_574995bd completed after 10 iterations at 2025-04-25 16:16:18. Total running time: 45min 58s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_574995bd result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46238 â”‚
â”‚ time_total_s                                      178.02565 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70494 â”‚
â”‚ id_test-average_precision                           0.59906 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70573 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68892 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68892 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67679 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66486 â”‚
â”‚ ood_test_3-average_precision                        0.77783 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70114 â”‚
â”‚ validation-average_precision                        0.59528 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d6325af4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d6325af4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.917129 â”‚
â”‚ params/colsample_bytree                      0.501623 â”‚
â”‚ params/learning_rate                      0.000195092 â”‚
â”‚ params/max_depth                                   10 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       27.4374 â”‚
â”‚ params/reg_alpha                          2.66537e-05 â”‚
â”‚ params/reg_lambda                          0.00126417 â”‚
â”‚ params/subsample                             0.696258 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 29 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:16:24. Total running time: 46min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
Trial status: 29 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:16:54. Total running time: 46min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044862 seconds.
[36m(RayTrainWorker pid=3346102)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3346102)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 29 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:17:24. Total running time: 47min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_877005e3   RUNNING                 3.897e-05                          2            6376.65                   0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3346102)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_877005e3 completed after 10 iterations at 2025-04-25 16:17:36. Total running time: 47min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_877005e3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.51556 â”‚
â”‚ time_total_s                                      186.49889 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6a8f0c9d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6a8f0c9d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.864251 â”‚
â”‚ params/colsample_bytree                     0.647681 â”‚
â”‚ params/learning_rate                      0.00108887 â”‚
â”‚ params/max_depth                                   3 â”‚
â”‚ params/min_child_samples                          32 â”‚
â”‚ params/min_child_weight                      98199.4 â”‚
â”‚ params/reg_alpha                              75.849 â”‚
â”‚ params/reg_lambda                            15.9132 â”‚
â”‚ params/subsample                            0.925271 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 30 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:17:54. Total running time: 47min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more TERMINATED
Trial status: 30 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:18:25. Total running time: 48min 4s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more TERMINATED
Trial status: 30 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:18:55. Total running time: 48min 34s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417                                                                                                                     â”‚
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more TERMINATED
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043355 seconds.
[36m(RayTrainWorker pid=3347853)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3347853)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3347853)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 30 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:19:25. Total running time: 49min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d6325af4   RUNNING                 0.000195092                        4              27.4374                 0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417         9            185.902               0.401213      0.701596                 0.593558                 0.522494 â”‚
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more TERMINATED

Trial LightGBMTrainer_d6325af4 completed after 10 iterations at 2025-04-25 16:19:27. Total running time: 49min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d6325af4 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.47221 â”‚
â”‚ time_total_s                                      186.37462 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70494 â”‚
â”‚ id_test-average_precision                           0.59906 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70573 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68892 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68892 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67679 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66486 â”‚
â”‚ ood_test_3-average_precision                        0.77783 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70114 â”‚
â”‚ validation-average_precision                        0.59528 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_090824e8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_090824e8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.890666 â”‚
â”‚ params/colsample_bytree                      0.852201 â”‚
â”‚ params/learning_rate                      6.46221e-05 â”‚
â”‚ params/max_depth                                   11 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                        1519.2 â”‚
â”‚ params/reg_alpha                              12.9457 â”‚
â”‚ params/reg_lambda                            0.406894 â”‚
â”‚ params/subsample                             0.975552 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 31 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:19:55. Total running time: 49min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
Trial status: 31 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:20:25. Total running time: 50min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6a8f0c9d   RUNNING                 0.00108887                        32           98199.4                    0.925271                    3                 0.647681                 0.864251         75.849                15.9132                                                                                                                         â”‚
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042966 seconds.
[36m(RayTrainWorker pid=3349695)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3349695)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3349695)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_6a8f0c9d completed after 10 iterations at 2025-04-25 16:20:41. Total running time: 50min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6a8f0c9d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50733 â”‚
â”‚ time_total_s                                      182.57132 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6879717b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6879717b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.803638 â”‚
â”‚ params/colsample_bytree                       0.79128 â”‚
â”‚ params/learning_rate                      1.95574e-05 â”‚
â”‚ params/max_depth                                   22 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                    0.00168268 â”‚
â”‚ params/reg_alpha                           0.00245891 â”‚
â”‚ params/reg_lambda                         0.000616406 â”‚
â”‚ params/subsample                             0.670981 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 32 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:20:55. Total running time: 50min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
Trial status: 32 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:21:25. Total running time: 51min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
Trial status: 32 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:21:55. Total running time: 51min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
Trial status: 32 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:22:25. Total running time: 52min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_090824e8   RUNNING                 6.46221e-05                        2            1519.2                    0.975552                   11                 0.852201                 0.890666         12.9457                0.406894                                                                                                                       â”‚
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044166 seconds.
[36m(RayTrainWorker pid=3360235)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3360235)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3360235)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_090824e8 completed after 10 iterations at 2025-04-25 16:22:48. Total running time: 52min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_090824e8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                      0.462 â”‚
â”‚ time_total_s                                      200.02738 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3338edc9 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3338edc9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.99329 â”‚
â”‚ params/colsample_bytree                     0.585454 â”‚
â”‚ params/learning_rate                      0.00142042 â”‚
â”‚ params/max_depth                                   9 â”‚
â”‚ params/min_child_samples                          32 â”‚
â”‚ params/min_child_weight                      11008.5 â”‚
â”‚ params/reg_alpha                             1.87022 â”‚
â”‚ params/reg_lambda                          0.0217273 â”‚
â”‚ params/subsample                            0.902931 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 33 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:22:55. Total running time: 52min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32           11008.5                    0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
28 more TERMINATED
Trial status: 33 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:23:25. Total running time: 53min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6879717b   RUNNING                 1.95574e-05                        8               0.00168268             0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406                                                                                                                    â”‚
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32           11008.5                    0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
28 more TERMINATED
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045722 seconds.
[36m(RayTrainWorker pid=3361830)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3361830)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3361830)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_6879717b completed after 10 iterations at 2025-04-25 16:23:54. Total running time: 53min 34s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6879717b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.51833 â”‚
â”‚ time_total_s                                      191.19958 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_90bd3626 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_90bd3626 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.776931 â”‚
â”‚ params/colsample_bytree                      0.658164 â”‚
â”‚ params/learning_rate                      0.000302989 â”‚
â”‚ params/max_depth                                    2 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                   0.000117948 â”‚
â”‚ params/reg_alpha                          0.000312591 â”‚
â”‚ params/reg_lambda                         2.37662e-07 â”‚
â”‚ params/subsample                              0.76415 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 34 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:23:55. Total running time: 53min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
Trial status: 34 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:24:25. Total running time: 54min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
Trial status: 34 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:24:55. Total running time: 54min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
Trial status: 34 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:25:25. Total running time: 55min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273                                                                                                                      â”‚
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043063 seconds.
[36m(RayTrainWorker pid=3363648)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3363648)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3363648)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 34 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:25:55. Total running time: 55min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3338edc9   RUNNING                 0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273          6            186.429               0.401213      0.702113                 0.593972                 0.522494 â”‚
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED

Trial LightGBMTrainer_3338edc9 completed after 10 iterations at 2025-04-25 16:25:59. Total running time: 55min 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3338edc9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45754 â”‚
â”‚ time_total_s                                      189.16854 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_a9750ae1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a9750ae1 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.984815 â”‚
â”‚ params/colsample_bytree                      0.743846 â”‚
â”‚ params/learning_rate                       1.3951e-05 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                      0.999046 â”‚
â”‚ params/reg_alpha                          3.31555e-05 â”‚
â”‚ params/reg_lambda                         3.43548e-06 â”‚
â”‚ params/subsample                             0.870188 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 35 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:26:25. Total running time: 56min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8              0.999046                0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
Trial status: 35 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:26:55. Total running time: 56min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_90bd3626   RUNNING                 0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8              0.999046                0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043732 seconds.
[36m(RayTrainWorker pid=3370585)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3370585)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3370585)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_90bd3626 completed after 10 iterations at 2025-04-25 16:27:20. Total running time: 57min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_90bd3626 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.4947 â”‚
â”‚ time_total_s                                      204.78914 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_57eaa234 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_57eaa234 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.838415 â”‚
â”‚ params/colsample_bytree                      0.818249 â”‚
â”‚ params/learning_rate                       0.00704019 â”‚
â”‚ params/max_depth                                    5 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                      0.094578 â”‚
â”‚ params/reg_alpha                             0.342359 â”‚
â”‚ params/reg_lambda                         2.26804e-05 â”‚
â”‚ params/subsample                             0.567127 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 36 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:27:26. Total running time: 57min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8               0.999046               0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
Trial status: 36 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:27:56. Total running time: 57min 35s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8               0.999046               0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
Trial status: 36 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:28:26. Total running time: 58min 5s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8               0.999046               0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
Trial status: 36 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:28:56. Total running time: 58min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a9750ae1   RUNNING                 1.3951e-05                         8               0.999046               0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043476 seconds.
[36m(RayTrainWorker pid=3375994)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3375994)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3375994)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_a9750ae1 completed after 10 iterations at 2025-04-25 16:29:22. Total running time: 59min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a9750ae1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46417 â”‚
â”‚ time_total_s                                      201.81754 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_55c8d0cb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_55c8d0cb config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.938414 â”‚
â”‚ params/colsample_bytree                      0.513827 â”‚
â”‚ params/learning_rate                       0.00166409 â”‚
â”‚ params/max_depth                                   26 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                       38.4634 â”‚
â”‚ params/reg_alpha                          1.45805e-07 â”‚
â”‚ params/reg_lambda                         0.000134061 â”‚
â”‚ params/subsample                             0.719977 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 37 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:29:26. Total running time: 59min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
32 more TERMINATED
Trial status: 37 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:29:56. Total running time: 59min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
32 more TERMINATED
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046283 seconds.
[36m(RayTrainWorker pid=3377588)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3377588)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 37 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:30:26. Total running time: 1hr 0min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_57eaa234   RUNNING                 0.00704019                        16               0.094578               0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
32 more TERMINATED
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3377588)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_57eaa234 completed after 10 iterations at 2025-04-25 16:30:39. Total running time: 1hr 0min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_57eaa234 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    1.06921 â”‚
â”‚ time_total_s                                       197.5545 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b472b5d6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b472b5d6 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.924163 â”‚
â”‚ params/colsample_bytree                      0.663261 â”‚
â”‚ params/learning_rate                      0.000198681 â”‚
â”‚ params/max_depth                                    8 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       436.071 â”‚
â”‚ params/reg_alpha                            0.0304236 â”‚
â”‚ params/reg_lambda                          0.00141403 â”‚
â”‚ params/subsample                             0.810704 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 38 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:30:56. Total running time: 1hr 0min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4             436.071                  0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
Trial status: 38 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:31:26. Total running time: 1hr 1min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4             436.071                  0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
Trial status: 38 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:31:56. Total running time: 1hr 1min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4             436.071                  0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047042 seconds.
[36m(RayTrainWorker pid=3386540)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3386540)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 38 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:32:26. Total running time: 1hr 2min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55c8d0cb   RUNNING                 0.00166409                         1              38.4634                 0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061                                                                                                                    â”‚
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4             436.071                  0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3386540)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_55c8d0cb completed after 10 iterations at 2025-04-25 16:32:33. Total running time: 1hr 2min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_55c8d0cb result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.47715 â”‚
â”‚ time_total_s                                      188.58665 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bc32f346 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bc32f346 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.689104 â”‚
â”‚ params/colsample_bytree                      0.963428 â”‚
â”‚ params/learning_rate                      0.000626822 â”‚
â”‚ params/max_depth                                   29 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   0.000241397 â”‚
â”‚ params/reg_alpha                              2.75526 â”‚
â”‚ params/reg_lambda                         7.59967e-08 â”‚
â”‚ params/subsample                             0.592177 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 39 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:32:56. Total running time: 1hr 2min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4            436.071                   0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
Trial status: 39 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:33:26. Total running time: 1hr 3min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b472b5d6   RUNNING                 0.000198681                        4            436.071                   0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403                                                                                                                     â”‚
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043231 seconds.
[36m(RayTrainWorker pid=3388047)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3388047)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3388047)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_b472b5d6 completed after 10 iterations at 2025-04-25 16:33:44. Total running time: 1hr 3min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b472b5d6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.4916 â”‚
â”‚ time_total_s                                      183.49478 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6daaa906 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6daaa906 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                       0.7756 â”‚
â”‚ params/colsample_bytree                      0.846091 â”‚
â”‚ params/learning_rate                         0.117013 â”‚
â”‚ params/max_depth                                   16 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                   2.54829e-07 â”‚
â”‚ params/reg_alpha                           7.3467e-05 â”‚
â”‚ params/reg_lambda                         8.44147e-07 â”‚
â”‚ params/subsample                              0.76759 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 40 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:33:56. Total running time: 1hr 3min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
Trial status: 40 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:34:26. Total running time: 1hr 4min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
Trial status: 40 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:34:56. Total running time: 1hr 4min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.450010 seconds.
[36m(RayTrainWorker pid=3389813)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3389813)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 40 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:35:26. Total running time: 1hr 5min 6s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bc32f346   RUNNING                 0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3389813)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_bc32f346 completed after 10 iterations at 2025-04-25 16:35:38. Total running time: 1hr 5min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bc32f346 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     0.4833 â”‚
â”‚ time_total_s                                      183.15852 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_be5e91db started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_be5e91db config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.517026 â”‚
â”‚ params/colsample_bytree                      0.763192 â”‚
â”‚ params/learning_rate                      7.99972e-05 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                        3.0112 â”‚
â”‚ params/reg_alpha                          1.36977e-05 â”‚
â”‚ params/reg_lambda                            0.254155 â”‚
â”‚ params/subsample                             0.658834 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 41 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:35:57. Total running time: 1hr 5min 36s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1              3.0112                  0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
36 more TERMINATED
Trial status: 41 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:36:27. Total running time: 1hr 6min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1              3.0112                  0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
36 more TERMINATED
Trial status: 41 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:36:57. Total running time: 1hr 6min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6daaa906   RUNNING                 0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1              3.0112                  0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
36 more TERMINATED
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054184 seconds.
[36m(RayTrainWorker pid=3394442)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3394442)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3394442)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_6daaa906 completed after 10 iterations at 2025-04-25 16:37:19. Total running time: 1hr 6min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6daaa906 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.52867 â”‚
â”‚ time_total_s                                      212.91346 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_2afacdaa started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2afacdaa config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.883186 â”‚
â”‚ params/colsample_bytree                      0.732898 â”‚
â”‚ params/learning_rate                       3.6886e-05 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                    0.00671088 â”‚
â”‚ params/reg_alpha                          2.02819e-06 â”‚
â”‚ params/reg_lambda                          0.00866318 â”‚
â”‚ params/subsample                             0.901462 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 42 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:37:27. Total running time: 1hr 7min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1               3.0112                 0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
37 more TERMINATED
Trial status: 42 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:37:57. Total running time: 1hr 7min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1               3.0112                 0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
37 more TERMINATED
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 42 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:38:27. Total running time: 1hr 8min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_be5e91db   RUNNING                 7.99972e-05                        1               3.0112                 0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155                                                                                                                       â”‚
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
37 more TERMINATED
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042688 seconds.
[36m(RayTrainWorker pid=3401295)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3401295)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3401295)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_be5e91db completed after 10 iterations at 2025-04-25 16:38:39. Total running time: 1hr 8min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_be5e91db result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45602 â”‚
â”‚ time_total_s                                      179.33924 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d8ce0395 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d8ce0395 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.828925 â”‚
â”‚ params/colsample_bytree                       0.59031 â”‚
â”‚ params/learning_rate                       0.00433772 â”‚
â”‚ params/max_depth                                   12 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                         24546 â”‚
â”‚ params/reg_alpha                              26.1711 â”‚
â”‚ params/reg_lambda                         3.89366e-06 â”‚
â”‚ params/subsample                             0.528991 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 43 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:38:57. Total running time: 1hr 8min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:39:27. Total running time: 1hr 9min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:39:57. Total running time: 1hr 9min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2afacdaa   RUNNING                 3.6886e-05                        32               0.00671088             0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318                                                                                                                     â”‚
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043380 seconds.
[36m(RayTrainWorker pid=3402997)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3402997)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3402997)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_2afacdaa completed after 10 iterations at 2025-04-25 16:40:22. Total running time: 1hr 10min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2afacdaa result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.48716 â”‚
â”‚ time_total_s                                      181.32019 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_4bff171e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_4bff171e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.748428 â”‚
â”‚ params/colsample_bytree                     0.684247 â”‚
â”‚ params/learning_rate                       0.0213262 â”‚
â”‚ params/max_depth                                  17 â”‚
â”‚ params/min_child_samples                          16 â”‚
â”‚ params/min_child_weight                      95.0889 â”‚
â”‚ params/reg_alpha                          0.00288601 â”‚
â”‚ params/reg_lambda                         4.5353e-05 â”‚
â”‚ params/subsample                            0.993085 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 44 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:40:27. Total running time: 1hr 10min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
Trial status: 44 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:40:57. Total running time: 1hr 10min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
Trial status: 44 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:41:27. Total running time: 1hr 11min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d8ce0395   RUNNING                 0.00433772                        64           24546                      0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043655 seconds.
[36m(RayTrainWorker pid=3404608)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3404608)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3404608)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d8ce0395 completed after 10 iterations at 2025-04-25 16:41:49. Total running time: 1hr 11min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d8ce0395 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46696 â”‚
â”‚ time_total_s                                      188.49614 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3a3e9899 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3a3e9899 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.786856 â”‚
â”‚ params/colsample_bytree                      0.903379 â”‚
â”‚ params/learning_rate                      0.000217385 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                      0.041384 â”‚
â”‚ params/reg_alpha                          0.000380256 â”‚
â”‚ params/reg_lambda                         0.000276791 â”‚
â”‚ params/subsample                              0.73432 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 45 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:41:57. Total running time: 1hr 11min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
Trial status: 45 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:42:27. Total running time: 1hr 12min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
Trial status: 45 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:42:57. Total running time: 1hr 12min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041623 seconds.
[36m(RayTrainWorker pid=3412936)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3412936)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 45 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:43:28. Total running time: 1hr 13min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_4bff171e   RUNNING                 0.0213262                         16              95.0889                 0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05                                                                                                                     â”‚
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3412936)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_4bff171e completed after 10 iterations at 2025-04-25 16:43:36. Total running time: 1hr 13min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_4bff171e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50088 â”‚
â”‚ time_total_s                                      191.75669 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5ca6e778 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5ca6e778 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.960681 â”‚
â”‚ params/colsample_bytree                      0.946858 â”‚
â”‚ params/learning_rate                      0.000717583 â”‚
â”‚ params/max_depth                                   14 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                      0.274302 â”‚
â”‚ params/reg_alpha                          6.77448e-07 â”‚
â”‚ params/reg_lambda                             8.85427 â”‚
â”‚ params/subsample                             0.858802 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 46 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:43:58. Total running time: 1hr 13min 38s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4               0.274302               0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
41 more TERMINATED
Trial status: 46 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:44:28. Total running time: 1hr 14min 8s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3a3e9899   RUNNING                 0.000217385                        8               0.041384               0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791                                                                                                                    â”‚
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4               0.274302               0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
41 more TERMINATED
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042452 seconds.
[36m(RayTrainWorker pid=3414422)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3414422)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3414422)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_3a3e9899 completed after 10 iterations at 2025-04-25 16:44:55. Total running time: 1hr 14min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3a3e9899 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.46342 â”‚
â”‚ time_total_s                                      184.59015 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_0df741f4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0df741f4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.574721 â”‚
â”‚ params/colsample_bytree                      0.721048 â”‚
â”‚ params/learning_rate                         0.376041 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000401599 â”‚
â”‚ params/reg_alpha                          1.04067e-08 â”‚
â”‚ params/reg_lambda                         1.06053e-06 â”‚
â”‚ params/subsample                             0.943764 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 47 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:44:58. Total running time: 1hr 14min 38s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4              0.274302                0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:45:28. Total running time: 1hr 15min 8s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4              0.274302                0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:45:58. Total running time: 1hr 15min 38s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4              0.274302                0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:46:28. Total running time: 1hr 16min 8s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5ca6e778   RUNNING                 0.000717583                        4              0.274302                0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427                                                                                                                        â”‚
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051104 seconds.
[36m(RayTrainWorker pid=3416167)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3416167)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3416167)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_5ca6e778 completed after 10 iterations at 2025-04-25 16:46:56. Total running time: 1hr 16min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5ca6e778 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.79442 â”‚
â”‚ time_total_s                                      198.95657 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_7e141f4d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7e141f4d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.652157 â”‚
â”‚ params/colsample_bytree                      0.993585 â”‚
â”‚ params/learning_rate                       0.00198402 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                       1533.96 â”‚
â”‚ params/reg_alpha                          1.72828e-07 â”‚
â”‚ params/reg_lambda                          0.00488804 â”‚
â”‚ params/subsample                             0.679446 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 48 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:46:58. Total running time: 1hr 16min 38s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64           1533.96                    0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
43 more TERMINATED
Trial status: 48 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:47:28. Total running time: 1hr 17min 8s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64           1533.96                    0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
43 more TERMINATED
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042765 seconds.
[36m(RayTrainWorker pid=3424410)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3424410)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3424410)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 48 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:47:58. Total running time: 1hr 17min 38s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0df741f4   RUNNING                 0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06        3            182.811               0.401213      0.700342                 0.588848                 0.522494 â”‚
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64           1533.96                    0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
43 more TERMINATED

Trial LightGBMTrainer_0df741f4 completed after 10 iterations at 2025-04-25 16:48:03. Total running time: 1hr 17min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0df741f4 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.45724 â”‚
â”‚ time_total_s                                      186.03506 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff03062c65e113cc27672fa39e01000000 Worker ID: 76d0bdbab5ae16ee71d85999bf837903ed917dc8f9af631991557652 Node ID: 6952427dc156d3b0c6734e6de90b517fba6a5ea6acdd22be5aa79d46 Worker IP address: 10.164.8.140 Worker port: 45079 Worker PID: 3424508 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM.

Trial status: 49 TERMINATED | 1 RUNNING
Current time: 2025-04-25 16:48:28. Total running time: 1hr 18min 8s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64            1533.96                   0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
44 more TERMINATED
Trial status: 49 TERMINATED | 1 RUNNING
Current time: 2025-04-25 16:48:58. Total running time: 1hr 18min 38s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64            1533.96                   0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
44 more TERMINATED
Trial status: 49 TERMINATED | 1 RUNNING
Current time: 2025-04-25 16:49:28. Total running time: 1hr 19min 8s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7e141f4d   RUNNING                 0.00198402                        64            1533.96                   0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
44 more TERMINATED
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042701 seconds.
[36m(RayTrainWorker pid=3427432)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=3427432)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=3427432)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_7e141f4d completed after 10 iterations at 2025-04-25 16:49:50. Total running time: 1hr 19min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7e141f4d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.50584 â”‚
â”‚ time_total_s                                      172.59562 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 50 TERMINATED
Current time: 2025-04-25 16:49:51. Total running time: 1hr 19min 31s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_4-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b81c0c2   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            207.815               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_8a157d87   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            202.893               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_fc51d1bb   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            195.588               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3b27c720   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809       10            180.133               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_bd7233de   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364           10            177.011               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ddfaed8a   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06       10            167.713               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_1a0be928   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05       10            179.525               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_ef5c58d4   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            214.682               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_17d4b55e   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            173.287               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3fef2789   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            180.475               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_86413810   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07       10            171.467               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5b1f3996   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            178.201               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_22460414   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698         10            181.061               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_489a88af   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264          10            176.001               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_26857256   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861       10            186.441               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_031c3829   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            185.318               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_b3369e05   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08       10            178.754               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_9c447241   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442        10            179.597               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_65f0175b   TERMINATED              0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08       10            183.917               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_6222560e   TERMINATED              5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961           10            173.337               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_32c608b6   TERMINATED              1.08027e-05                        4              7.43684                 0.837436                   19                 0.921792                 0.893064          1.811e-08             0.0916407         10            191.369               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_2c7400dc   TERMINATED              9.80991e-05                        4             11.0146                  0.93083                     4                 0.783473                 0.946168          0.00771771           44.9291            10            183.269               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_301b2b78   TERMINATED              0.00275329                         4            473.221                   0.829227                   18                 0.612485                 0.868694          1.32289               5.07964e-05       10            181.915               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_3b699802   TERMINATED              0.000113117                        8              4.34465                 0.787782                   15                 0.915119                 0.956108          0.00642446            0.0308342         10            191.707               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_d7cf3973   TERMINATED              2.416e-05                         32            198.491                   0.866313                   -1                 0.806699                 0.859736         90.627                 0.000373607       10            174.048               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_d94608c9   TERMINATED              0.000139049                        4           2248.57                    0.502257                   20                 0.75575                  0.970751          0.0454263             9.12876e-06       10            188.175               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_5ac96151   TERMINATED              1.00054e-05                        4              0.878472                0.956884                    1                 0.620445                 0.840217          0.00104969            0.00322462        10            181.796               0.401213      0.701728                 0.593419                 0.522494 â”‚
â”‚ LightGBMTrainer_189af84a   TERMINATED              0.00308779                         8             30.6802                  0.787888                   23                 0.870271                 0.909213          0.128728              0.000137752       10            196.365               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_574995bd   TERMINATED              0.00839989                         8              0.709055                0.83532                    28                 0.94091                  0.998232          7.64164e-08           0.0597149         10            178.026               0.401213      0.701728                 0.593419                 0.522494 â”‚
â”‚ LightGBMTrainer_877005e3   TERMINATED              3.897e-05                          2           6376.65                    0.55223                    30                 0.886995                 0.968986          0.000177373           1.29028e-05       10            186.499               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_d6325af4   TERMINATED              0.000195092                        4             27.4374                  0.696258                   10                 0.501623                 0.917129          2.66537e-05           0.00126417        10            186.375               0.401213      0.701728                 0.593419                 0.522494 â”‚
â”‚ LightGBMTrainer_6a8f0c9d   TERMINATED              0.00108887                        32          98199.4                     0.925271                    3                 0.647681                 0.864251         75.849                15.9132            10            182.571               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_090824e8   TERMINATED              6.46221e-05                        2           1519.2                     0.975552                   11                 0.852201                 0.890666         12.9457                0.406894          10            200.027               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_6879717b   TERMINATED              1.95574e-05                        8              0.00168268              0.670981                   22                 0.79128                  0.803638          0.00245891            0.000616406       10            191.2                 0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3338edc9   TERMINATED              0.00142042                        32          11008.5                     0.902931                    9                 0.585454                 0.99329           1.87022               0.0217273         10            189.169               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_90bd3626   TERMINATED              0.000302989                        4              0.000117948             0.76415                     2                 0.658164                 0.776931          0.000312591           2.37662e-07       10            204.789               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_a9750ae1   TERMINATED              1.3951e-05                         8              0.999046                0.870188                    6                 0.743846                 0.984815          3.31555e-05           3.43548e-06       10            201.818               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_57eaa234   TERMINATED              0.00704019                        16              0.094578                0.567127                    5                 0.818249                 0.838415          0.342359              2.26804e-05       10            197.554               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_55c8d0cb   TERMINATED              0.00166409                         1             38.4634                  0.719977                   26                 0.513827                 0.938414          1.45805e-07           0.000134061       10            188.587               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_b472b5d6   TERMINATED              0.000198681                        4            436.071                   0.810704                    8                 0.663261                 0.924163          0.0304236             0.00141403        10            183.495               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_bc32f346   TERMINATED              0.000626822                        2              0.000241397             0.592177                   29                 0.963428                 0.689104          2.75526               7.59967e-08       10            183.159               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_6daaa906   TERMINATED              0.117013                           8              2.54829e-07             0.76759                    16                 0.846091                 0.7756            7.3467e-05            8.44147e-07       10            212.913               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_be5e91db   TERMINATED              7.99972e-05                        1              3.0112                  0.658834                    6                 0.763192                 0.517026          1.36977e-05           0.254155          10            179.339               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_2afacdaa   TERMINATED              3.6886e-05                        32              0.00671088              0.901462                   19                 0.732898                 0.883186          2.02819e-06           0.00866318        10            181.32                0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_d8ce0395   TERMINATED              0.00433772                        64          24546                       0.528991                   12                 0.59031                  0.828925         26.1711                3.89366e-06       10            188.496               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_4bff171e   TERMINATED              0.0213262                         16             95.0889                  0.993085                   17                 0.684247                 0.748428          0.00288601            4.5353e-05        10            191.757               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_3a3e9899   TERMINATED              0.000217385                        8              0.041384                0.73432                    27                 0.903379                 0.786856          0.000380256           0.000276791       10            184.59                0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_5ca6e778   TERMINATED              0.000717583                        4              0.274302                0.858802                   14                 0.946858                 0.960681          6.77448e-07           8.85427           10            198.957               0.401213      0.701815                 0.595072                 0.522494 â”‚
â”‚ LightGBMTrainer_0df741f4   TERMINATED              0.376041                           1              0.000401599             0.943764                   19                 0.721048                 0.574721          1.04067e-08           1.06053e-06       10            186.035               0.401213      0.701732                 0.593421                 0.522494 â”‚
â”‚ LightGBMTrainer_7e141f4d   TERMINATED              0.00198402                        64           1533.96                    0.679446                   25                 0.993585                 0.652157          1.72828e-07           0.00488804        10            172.596               0.401213      0.701815                 0.595072                 0.522494 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

    train-auc  ...  domain_split_id_values
0    0.701815  ...         ['0', '1', '4']
1    0.701732  ...         ['0', '1', '4']
2    0.701815  ...         ['0', '1', '4']
3    0.701732  ...         ['0', '1', '4']
4    0.701732  ...         ['0', '1', '4']
5    0.701815  ...         ['0', '1', '4']
6    0.701732  ...         ['0', '1', '4']
7    0.701815  ...         ['0', '1', '4']
8    0.701732  ...         ['0', '1', '4']
9    0.701815  ...         ['0', '1', '4']
10   0.701732  ...         ['0', '1', '4']
11   0.701815  ...         ['0', '1', '4']
12   0.701732  ...         ['0', '1', '4']
13   0.701815  ...         ['0', '1', '4']
14   0.701732  ...         ['0', '1', '4']
15   0.701815  ...         ['0', '1', '4']
16   0.701732  ...         ['0', '1', '4']
17   0.701815  ...         ['0', '1', '4']
18   0.701732  ...         ['0', '1', '4']
19   0.701815  ...         ['0', '1', '4']
20   0.701732  ...         ['0', '1', '4']
21   0.701815  ...         ['0', '1', '4']
22   0.701732  ...         ['0', '1', '4']
23   0.701815  ...         ['0', '1', '4']
24   0.701732  ...         ['0', '1', '4']
25   0.701815  ...         ['0', '1', '4']
26   0.701728  ...         ['0', '1', '4']
27   0.701815  ...         ['0', '1', '4']
28   0.701728  ...         ['0', '1', '4']
29   0.701815  ...         ['0', '1', '4']
30   0.701728  ...         ['0', '1', '4']
31   0.701815  ...         ['0', '1', '4']
32   0.701732  ...         ['0', '1', '4']
33   0.701815  ...         ['0', '1', '4']
34   0.701732  ...         ['0', '1', '4']
35   0.701815  ...         ['0', '1', '4']
36   0.701732  ...         ['0', '1', '4']
37   0.701815  ...         ['0', '1', '4']
38   0.701732  ...         ['0', '1', '4']
39   0.701815  ...         ['0', '1', '4']
40   0.701732  ...         ['0', '1', '4']
41   0.701815  ...         ['0', '1', '4']
42   0.701732  ...         ['0', '1', '4']
43   0.701815  ...         ['0', '1', '4']
44   0.701732  ...         ['0', '1', '4']
45   0.701815  ...         ['0', '1', '4']
46   0.701732  ...         ['0', '1', '4']
47   0.701815  ...         ['0', '1', '4']
48   0.701732  ...         ['0', '1', '4']
49   0.701815  ...         ['0', '1', '4']

[50 rows x 70 columns]
