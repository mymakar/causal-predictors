â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     tableshift              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator         â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler â”‚
â”‚ Number of trials                 50                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/rjsingh/ray_results/tableshift
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-04-25_15-58-37_826776_1478295/artifacts/2025-04-25_15-58-54/tableshift/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-04-25 15:58:55. Total running time: 0s
Logical resource usage: 0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   PENDING               0.000164587                        8                  31.1567             0.795395                    6                  0.72302                 0.925513               11.443             0.0032299 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_67999564 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_67999564 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.925513 â”‚
â”‚ params/colsample_bytree                       0.72302 â”‚
â”‚ params/learning_rate                      0.000164587 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                       31.1567 â”‚
â”‚ params/reg_alpha                               11.443 â”‚
â”‚ params/reg_lambda                           0.0032299 â”‚
â”‚ params/subsample                             0.795395 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_96a913ea started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_96a913ea config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.91828 â”‚
â”‚ params/colsample_bytree                      0.963194 â”‚
â”‚ params/learning_rate                      0.000121064 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       88.6536 â”‚
â”‚ params/reg_alpha                          3.15908e-05 â”‚
â”‚ params/reg_lambda                          1.9731e-05 â”‚
â”‚ params/subsample                             0.995723 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 2 RUNNING | 1 PENDING
Current time: 2025-04-25 15:59:25. Total running time: 30s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â”‚ LightGBMTrainer_876c42c0   PENDING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379            2.79121    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 RUNNING | 1 PENDING
Current time: 2025-04-25 15:59:55. Total running time: 1min 0s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                  0.0032299  â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05            1.9731e-05 â”‚
â”‚ LightGBMTrainer_876c42c0   PENDING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379            2.79121    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_876c42c0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_876c42c0 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.995475 â”‚
â”‚ params/colsample_bytree                      0.890752 â”‚
â”‚ params/learning_rate                         0.285296 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    1.5737e-05 â”‚
â”‚ params/reg_alpha                          0.000468379 â”‚
â”‚ params/reg_lambda                             2.79121 â”‚
â”‚ params/subsample                             0.799768 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-04-25 16:00:25. Total running time: 1min 30s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   PENDING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 152 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).
Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-04-25 16:00:55. Total running time: 2min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   PENDING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_382bb831 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_382bb831 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.903575 â”‚
â”‚ params/colsample_bytree                      0.841159 â”‚
â”‚ params/learning_rate                      0.000988995 â”‚
â”‚ params/max_depth                                    5 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                    0.00324906 â”‚
â”‚ params/reg_alpha                           5.8573e-05 â”‚
â”‚ params/reg_lambda                         0.000552809 â”‚
â”‚ params/subsample                             0.652433 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 188 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).

Trial LightGBMTrainer_0ab5550e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0ab5550e config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.815193 â”‚
â”‚ params/colsample_bytree                    0.657187 â”‚
â”‚ params/learning_rate                      0.0415284 â”‚
â”‚ params/max_depth                                 17 â”‚
â”‚ params/min_child_samples                         32 â”‚
â”‚ params/min_child_weight                     5054.73 â”‚
â”‚ params/reg_alpha                            22.4911 â”‚
â”‚ params/reg_lambda                           3.52364 â”‚
â”‚ params/subsample                           0.570107 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 5 RUNNING | 1 PENDING
Current time: 2025-04-25 16:01:25. Total running time: 2min 30s
Logical resource usage: 6.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   PENDING               0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_c6c17020 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c6c17020 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.998595 â”‚
â”‚ params/colsample_bytree                      0.846572 â”‚
â”‚ params/learning_rate                      0.000408737 â”‚
â”‚ params/max_depth                                   16 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0240841 â”‚
â”‚ params/reg_alpha                          7.19007e-06 â”‚
â”‚ params/reg_lambda                         2.22449e-06 â”‚
â”‚ params/subsample                             0.902369 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 218 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).

Trial status: 6 RUNNING | 1 PENDING
Current time: 2025-04-25 16:01:55. Total running time: 3min 0s
Logical resource usage: 7.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   PENDING               0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ebe8995a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ebe8995a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.667537 â”‚
â”‚ params/colsample_bytree                      0.541613 â”‚
â”‚ params/learning_rate                      0.000722629 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                     0.0899496 â”‚
â”‚ params/reg_alpha                          3.73583e-05 â”‚
â”‚ params/reg_lambda                         1.60174e-05 â”‚
â”‚ params/subsample                             0.997766 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 252 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).

Trial status: 7 RUNNING | 1 PENDING
Current time: 2025-04-25 16:02:25. Total running time: 3min 30s
Logical resource usage: 8.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   PENDING               0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_dd34c228 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_dd34c228 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.760773 â”‚
â”‚ params/colsample_bytree                     0.771388 â”‚
â”‚ params/learning_rate                        0.173267 â”‚
â”‚ params/max_depth                                   7 â”‚
â”‚ params/min_child_samples                           1 â”‚
â”‚ params/min_child_weight                   0.00108024 â”‚
â”‚ params/reg_alpha                             6.15976 â”‚
â”‚ params/reg_lambda                            3.35489 â”‚
â”‚ params/subsample                            0.618161 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 8 RUNNING | 1 PENDING
Current time: 2025-04-25 16:02:55. Total running time: 4min 0s
Logical resource usage: 9.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   PENDING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8849c856 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8849c856 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.646288 â”‚
â”‚ params/colsample_bytree                      0.967027 â”‚
â”‚ params/learning_rate                         0.659853 â”‚
â”‚ params/max_depth                                   12 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000106202 â”‚
â”‚ params/reg_alpha                             0.558068 â”‚
â”‚ params/reg_lambda                         8.42149e-07 â”‚
â”‚ params/subsample                             0.696157 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 310 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).
[33m(raylet)[0m WARNING: 340 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).

Trial status: 9 RUNNING | 1 PENDING
Current time: 2025-04-25 16:03:25. Total running time: 4min 30s
Logical resource usage: 9.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   PENDING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_f2e40a84 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f2e40a84 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.935438 â”‚
â”‚ params/colsample_bytree                      0.984963 â”‚
â”‚ params/learning_rate                         0.620081 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                   2.24559e-06 â”‚
â”‚ params/reg_alpha                          3.40549e-08 â”‚
â”‚ params/reg_lambda                          2.1901e-06 â”‚
â”‚ params/subsample                             0.611725 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 10 RUNNING
Current time: 2025-04-25 16:03:55. Total running time: 5min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 370 PYTHON worker processes have been started on node: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 with address: 10.164.10.39. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).
Trial status: 10 RUNNING
Current time: 2025-04-25 16:04:25. Total running time: 5min 30s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:04:55. Total running time: 6min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:05:25. Total running time: 6min 30s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:05:55. Total running time: 7min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:06:25. Total running time: 7min 30s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:06:55. Total running time: 8min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 RUNNING
Current time: 2025-04-25 16:07:25. Total running time: 8min 30s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091275 seconds.
[36m(RayTrainWorker pid=1484910)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1484910)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 10 RUNNING
Current time: 2025-04-25 16:07:55. Total running time: 9min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING               0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_96a913ea   RUNNING               0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING               0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING               0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING               0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364     â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING               0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06 â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING               0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05 â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING               0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489     â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING               0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING               0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058829 seconds.
[36m(RayTrainWorker pid=1484049)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1484049)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1484910)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1484049)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial LightGBMTrainer_96a913ea completed after 10 iterations at 2025-04-25 16:08:25. Total running time: 9min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_96a913ea result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.72377 â”‚
â”‚ time_total_s                                      545.80881 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70495 â”‚
â”‚ id_test-average_precision                           0.59907 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66289 â”‚
â”‚ id_test_0-average_precision                         0.52361 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70574 â”‚
â”‚ id_test_1-average_precision                         0.58002 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68457 â”‚
â”‚ id_test_4-average_precision                          0.6916 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68891 â”‚
â”‚ new_ood_test-average_precision                      0.73976 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68891 â”‚
â”‚ new_ood_test_1-average_precision                    0.73976 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70173 â”‚
â”‚ new_train-average_precision                         0.59342 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68824 â”‚
â”‚ ood_test-average_precision                          0.73896 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67678 â”‚
â”‚ ood_test_2-average_precision                        0.67245 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66487 â”‚
â”‚ ood_test_3-average_precision                        0.77784 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68766 â”‚
â”‚ ood_validation-average_precision                    0.73715 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                           0.6873 â”‚
â”‚ oracle-average_precision                            0.73785 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70173 â”‚
â”‚ train-average_precision                             0.59342 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                      0.70116 â”‚
â”‚ validation-average_precision                        0.59529 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_f16fc5ce started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f16fc5ce config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.768668 â”‚
â”‚ params/colsample_bytree                      0.553555 â”‚
â”‚ params/learning_rate                        0.0126689 â”‚
â”‚ params/max_depth                                   17 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   6.10817e-06 â”‚
â”‚ params/reg_alpha                          4.03624e-07 â”‚
â”‚ params/reg_lambda                         5.15125e-07 â”‚
â”‚ params/subsample                             0.643136 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 10 RUNNING | 1 TERMINATED
Current time: 2025-04-25 16:08:25. Total running time: 9min 30s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   RUNNING                 0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          9            566.174               0.401213      0.701533                 0.59506                  0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   RUNNING                 0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_67999564 completed after 10 iterations at 2025-04-25 16:08:30. Total running time: 9min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_67999564 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    2.57313 â”‚
â”‚ time_total_s                                      568.74701 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.70523 â”‚
â”‚ id_test-average_precision                           0.60122 â”‚
â”‚ id_test-binary_error                                0.40197 â”‚
â”‚ id_test_0-auc                                       0.66338 â”‚
â”‚ id_test_0-average_precision                          0.5236 â”‚
â”‚ id_test_0-binary_error                              0.36837 â”‚
â”‚ id_test_1-auc                                       0.70487 â”‚
â”‚ id_test_1-average_precision                         0.58097 â”‚
â”‚ id_test_1-binary_error                              0.38716 â”‚
â”‚ id_test_4-auc                                       0.68677 â”‚
â”‚ id_test_4-average_precision                         0.69607 â”‚
â”‚ id_test_4-binary_error                              0.52249 â”‚
â”‚ new_ood_test-auc                                    0.68992 â”‚
â”‚ new_ood_test-average_precision                       0.7416 â”‚
â”‚ new_ood_test-binary_error                           0.58445 â”‚
â”‚ new_ood_test_1-auc                                  0.68992 â”‚
â”‚ new_ood_test_1-average_precision                     0.7416 â”‚
â”‚ new_ood_test_1-binary_error                         0.58445 â”‚
â”‚ new_train-auc                                       0.70181 â”‚
â”‚ new_train-average_precision                         0.59507 â”‚
â”‚ new_train-binary_error                              0.40121 â”‚
â”‚ ood_test-auc                                        0.68919 â”‚
â”‚ ood_test-average_precision                           0.7407 â”‚
â”‚ ood_test-binary_error                               0.58429 â”‚
â”‚ ood_test_2-auc                                      0.67631 â”‚
â”‚ ood_test_2-average_precision                        0.67232 â”‚
â”‚ ood_test_2-binary_error                             0.51538 â”‚
â”‚ ood_test_3-auc                                      0.66722 â”‚
â”‚ ood_test_3-average_precision                         0.7808 â”‚
â”‚ ood_test_3-binary_error                              0.6628 â”‚
â”‚ ood_validation-auc                                  0.68939 â”‚
â”‚ ood_validation-average_precision                    0.73987 â”‚
â”‚ ood_validation-binary_error                         0.58351 â”‚
â”‚ oracle-auc                                          0.68817 â”‚
â”‚ oracle-average_precision                            0.73946 â”‚
â”‚ oracle-binary_error                                 0.58407 â”‚
â”‚ train-auc                                           0.70181 â”‚
â”‚ train-average_precision                             0.59507 â”‚
â”‚ train-binary_error                                  0.40121 â”‚
â”‚ validation-auc                                       0.7007 â”‚
â”‚ validation-average_precision                        0.59634 â”‚
â”‚ validation-binary_error                              0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_1c4edb24 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1c4edb24 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.596556 â”‚
â”‚ params/colsample_bytree                      0.729611 â”‚
â”‚ params/learning_rate                      0.000556346 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   5.41365e-06 â”‚
â”‚ params/reg_alpha                          5.19352e-06 â”‚
â”‚ params/reg_lambda                         1.21963e-08 â”‚
â”‚ params/subsample                              0.74617 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 2 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:08:55. Total running time: 10min 0s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_876c42c0   RUNNING                 0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 2 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:09:25. Total running time: 10min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_876c42c0   RUNNING                 0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111075 seconds.
[36m(RayTrainWorker pid=1488427)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1488427)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 2 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:09:55. Total running time: 11min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_876c42c0   RUNNING                 0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121                                                                                                                        â”‚
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1488427)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_876c42c0 completed after 10 iterations at 2025-04-25 16:10:16. Total running time: 11min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_876c42c0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.86997 â”‚
â”‚ time_total_s                                      593.49025 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_2ef46010 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2ef46010 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.811766 â”‚
â”‚ params/colsample_bytree                    0.983905 â”‚
â”‚ params/learning_rate                      0.0355334 â”‚
â”‚ params/max_depth                                  7 â”‚
â”‚ params/min_child_samples                          8 â”‚
â”‚ params/min_child_weight                     41339.5 â”‚
â”‚ params/reg_alpha                          0.0912562 â”‚
â”‚ params/reg_lambda                         0.0032698 â”‚
â”‚ params/subsample                           0.627821 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 3 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:10:26. Total running time: 11min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 3 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:10:56. Total running time: 12min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_382bb831   RUNNING                 0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091849 seconds.
[36m(RayTrainWorker pid=1490576)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1490576)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.215669 seconds.
[36m(RayTrainWorker pid=1494084)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1494084)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 10x across cluster][0m
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 10x across cluster][0m
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1490576)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_382bb831 completed after 1 iterations at 2025-04-25 16:11:23. Total running time: 12min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_382bb831 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          626.217 â”‚
â”‚ time_total_s                              626.217 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_f970a727 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f970a727 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.722537 â”‚
â”‚ params/colsample_bytree                      0.551055 â”‚
â”‚ params/learning_rate                        0.0466036 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                         41181 â”‚
â”‚ params/reg_alpha                          0.000152476 â”‚
â”‚ params/reg_lambda                            0.527264 â”‚
â”‚ params/subsample                             0.517158 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial status: 4 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:11:26. Total running time: 12min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0ab5550e   RUNNING                 0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_0ab5550e completed after 1 iterations at 2025-04-25 16:11:28. Total running time: 12min 33s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0ab5550e result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          610.482 â”‚
â”‚ time_total_s                              610.482 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6479 â”‚
â”‚ id_test-average_precision                 0.51312 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.61638 â”‚
â”‚ id_test_0-average_precision               0.44807 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.66099 â”‚
â”‚ id_test_1-average_precision               0.50951 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.61505 â”‚
â”‚ id_test_4-average_precision               0.60364 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                           0.6057 â”‚
â”‚ new_ood_test-average_precision              0.656 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                         0.6057 â”‚
â”‚ new_ood_test_1-average_precision            0.656 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.64063 â”‚
â”‚ new_train-average_precision                0.5064 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.60497 â”‚
â”‚ ood_test-average_precision                0.65537 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.62687 â”‚
â”‚ ood_test_2-average_precision              0.60842 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.59521 â”‚
â”‚ ood_test_3-average_precision              0.72012 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.60479 â”‚
â”‚ ood_validation-average_precision           0.6542 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.60395 â”‚
â”‚ oracle-average_precision                  0.65448 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.64063 â”‚
â”‚ train-average_precision                    0.5064 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.64259 â”‚
â”‚ validation-average_precision              0.50965 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_5e3069a8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5e3069a8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.53918 â”‚
â”‚ params/colsample_bytree                      0.705943 â”‚
â”‚ params/learning_rate                       0.00106088 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                     0.0172776 â”‚
â”‚ params/reg_alpha                          3.50454e-06 â”‚
â”‚ params/reg_lambda                         0.000103861 â”‚
â”‚ params/subsample                             0.741189 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1494084)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial status: 5 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:11:56. Total running time: 13min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106901 seconds.
[36m(RayTrainWorker pid=1496174)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1496174)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 5 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:12:26. Total running time: 13min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c6c17020   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1496174)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_c6c17020 completed after 4 iterations at 2025-04-25 16:12:35. Total running time: 13min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c6c17020 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.81363 â”‚
â”‚ time_total_s                              650.196 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.70469 â”‚
â”‚ id_test-average_precision                 0.59678 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66566 â”‚
â”‚ id_test_0-average_precision               0.52255 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70471 â”‚
â”‚ id_test_1-average_precision               0.57709 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68532 â”‚
â”‚ id_test_4-average_precision               0.69209 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68891 â”‚
â”‚ new_ood_test-average_precision            0.73871 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68891 â”‚
â”‚ new_ood_test_1-average_precision          0.73871 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70129 â”‚
â”‚ new_train-average_precision               0.59011 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                               0.6882 â”‚
â”‚ ood_test-average_precision                0.73775 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                             0.6771 â”‚
â”‚ ood_test_2-average_precision              0.67066 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66537 â”‚
â”‚ ood_test_3-average_precision              0.77705 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68818 â”‚
â”‚ ood_validation-average_precision          0.73713 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68719 â”‚
â”‚ oracle-average_precision                   0.7364 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70129 â”‚
â”‚ train-average_precision                   0.59011 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70028 â”‚
â”‚ validation-average_precision              0.59193 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_2259c7ba started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2259c7ba config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.803075 â”‚
â”‚ params/colsample_bytree                       0.71708 â”‚
â”‚ params/learning_rate                      0.000306402 â”‚
â”‚ params/max_depth                                   14 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0131405 â”‚
â”‚ params/reg_alpha                           0.00116657 â”‚
â”‚ params/reg_lambda                         1.41736e-07 â”‚
â”‚ params/subsample                             0.703283 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086838 seconds.
[36m(RayTrainWorker pid=1501342)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 6 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:12:56. Total running time: 14min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ebe8995a   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1501342)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.347654 seconds.
[36m(RayTrainWorker pid=1502600)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1502600)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial LightGBMTrainer_ebe8995a completed after 4 iterations at 2025-04-25 16:13:23. Total running time: 14min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ebe8995a result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           2.9032 â”‚
â”‚ time_total_s                              667.416 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69657 â”‚
â”‚ id_test-average_precision                 0.59878 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66389 â”‚
â”‚ id_test_0-average_precision               0.52694 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69785 â”‚
â”‚ id_test_1-average_precision               0.58386 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6759 â”‚
â”‚ id_test_4-average_precision               0.68935 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68289 â”‚
â”‚ new_ood_test-average_precision            0.74053 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68289 â”‚
â”‚ new_ood_test_1-average_precision          0.74053 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69262 â”‚
â”‚ new_train-average_precision               0.59262 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68245 â”‚
â”‚ ood_test-average_precision                0.73986 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67164 â”‚
â”‚ ood_test_2-average_precision              0.67407 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66416 â”‚
â”‚ ood_test_3-average_precision               0.7838 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68244 â”‚
â”‚ ood_validation-average_precision          0.74065 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68185 â”‚
â”‚ oracle-average_precision                  0.73894 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69262 â”‚
â”‚ train-average_precision                   0.59262 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69048 â”‚
â”‚ validation-average_precision              0.59239 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_708d9519 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_708d9519 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.703184 â”‚
â”‚ params/colsample_bytree                      0.687447 â”‚
â”‚ params/learning_rate                         0.038339 â”‚
â”‚ params/max_depth                                   21 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                        197.21 â”‚
â”‚ params/reg_alpha                          8.53002e-06 â”‚
â”‚ params/reg_lambda                         3.04949e-08 â”‚
â”‚ params/subsample                             0.993056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 7 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:13:26. Total running time: 14min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121848 seconds.
[36m(RayTrainWorker pid=1504379)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1504379)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1502600)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
Trial status: 7 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:13:56. Total running time: 15min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_dd34c228   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489            1            678.972               0.401213      0.688478                 0.575948                 0.401213 â”‚
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1504379)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184047 seconds.
[36m(RayTrainWorker pid=1513997)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1513997)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial LightGBMTrainer_dd34c228 completed after 10 iterations at 2025-04-25 16:14:15. Total running time: 15min 20s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_dd34c228 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    1.26073 â”‚
â”‚ time_total_s                                      699.68852 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                          0.7124 â”‚
â”‚ id_test-average_precision                            0.6128 â”‚
â”‚ id_test-binary_error                                0.33447 â”‚
â”‚ id_test_0-auc                                       0.67333 â”‚
â”‚ id_test_0-average_precision                         0.54619 â”‚
â”‚ id_test_0-binary_error                              0.34278 â”‚
â”‚ id_test_1-auc                                       0.71248 â”‚
â”‚ id_test_1-average_precision                         0.59533 â”‚
â”‚ id_test_1-binary_error                               0.3303 â”‚
â”‚ id_test_4-auc                                       0.69103 â”‚
â”‚ id_test_4-average_precision                         0.70218 â”‚
â”‚ id_test_4-binary_error                              0.36215 â”‚
â”‚ new_ood_test-auc                                    0.69562 â”‚
â”‚ new_ood_test-average_precision                      0.74705 â”‚
â”‚ new_ood_test-binary_error                           0.39031 â”‚
â”‚ new_ood_test_1-auc                                  0.69562 â”‚
â”‚ new_ood_test_1-average_precision                    0.74705 â”‚
â”‚ new_ood_test_1-binary_error                         0.39031 â”‚
â”‚ new_train-auc                                       0.71043 â”‚
â”‚ new_train-average_precision                         0.60801 â”‚
â”‚ new_train-binary_error                              0.33593 â”‚
â”‚ ood_test-auc                                        0.69508 â”‚
â”‚ ood_test-average_precision                          0.74621 â”‚
â”‚ ood_test-binary_error                               0.39046 â”‚
â”‚ ood_test_2-auc                                      0.68434 â”‚
â”‚ ood_test_2-average_precision                        0.68272 â”‚
â”‚ ood_test_2-binary_error                             0.40607 â”‚
â”‚ ood_test_3-auc                                      0.67191 â”‚
â”‚ ood_test_3-average_precision                        0.78491 â”‚
â”‚ ood_test_3-binary_error                             0.37268 â”‚
â”‚ ood_validation-auc                                  0.69531 â”‚
â”‚ ood_validation-average_precision                    0.74546 â”‚
â”‚ ood_validation-binary_error                         0.38815 â”‚
â”‚ oracle-auc                                          0.69434 â”‚
â”‚ oracle-average_precision                            0.74504 â”‚
â”‚ oracle-binary_error                                 0.39067 â”‚
â”‚ train-auc                                           0.71043 â”‚
â”‚ train-average_precision                             0.60801 â”‚
â”‚ train-binary_error                                  0.33593 â”‚
â”‚ validation-auc                                      0.70769 â”‚
â”‚ validation-average_precision                        0.60815 â”‚
â”‚ validation-binary_error                             0.33685 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_efa753b8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_efa753b8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.604319 â”‚
â”‚ params/colsample_bytree                      0.621564 â”‚
â”‚ params/learning_rate                      2.58761e-05 â”‚
â”‚ params/max_depth                                   24 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.22199e-08 â”‚
â”‚ params/reg_alpha                          1.17838e-06 â”‚
â”‚ params/reg_lambda                          0.00859442 â”‚
â”‚ params/subsample                             0.953705 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 8 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:14:26. Total running time: 15min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8849c856   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        7            681.237               0.329905      0.716401                 0.617099                 0.329905 â”‚
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial LightGBMTrainer_8849c856 completed after 10 iterations at 2025-04-25 16:14:41. Total running time: 15min 46s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8849c856 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    3.55386 â”‚
â”‚ time_total_s                                      697.33736 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71728 â”‚
â”‚ id_test-average_precision                           0.62051 â”‚
â”‚ id_test-binary_error                                0.32837 â”‚
â”‚ id_test_0-auc                                       0.66655 â”‚
â”‚ id_test_0-average_precision                          0.5324 â”‚
â”‚ id_test_0-binary_error                              0.34461 â”‚
â”‚ id_test_1-auc                                       0.71698 â”‚
â”‚ id_test_1-average_precision                         0.60221 â”‚
â”‚ id_test_1-binary_error                                0.324 â”‚
â”‚ id_test_4-auc                                       0.70012 â”‚
â”‚ id_test_4-average_precision                          0.7149 â”‚
â”‚ id_test_4-binary_error                              0.35476 â”‚
â”‚ new_ood_test-auc                                    0.69883 â”‚
â”‚ new_ood_test-average_precision                      0.75156 â”‚
â”‚ new_ood_test-binary_error                           0.36949 â”‚
â”‚ new_ood_test_1-auc                                  0.69883 â”‚
â”‚ new_ood_test_1-average_precision                    0.75156 â”‚
â”‚ new_ood_test_1-binary_error                         0.36949 â”‚
â”‚ new_train-auc                                       0.71844 â”‚
â”‚ new_train-average_precision                          0.6206 â”‚
â”‚ new_train-binary_error                              0.32813 â”‚
â”‚ ood_test-auc                                        0.69836 â”‚
â”‚ ood_test-average_precision                          0.75112 â”‚
â”‚ ood_test-binary_error                               0.36979 â”‚
â”‚ ood_test_2-auc                                      0.68792 â”‚
â”‚ ood_test_2-average_precision                        0.68728 â”‚
â”‚ ood_test_2-binary_error                              0.3899 â”‚
â”‚ ood_test_3-auc                                      0.67533 â”‚
â”‚ ood_test_3-average_precision                        0.79085 â”‚
â”‚ ood_test_3-binary_error                             0.34689 â”‚
â”‚ ood_validation-auc                                   0.6985 â”‚
â”‚ ood_validation-average_precision                    0.74986 â”‚
â”‚ ood_validation-binary_error                         0.36791 â”‚
â”‚ oracle-auc                                           0.6977 â”‚
â”‚ oracle-average_precision                            0.75052 â”‚
â”‚ oracle-binary_error                                 0.37021 â”‚
â”‚ train-auc                                           0.71844 â”‚
â”‚ train-average_precision                              0.6206 â”‚
â”‚ train-binary_error                                  0.32813 â”‚
â”‚ validation-auc                                      0.71268 â”‚
â”‚ validation-average_precision                        0.61462 â”‚
â”‚ validation-binary_error                             0.33274 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d81ba0dc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d81ba0dc config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.637239 â”‚
â”‚ params/colsample_bytree                      0.691992 â”‚
â”‚ params/learning_rate                      0.000406627 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                      0.223195 â”‚
â”‚ params/reg_alpha                            0.0096948 â”‚
â”‚ params/reg_lambda                         2.09777e-08 â”‚
â”‚ params/subsample                             0.621653 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1513997)[0m [LightGBM] [Info] Start training from score -0.400412

Trial status: 9 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:14:56. Total running time: 16min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         2            666.109               0.338874      0.705553                 0.600776                 0.338874 â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 9 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:15:26. Total running time: 16min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f2e40a84   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         8            694.945               0.331055      0.715453                 0.616302                 0.331055 â”‚
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_f2e40a84 completed after 10 iterations at 2025-04-25 16:15:33. Total running time: 16min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f2e40a84 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    3.84145 â”‚
â”‚ time_total_s                                      703.29599 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71425 â”‚
â”‚ id_test-average_precision                            0.6141 â”‚
â”‚ id_test-binary_error                                0.33262 â”‚
â”‚ id_test_0-auc                                       0.66642 â”‚
â”‚ id_test_0-average_precision                         0.52424 â”‚
â”‚ id_test_0-binary_error                              0.34918 â”‚
â”‚ id_test_1-auc                                       0.71443 â”‚
â”‚ id_test_1-average_precision                         0.59708 â”‚
â”‚ id_test_1-binary_error                              0.32702 â”‚
â”‚ id_test_4-auc                                        0.6913 â”‚
â”‚ id_test_4-average_precision                         0.70414 â”‚
â”‚ id_test_4-binary_error                              0.36793 â”‚
â”‚ new_ood_test-auc                                    0.69706 â”‚
â”‚ new_ood_test-average_precision                      0.74923 â”‚
â”‚ new_ood_test-binary_error                           0.37058 â”‚
â”‚ new_ood_test_1-auc                                  0.69706 â”‚
â”‚ new_ood_test_1-average_precision                    0.74923 â”‚
â”‚ new_ood_test_1-binary_error                         0.37058 â”‚
â”‚ new_train-auc                                       0.71689 â”‚
â”‚ new_train-average_precision                         0.61841 â”‚
â”‚ new_train-binary_error                              0.33005 â”‚
â”‚ ood_test-auc                                        0.69676 â”‚
â”‚ ood_test-average_precision                          0.74918 â”‚
â”‚ ood_test-binary_error                               0.37073 â”‚
â”‚ ood_test_2-auc                                      0.68607 â”‚
â”‚ ood_test_2-average_precision                         0.6856 â”‚
â”‚ ood_test_2-binary_error                             0.39228 â”‚
â”‚ ood_test_3-auc                                      0.67341 â”‚
â”‚ ood_test_3-average_precision                        0.78848 â”‚
â”‚ ood_test_3-binary_error                             0.34617 â”‚
â”‚ ood_validation-auc                                  0.69694 â”‚
â”‚ ood_validation-average_precision                    0.74973 â”‚
â”‚ ood_validation-binary_error                         0.37095 â”‚
â”‚ oracle-auc                                          0.69635 â”‚
â”‚ oracle-average_precision                             0.7491 â”‚
â”‚ oracle-binary_error                                 0.37094 â”‚
â”‚ train-auc                                           0.71689 â”‚
â”‚ train-average_precision                             0.61841 â”‚
â”‚ train-binary_error                                  0.33005 â”‚
â”‚ validation-auc                                      0.71096 â”‚
â”‚ validation-average_precision                        0.61181 â”‚
â”‚ validation-binary_error                             0.33222 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_7f258857 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7f258857 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.733572 â”‚
â”‚ params/colsample_bytree                      0.819417 â”‚
â”‚ params/learning_rate                       5.2365e-05 â”‚
â”‚ params/max_depth                                   13 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.97276e-08 â”‚
â”‚ params/reg_alpha                          4.79278e-07 â”‚
â”‚ params/reg_lambda                             1.41961 â”‚
â”‚ params/subsample                             0.882547 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:15:56. Total running time: 17min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:16:26. Total running time: 17min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:16:56. Total running time: 18min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:17:26. Total running time: 18min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:17:56. Total running time: 19min 1s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:18:26. Total running time: 19min 31s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:18:57. Total running time: 20min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.649516 seconds.
[36m(RayTrainWorker pid=1529065)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115086 seconds.
[36m(RayTrainWorker pid=1528957)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1528957)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m
Trial status: 10 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:19:27. Total running time: 20min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f16fc5ce   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_1c4edb24   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 10x across cluster][0m
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 10x across cluster][0m
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1528957)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_f16fc5ce completed after 1 iterations at 2025-04-25 16:19:42. Total running time: 20min 47s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f16fc5ce result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          677.567 â”‚
â”‚ time_total_s                              677.567 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69766 â”‚
â”‚ id_test-average_precision                 0.58726 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66195 â”‚
â”‚ id_test_0-average_precision               0.51595 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70155 â”‚
â”‚ id_test_1-average_precision               0.57193 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6898 â”‚
â”‚ id_test_4-average_precision               0.69595 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67553 â”‚
â”‚ new_ood_test-average_precision            0.72674 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67553 â”‚
â”‚ new_ood_test_1-average_precision          0.72674 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69192 â”‚
â”‚ new_train-average_precision               0.57826 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67473 â”‚
â”‚ ood_test-average_precision                0.72584 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67381 â”‚
â”‚ ood_test_2-average_precision               0.6661 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66585 â”‚
â”‚ ood_test_3-average_precision              0.77744 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67437 â”‚
â”‚ ood_validation-average_precision          0.72453 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67361 â”‚
â”‚ oracle-average_precision                  0.72459 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69192 â”‚
â”‚ train-average_precision                   0.57826 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68984 â”‚
â”‚ validation-average_precision              0.57964 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d783e720 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d783e720 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.994394 â”‚
â”‚ params/colsample_bytree                      0.917927 â”‚
â”‚ params/learning_rate                         0.969558 â”‚
â”‚ params/max_depth                                   28 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    1.0684e-06 â”‚
â”‚ params/reg_alpha                          1.21829e-08 â”‚
â”‚ params/reg_lambda                             35.4744 â”‚
â”‚ params/subsample                             0.809168 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1529065)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_1c4edb24 completed after 1 iterations at 2025-04-25 16:19:48. Total running time: 20min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1c4edb24 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          677.857 â”‚
â”‚ time_total_s                              677.857 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d7e0cfeb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d7e0cfeb config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.959597 â”‚
â”‚ params/colsample_bytree                      0.914079 â”‚
â”‚ params/learning_rate                         0.428903 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                     1.176e-08 â”‚
â”‚ params/reg_alpha                          1.39166e-08 â”‚
â”‚ params/reg_lambda                           0.0574304 â”‚
â”‚ params/subsample                             0.515165 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 12 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:19:57. Total running time: 21min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8           41339.5                    0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2           41181                      0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16               0.0172776              0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8               0.0131405              0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64             197.21                   0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 7 more TERMINATED
Trial status: 12 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:20:27. Total running time: 21min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8           41339.5                    0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2           41181                      0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16               0.0172776              0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8               0.0131405              0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64             197.21                   0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 7 more TERMINATED
Trial status: 12 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:20:57. Total running time: 22min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8           41339.5                    0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2           41181                      0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16               0.0172776              0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8               0.0131405              0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64             197.21                   0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 7 more TERMINATED
Trial status: 12 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:21:27. Total running time: 22min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8           41339.5                    0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2           41181                      0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16               0.0172776              0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8               0.0131405              0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64             197.21                   0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 7 more TERMINATED
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406720 seconds.
[36m(RayTrainWorker pid=1549826)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1549826)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 12 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:21:57. Total running time: 23min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2ef46010   RUNNING                 0.0355334                          8           41339.5                    0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2           41181                      0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16               0.0172776              0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8               0.0131405              0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64             197.21                   0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 7 more TERMINATED
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1549826)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.331137 seconds.
[36m(RayTrainWorker pid=1551377)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1551377)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m

Trial LightGBMTrainer_2ef46010 completed after 4 iterations at 2025-04-25 16:22:12. Total running time: 23min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2ef46010 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.68385 â”‚
â”‚ time_total_s                              715.454 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71007 â”‚
â”‚ id_test-average_precision                 0.60927 â”‚
â”‚ id_test-binary_error                      0.34038 â”‚
â”‚ id_test_0-auc                             0.67875 â”‚
â”‚ id_test_0-average_precision               0.54622 â”‚
â”‚ id_test_0-binary_error                    0.33364 â”‚
â”‚ id_test_1-auc                             0.70952 â”‚
â”‚ id_test_1-average_precision               0.58958 â”‚
â”‚ id_test_1-binary_error                    0.33673 â”‚
â”‚ id_test_4-auc                             0.68858 â”‚
â”‚ id_test_4-average_precision               0.69885 â”‚
â”‚ id_test_4-binary_error                    0.36954 â”‚
â”‚ new_ood_test-auc                          0.69324 â”‚
â”‚ new_ood_test-average_precision             0.7441 â”‚
â”‚ new_ood_test-binary_error                   0.406 â”‚
â”‚ new_ood_test_1-auc                        0.69324 â”‚
â”‚ new_ood_test_1-average_precision           0.7441 â”‚
â”‚ new_ood_test_1-binary_error                 0.406 â”‚
â”‚ new_train-auc                             0.70711 â”‚
â”‚ new_train-average_precision               0.60333 â”‚
â”‚ new_train-binary_error                    0.34128 â”‚
â”‚ ood_test-auc                              0.69262 â”‚
â”‚ ood_test-average_precision                0.74313 â”‚
â”‚ ood_test-binary_error                      0.4061 â”‚
â”‚ ood_test_2-auc                            0.68174 â”‚
â”‚ ood_test_2-average_precision               0.6792 â”‚
â”‚ ood_test_2-binary_error                   0.42019 â”‚
â”‚ ood_test_3-auc                            0.66819 â”‚
â”‚ ood_test_3-average_precision              0.78074 â”‚
â”‚ ood_test_3-binary_error                   0.39006 â”‚
â”‚ ood_validation-auc                        0.69266 â”‚
â”‚ ood_validation-average_precision          0.74226 â”‚
â”‚ ood_validation-binary_error                0.4039 â”‚
â”‚ oracle-auc                                0.69177 â”‚
â”‚ oracle-average_precision                  0.74179 â”‚
â”‚ oracle-binary_error                       0.40625 â”‚
â”‚ train-auc                                 0.70711 â”‚
â”‚ train-average_precision                   0.60333 â”‚
â”‚ train-binary_error                        0.34128 â”‚
â”‚ validation-auc                            0.70622 â”‚
â”‚ validation-average_precision               0.6055 â”‚
â”‚ validation-binary_error                   0.34121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_31bee9ea started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_31bee9ea config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.866885 â”‚
â”‚ params/colsample_bytree                      0.893839 â”‚
â”‚ params/learning_rate                           0.2008 â”‚
â”‚ params/max_depth                                   22 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                   7.92478e-05 â”‚
â”‚ params/reg_alpha                          7.90088e-08 â”‚
â”‚ params/reg_lambda                             64.7894 â”‚
â”‚ params/subsample                             0.829095 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079142 seconds.
[36m(RayTrainWorker pid=1551466)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1551466)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial status: 13 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:22:27. Total running time: 23min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_f970a727   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_5e3069a8   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 8 more TERMINATED
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1551377)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_f970a727 completed after 1 iterations at 2025-04-25 16:22:28. Total running time: 23min 33s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f970a727 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          665.011 â”‚
â”‚ time_total_s                              665.011 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d2fc64b0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d2fc64b0 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.873135 â”‚
â”‚ params/colsample_bytree                      0.999599 â”‚
â”‚ params/learning_rate                       0.00524715 â”‚
â”‚ params/max_depth                                   -1 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   4.75495e-07 â”‚
â”‚ params/reg_alpha                           0.00108905 â”‚
â”‚ params/reg_lambda                           0.0308342 â”‚
â”‚ params/subsample                             0.563555 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_5e3069a8 completed after 1 iterations at 2025-04-25 16:22:44. Total running time: 23min 49s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5e3069a8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          676.067 â”‚
â”‚ time_total_s                              676.067 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6479 â”‚
â”‚ id_test-average_precision                 0.51312 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.61638 â”‚
â”‚ id_test_0-average_precision               0.44807 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.66099 â”‚
â”‚ id_test_1-average_precision               0.50951 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.61505 â”‚
â”‚ id_test_4-average_precision               0.60364 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                           0.6057 â”‚
â”‚ new_ood_test-average_precision              0.656 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                         0.6057 â”‚
â”‚ new_ood_test_1-average_precision            0.656 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.64063 â”‚
â”‚ new_train-average_precision                0.5064 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.60497 â”‚
â”‚ ood_test-average_precision                0.65537 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.62687 â”‚
â”‚ ood_test_2-average_precision              0.60842 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.59521 â”‚
â”‚ ood_test_3-average_precision              0.72012 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.60479 â”‚
â”‚ ood_validation-average_precision           0.6542 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.60395 â”‚
â”‚ oracle-average_precision                  0.65448 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.64063 â”‚
â”‚ train-average_precision                    0.5064 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.64259 â”‚
â”‚ validation-average_precision              0.50965 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1551466)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_d733d922 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d733d922 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.981189 â”‚
â”‚ params/colsample_bytree                      0.783773 â”‚
â”‚ params/learning_rate                         0.164328 â”‚
â”‚ params/max_depth                                    3 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                   0.000103335 â”‚
â”‚ params/reg_alpha                            0.0812618 â”‚
â”‚ params/reg_lambda                         0.000325247 â”‚
â”‚ params/subsample                             0.887153 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 15 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:22:57. Total running time: 24min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 10 more TERMINATED
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.180133 seconds.
[36m(RayTrainWorker pid=1554509)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1554509)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 15 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:23:27. Total running time: 24min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_2259c7ba   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 10 more TERMINATED
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1554509)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_2259c7ba completed after 1 iterations at 2025-04-25 16:23:43. Total running time: 24min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_2259c7ba result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           668.09 â”‚
â”‚ time_total_s                               668.09 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69401 â”‚
â”‚ id_test-average_precision                 0.58447 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66832 â”‚
â”‚ id_test_0-average_precision               0.51552 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69778 â”‚
â”‚ id_test_1-average_precision               0.56939 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68673 â”‚
â”‚ id_test_4-average_precision               0.69257 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67239 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67239 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68854 â”‚
â”‚ new_train-average_precision               0.57584 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67168 â”‚
â”‚ ood_test-average_precision                0.72399 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67132 â”‚
â”‚ ood_test_2-average_precision              0.66463 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66351 â”‚
â”‚ ood_test_3-average_precision              0.77578 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67191 â”‚
â”‚ ood_validation-average_precision          0.72344 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67069 â”‚
â”‚ oracle-average_precision                  0.72262 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68854 â”‚
â”‚ train-average_precision                   0.57584 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68669 â”‚
â”‚ validation-average_precision              0.57768 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_c74839c4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c74839c4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.957726 â”‚
â”‚ params/colsample_bytree                      0.892371 â”‚
â”‚ params/learning_rate                        0.0108039 â”‚
â”‚ params/max_depth                                   20 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                       1.02432 â”‚
â”‚ params/reg_alpha                           0.00406788 â”‚
â”‚ params/reg_lambda                         2.53758e-05 â”‚
â”‚ params/subsample                             0.692643 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 16 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:23:57. Total running time: 25min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_708d9519   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 11 more TERMINATED
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058040 seconds.
[36m(RayTrainWorker pid=1555870)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1555870)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1555870)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_708d9519 completed after 1 iterations at 2025-04-25 16:24:27. Total running time: 25min 32s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_708d9519 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          664.644 â”‚
â”‚ time_total_s                              664.644 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.67312 â”‚
â”‚ id_test-average_precision                 0.56543 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.63924 â”‚
â”‚ id_test_0-average_precision               0.48628 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.67384 â”‚
â”‚ id_test_1-average_precision               0.54893 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.67256 â”‚
â”‚ id_test_4-average_precision               0.67788 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.66524 â”‚
â”‚ new_ood_test-average_precision            0.71958 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.66524 â”‚
â”‚ new_ood_test_1-average_precision          0.71958 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.67098 â”‚
â”‚ new_train-average_precision               0.56172 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.66516 â”‚
â”‚ ood_test-average_precision                 0.7195 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.65817 â”‚
â”‚ ood_test_2-average_precision              0.65505 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.65683 â”‚
â”‚ ood_test_3-average_precision              0.77198 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.66703 â”‚
â”‚ ood_validation-average_precision          0.72249 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66504 â”‚
â”‚ oracle-average_precision                  0.71939 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.67098 â”‚
â”‚ train-average_precision                   0.56172 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.66745 â”‚
â”‚ validation-average_precision              0.55905 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 17 TERMINATED | 9 RUNNING
Current time: 2025-04-25 16:24:27. Total running time: 25min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
4 more RUNNING, 12 more TERMINATED

Trial LightGBMTrainer_b83ad2d4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b83ad2d4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.849415 â”‚
â”‚ params/colsample_bytree                      0.952761 â”‚
â”‚ params/learning_rate                          0.34828 â”‚
â”‚ params/max_depth                                    1 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                   3.46644e-07 â”‚
â”‚ params/reg_alpha                          8.71542e-08 â”‚
â”‚ params/reg_lambda                            0.103845 â”‚
â”‚ params/subsample                              0.84732 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 17 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:24:57. Total running time: 26min 2s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 12 more TERMINATED
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.303853 seconds.
[36m(RayTrainWorker pid=1578159)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.207683 seconds.
[36m(RayTrainWorker pid=1572772)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1572772)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1578159)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
Trial status: 17 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:25:27. Total running time: 26min 32s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_efa753b8   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_d81ba0dc   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08        1            644.168               0.352704      0.69193                  0.578256                 0.352704 â”‚
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 12 more TERMINATED
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1572772)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial LightGBMTrainer_efa753b8 completed after 1 iterations at 2025-04-25 16:25:33. Total running time: 26min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_efa753b8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          677.053 â”‚
â”‚ time_total_s                              677.053 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69429 â”‚
â”‚ id_test-average_precision                 0.58483 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66896 â”‚
â”‚ id_test_0-average_precision               0.51676 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69791 â”‚
â”‚ id_test_1-average_precision               0.56968 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68765 â”‚
â”‚ id_test_4-average_precision               0.69283 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67225 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67225 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68848 â”‚
â”‚ new_train-average_precision               0.57595 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67155 â”‚
â”‚ ood_test-average_precision                0.72397 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67102 â”‚
â”‚ ood_test_2-average_precision              0.66454 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66332 â”‚
â”‚ ood_test_3-average_precision               0.7757 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67201 â”‚
â”‚ ood_validation-average_precision          0.72367 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67057 â”‚
â”‚ oracle-average_precision                  0.72259 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68848 â”‚
â”‚ train-average_precision                   0.57595 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68584 â”‚
â”‚ validation-average_precision              0.57733 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6b17a432 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6b17a432 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.952287 â”‚
â”‚ params/colsample_bytree                      0.853667 â”‚
â”‚ params/learning_rate                        0.0878197 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                   1.36874e-05 â”‚
â”‚ params/reg_alpha                              1.62106 â”‚
â”‚ params/reg_lambda                             18.1917 â”‚
â”‚ params/subsample                             0.775132 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_d81ba0dc completed after 10 iterations at 2025-04-25 16:25:54. Total running time: 27min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d81ba0dc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    7.43887 â”‚
â”‚ time_total_s                                      671.44069 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71776 â”‚
â”‚ id_test-average_precision                           0.62189 â”‚
â”‚ id_test-binary_error                                0.32911 â”‚
â”‚ id_test_0-auc                                       0.67609 â”‚
â”‚ id_test_0-average_precision                         0.55228 â”‚
â”‚ id_test_0-binary_error                              0.34552 â”‚
â”‚ id_test_1-auc                                       0.71722 â”‚
â”‚ id_test_1-average_precision                         0.60394 â”‚
â”‚ id_test_1-binary_error                              0.32478 â”‚
â”‚ id_test_4-auc                                       0.69996 â”‚
â”‚ id_test_4-average_precision                         0.71404 â”‚
â”‚ id_test_4-binary_error                              0.35508 â”‚
â”‚ new_ood_test-auc                                    0.69889 â”‚
â”‚ new_ood_test-average_precision                       0.7519 â”‚
â”‚ new_ood_test-binary_error                           0.36741 â”‚
â”‚ new_ood_test_1-auc                                  0.69889 â”‚
â”‚ new_ood_test_1-average_precision                     0.7519 â”‚
â”‚ new_ood_test_1-binary_error                         0.36741 â”‚
â”‚ new_train-auc                                       0.71853 â”‚
â”‚ new_train-average_precision                         0.62023 â”‚
â”‚ new_train-binary_error                              0.32777 â”‚
â”‚ ood_test-auc                                        0.69826 â”‚
â”‚ ood_test-average_precision                          0.75144 â”‚
â”‚ ood_test-binary_error                               0.36788 â”‚
â”‚ ood_test_2-auc                                      0.68799 â”‚
â”‚ ood_test_2-average_precision                        0.68761 â”‚
â”‚ ood_test_2-binary_error                             0.38912 â”‚
â”‚ ood_test_3-auc                                      0.67496 â”‚
â”‚ ood_test_3-average_precision                        0.79121 â”‚
â”‚ ood_test_3-binary_error                             0.34369 â”‚
â”‚ ood_validation-auc                                   0.6986 â”‚
â”‚ ood_validation-average_precision                    0.75122 â”‚
â”‚ ood_validation-binary_error                         0.36724 â”‚
â”‚ oracle-auc                                          0.69739 â”‚
â”‚ oracle-average_precision                             0.7508 â”‚
â”‚ oracle-binary_error                                 0.36854 â”‚
â”‚ train-auc                                           0.71853 â”‚
â”‚ train-average_precision                             0.62023 â”‚
â”‚ train-binary_error                                  0.32777 â”‚
â”‚ validation-auc                                      0.71361 â”‚
â”‚ validation-average_precision                        0.61476 â”‚
â”‚ validation-binary_error                             0.33056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_c74f6e10 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c74f6e10 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.552012 â”‚
â”‚ params/colsample_bytree                     0.608417 â”‚
â”‚ params/learning_rate                      0.00225169 â”‚
â”‚ params/max_depth                                  25 â”‚
â”‚ params/min_child_samples                           2 â”‚
â”‚ params/min_child_weight                      2.55273 â”‚
â”‚ params/reg_alpha                           0.0168175 â”‚
â”‚ params/reg_lambda                           0.391092 â”‚
â”‚ params/subsample                            0.781356 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 19 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:25:58. Total running time: 27min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 14 more TERMINATED
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118781 seconds.
[36m(RayTrainWorker pid=1579532)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1579532)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 19 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:26:28. Total running time: 27min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 14 more TERMINATED
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1579532)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 19 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:26:58. Total running time: 28min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7f258857   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961            6            681.605               0.33252       0.713719                 0.613417                 0.33252  â”‚
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 14 more TERMINATED

Trial LightGBMTrainer_7f258857 completed after 10 iterations at 2025-04-25 16:27:06. Total running time: 28min 11s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7f258857 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     1.0971 â”‚
â”‚ time_total_s                                      690.30919 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71425 â”‚
â”‚ id_test-average_precision                            0.6141 â”‚
â”‚ id_test-binary_error                                0.33262 â”‚
â”‚ id_test_0-auc                                       0.66642 â”‚
â”‚ id_test_0-average_precision                         0.52424 â”‚
â”‚ id_test_0-binary_error                              0.34918 â”‚
â”‚ id_test_1-auc                                       0.71443 â”‚
â”‚ id_test_1-average_precision                         0.59708 â”‚
â”‚ id_test_1-binary_error                              0.32702 â”‚
â”‚ id_test_4-auc                                        0.6913 â”‚
â”‚ id_test_4-average_precision                         0.70414 â”‚
â”‚ id_test_4-binary_error                              0.36793 â”‚
â”‚ new_ood_test-auc                                    0.69706 â”‚
â”‚ new_ood_test-average_precision                      0.74923 â”‚
â”‚ new_ood_test-binary_error                           0.37058 â”‚
â”‚ new_ood_test_1-auc                                  0.69706 â”‚
â”‚ new_ood_test_1-average_precision                    0.74923 â”‚
â”‚ new_ood_test_1-binary_error                         0.37058 â”‚
â”‚ new_train-auc                                       0.71689 â”‚
â”‚ new_train-average_precision                         0.61841 â”‚
â”‚ new_train-binary_error                              0.33005 â”‚
â”‚ ood_test-auc                                        0.69676 â”‚
â”‚ ood_test-average_precision                          0.74918 â”‚
â”‚ ood_test-binary_error                               0.37073 â”‚
â”‚ ood_test_2-auc                                      0.68607 â”‚
â”‚ ood_test_2-average_precision                         0.6856 â”‚
â”‚ ood_test_2-binary_error                             0.39228 â”‚
â”‚ ood_test_3-auc                                      0.67341 â”‚
â”‚ ood_test_3-average_precision                        0.78848 â”‚
â”‚ ood_test_3-binary_error                             0.34617 â”‚
â”‚ ood_validation-auc                                  0.69694 â”‚
â”‚ ood_validation-average_precision                    0.74973 â”‚
â”‚ ood_validation-binary_error                         0.37095 â”‚
â”‚ oracle-auc                                          0.69635 â”‚
â”‚ oracle-average_precision                             0.7491 â”‚
â”‚ oracle-binary_error                                 0.37094 â”‚
â”‚ train-auc                                           0.71689 â”‚
â”‚ train-average_precision                             0.61841 â”‚
â”‚ train-binary_error                                  0.33005 â”‚
â”‚ validation-auc                                      0.71096 â”‚
â”‚ validation-average_precision                        0.61181 â”‚
â”‚ validation-binary_error                             0.33222 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_249f3f8f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_249f3f8f config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.582712 â”‚
â”‚ params/colsample_bytree                      0.506629 â”‚
â”‚ params/learning_rate                      1.15575e-05 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                      0.476108 â”‚
â”‚ params/reg_alpha                           0.00882842 â”‚
â”‚ params/reg_lambda                          0.00342848 â”‚
â”‚ params/subsample                             0.570887 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:27:28. Total running time: 28min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:27:58. Total running time: 29min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:28:28. Total running time: 29min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:28:58. Total running time: 30min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:29:28. Total running time: 30min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:29:58. Total running time: 31min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
Trial status: 20 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:30:28. Total running time: 31min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d783e720   RUNNING                 0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744                                                                                                                         â”‚
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 15 more TERMINATED
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080038 seconds.
[36m(RayTrainWorker pid=1600167)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1600167)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1600167)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d783e720 completed after 1 iterations at 2025-04-25 16:30:57. Total running time: 32min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d783e720 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          674.894 â”‚
â”‚ time_total_s                              674.894 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69766 â”‚
â”‚ id_test-average_precision                 0.58726 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66195 â”‚
â”‚ id_test_0-average_precision               0.51595 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70155 â”‚
â”‚ id_test_1-average_precision               0.57193 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6898 â”‚
â”‚ id_test_4-average_precision               0.69595 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67553 â”‚
â”‚ new_ood_test-average_precision            0.72674 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67553 â”‚
â”‚ new_ood_test_1-average_precision          0.72674 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69192 â”‚
â”‚ new_train-average_precision               0.57826 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67473 â”‚
â”‚ ood_test-average_precision                0.72584 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67381 â”‚
â”‚ ood_test_2-average_precision               0.6661 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66585 â”‚
â”‚ ood_test_3-average_precision              0.77744 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67437 â”‚
â”‚ ood_validation-average_precision          0.72453 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67361 â”‚
â”‚ oracle-average_precision                  0.72459 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69192 â”‚
â”‚ train-average_precision                   0.57826 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68984 â”‚
â”‚ validation-average_precision              0.57964 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_919001a7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_919001a7 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.64991 â”‚
â”‚ params/colsample_bytree                      0.799372 â”‚
â”‚ params/learning_rate                      8.19642e-05 â”‚
â”‚ params/max_depth                                   15 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                        13.666 â”‚
â”‚ params/reg_alpha                              82.2433 â”‚
â”‚ params/reg_lambda                         7.80862e-08 â”‚
â”‚ params/subsample                             0.937946 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 21 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:30:58. Total running time: 32min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 16 more TERMINATED
Trial status: 21 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:31:28. Total running time: 32min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d7e0cfeb   RUNNING                 0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304                                                                                                                      â”‚
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 16 more TERMINATED
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093311 seconds.
[36m(RayTrainWorker pid=1600249)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1600249)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d7e0cfeb completed after 1 iterations at 2025-04-25 16:31:49. Total running time: 32min 54s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d7e0cfeb result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          720.716 â”‚
â”‚ time_total_s                              720.716 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_243f756b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_243f756b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.687784 â”‚
â”‚ params/colsample_bytree                       0.74978 â”‚
â”‚ params/learning_rate                      0.000181923 â”‚
â”‚ params/max_depth                                    4 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    0.00106125 â”‚
â”‚ params/reg_alpha                          0.000343458 â”‚
â”‚ params/reg_lambda                              10.808 â”‚
â”‚ params/subsample                             0.672682 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 22 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:31:58. Total running time: 33min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 17 more TERMINATED
Trial status: 22 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:32:28. Total running time: 33min 33s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 17 more TERMINATED
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159329 seconds.
[36m(RayTrainWorker pid=1603398)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1603398)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 22 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:32:58. Total running time: 34min 3s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_31bee9ea   RUNNING                 0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894                                                                                                                         â”‚
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 17 more TERMINATED
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1603398)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_31bee9ea completed after 4 iterations at 2025-04-25 16:33:11. Total running time: 34min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_31bee9ea result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          1.01443 â”‚
â”‚ time_total_s                              658.756 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71007 â”‚
â”‚ id_test-average_precision                 0.60927 â”‚
â”‚ id_test-binary_error                      0.34038 â”‚
â”‚ id_test_0-auc                             0.67875 â”‚
â”‚ id_test_0-average_precision               0.54622 â”‚
â”‚ id_test_0-binary_error                    0.33364 â”‚
â”‚ id_test_1-auc                             0.70952 â”‚
â”‚ id_test_1-average_precision               0.58958 â”‚
â”‚ id_test_1-binary_error                    0.33673 â”‚
â”‚ id_test_4-auc                             0.68858 â”‚
â”‚ id_test_4-average_precision               0.69885 â”‚
â”‚ id_test_4-binary_error                    0.36954 â”‚
â”‚ new_ood_test-auc                          0.69324 â”‚
â”‚ new_ood_test-average_precision             0.7441 â”‚
â”‚ new_ood_test-binary_error                   0.406 â”‚
â”‚ new_ood_test_1-auc                        0.69324 â”‚
â”‚ new_ood_test_1-average_precision           0.7441 â”‚
â”‚ new_ood_test_1-binary_error                 0.406 â”‚
â”‚ new_train-auc                             0.70711 â”‚
â”‚ new_train-average_precision               0.60333 â”‚
â”‚ new_train-binary_error                    0.34128 â”‚
â”‚ ood_test-auc                              0.69262 â”‚
â”‚ ood_test-average_precision                0.74313 â”‚
â”‚ ood_test-binary_error                      0.4061 â”‚
â”‚ ood_test_2-auc                            0.68174 â”‚
â”‚ ood_test_2-average_precision               0.6792 â”‚
â”‚ ood_test_2-binary_error                   0.42019 â”‚
â”‚ ood_test_3-auc                            0.66819 â”‚
â”‚ ood_test_3-average_precision              0.78074 â”‚
â”‚ ood_test_3-binary_error                   0.39006 â”‚
â”‚ ood_validation-auc                        0.69266 â”‚
â”‚ ood_validation-average_precision          0.74226 â”‚
â”‚ ood_validation-binary_error                0.4039 â”‚
â”‚ oracle-auc                                0.69177 â”‚
â”‚ oracle-average_precision                  0.74179 â”‚
â”‚ oracle-binary_error                       0.40625 â”‚
â”‚ train-auc                                 0.70711 â”‚
â”‚ train-average_precision                   0.60333 â”‚
â”‚ train-binary_error                        0.34128 â”‚
â”‚ validation-auc                            0.70622 â”‚
â”‚ validation-average_precision               0.6055 â”‚
â”‚ validation-binary_error                   0.34121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8a2e57f4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a2e57f4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.504082 â”‚
â”‚ params/colsample_bytree                      0.673041 â”‚
â”‚ params/learning_rate                       0.00212471 â”‚
â”‚ params/max_depth                                   29 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                       1173.54 â”‚
â”‚ params/reg_alpha                              0.11748 â”‚
â”‚ params/reg_lambda                         0.000810531 â”‚
â”‚ params/subsample                             0.733873 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.661556 seconds.
[36m(RayTrainWorker pid=1604766)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 23 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:33:29. Total running time: 34min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_d733d922   RUNNING                 0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247                                                                                                                    â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 18 more TERMINATED
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238904 seconds.
[36m(RayTrainWorker pid=1603533)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1604766)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_d733d922 completed after 1 iterations at 2025-04-25 16:33:52. Total running time: 34min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d733d922 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          667.889 â”‚
â”‚ time_total_s                              667.889 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6479 â”‚
â”‚ id_test-average_precision                 0.51312 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.61638 â”‚
â”‚ id_test_0-average_precision               0.44807 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.66099 â”‚
â”‚ id_test_1-average_precision               0.50951 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.61505 â”‚
â”‚ id_test_4-average_precision               0.60364 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                           0.6057 â”‚
â”‚ new_ood_test-average_precision              0.656 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                         0.6057 â”‚
â”‚ new_ood_test_1-average_precision            0.656 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.64063 â”‚
â”‚ new_train-average_precision                0.5064 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.60497 â”‚
â”‚ ood_test-average_precision                0.65537 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.62687 â”‚
â”‚ ood_test_2-average_precision              0.60842 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.59521 â”‚
â”‚ ood_test_3-average_precision              0.72012 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.60479 â”‚
â”‚ ood_validation-average_precision           0.6542 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.60395 â”‚
â”‚ oracle-average_precision                  0.65448 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.64063 â”‚
â”‚ train-average_precision                    0.5064 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.64259 â”‚
â”‚ validation-average_precision              0.50965 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8c1c2fa6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8c1c2fa6 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.533251 â”‚
â”‚ params/colsample_bytree                      0.626013 â”‚
â”‚ params/learning_rate                       0.00450874 â”‚
â”‚ params/max_depth                                   18 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                      0.113362 â”‚
â”‚ params/reg_alpha                          0.000144952 â”‚
â”‚ params/reg_lambda                           0.0197576 â”‚
â”‚ params/subsample                             0.597137 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial status: 24 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:33:59. Total running time: 35min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_d2fc64b0   RUNNING                 0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342                                                                                                                      â”‚
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 19 more TERMINATED
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1603533)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_d2fc64b0 completed after 1 iterations at 2025-04-25 16:34:20. Total running time: 35min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_d2fc64b0 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          711.384 â”‚
â”‚ time_total_s                              711.384 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_0df713ef started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0df713ef config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.626549 â”‚
â”‚ params/colsample_bytree                      0.864236 â”‚
â”‚ params/learning_rate                        0.0141836 â”‚
â”‚ params/max_depth                                   10 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                       14.2339 â”‚
â”‚ params/reg_alpha                            0.0233874 â”‚
â”‚ params/reg_lambda                         8.62385e-05 â”‚
â”‚ params/subsample                             0.854055 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 25 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:34:29. Total running time: 35min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 20 more TERMINATED
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115360 seconds.
[36m(RayTrainWorker pid=1610762)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1610762)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 25 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:34:59. Total running time: 36min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c74839c4   RUNNING                 0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 20 more TERMINATED
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1610762)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_c74839c4 completed after 1 iterations at 2025-04-25 16:35:08. Total running time: 36min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c74839c4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          684.814 â”‚
â”‚ time_total_s                              684.814 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69401 â”‚
â”‚ id_test-average_precision                 0.58447 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66832 â”‚
â”‚ id_test_0-average_precision               0.51552 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69778 â”‚
â”‚ id_test_1-average_precision               0.56939 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68673 â”‚
â”‚ id_test_4-average_precision               0.69257 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67239 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67239 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68854 â”‚
â”‚ new_train-average_precision               0.57584 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67168 â”‚
â”‚ ood_test-average_precision                0.72399 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67132 â”‚
â”‚ ood_test_2-average_precision              0.66463 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66351 â”‚
â”‚ ood_test_3-average_precision              0.77578 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67191 â”‚
â”‚ ood_validation-average_precision          0.72344 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67069 â”‚
â”‚ oracle-average_precision                  0.72262 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68854 â”‚
â”‚ train-average_precision                   0.57584 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68669 â”‚
â”‚ validation-average_precision              0.57768 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_12006abf started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_12006abf config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.778579 â”‚
â”‚ params/colsample_bytree                      0.647569 â”‚
â”‚ params/learning_rate                      0.000188708 â”‚
â”‚ params/max_depth                                    2 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                    0.00333306 â”‚
â”‚ params/reg_alpha                              1.10238 â”‚
â”‚ params/reg_lambda                          7.4399e-06 â”‚
â”‚ params/subsample                             0.550467 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.244268 seconds.
[36m(RayTrainWorker pid=1625096)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1625096)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 26 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:35:29. Total running time: 36min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b83ad2d4   RUNNING                 0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845                                                                                                                       â”‚
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4             13.666                   0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 21 more TERMINATED
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1625096)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_b83ad2d4 completed after 1 iterations at 2025-04-25 16:35:48. Total running time: 36min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b83ad2d4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          680.342 â”‚
â”‚ time_total_s                              680.342 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.67312 â”‚
â”‚ id_test-average_precision                 0.56543 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.63924 â”‚
â”‚ id_test_0-average_precision               0.48628 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.67384 â”‚
â”‚ id_test_1-average_precision               0.54893 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.67256 â”‚
â”‚ id_test_4-average_precision               0.67788 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.66524 â”‚
â”‚ new_ood_test-average_precision            0.71958 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.66524 â”‚
â”‚ new_ood_test_1-average_precision          0.71958 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.67098 â”‚
â”‚ new_train-average_precision               0.56172 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.66516 â”‚
â”‚ ood_test-average_precision                 0.7195 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.65817 â”‚
â”‚ ood_test_2-average_precision              0.65505 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.65683 â”‚
â”‚ ood_test_3-average_precision              0.77198 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.66703 â”‚
â”‚ ood_validation-average_precision          0.72249 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66504 â”‚
â”‚ oracle-average_precision                  0.71939 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.67098 â”‚
â”‚ train-average_precision                   0.56172 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.66745 â”‚
â”‚ validation-average_precision              0.55905 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_cb5815b7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_cb5815b7 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.905995 â”‚
â”‚ params/colsample_bytree                       0.59729 â”‚
â”‚ params/learning_rate                      1.58635e-05 â”‚
â”‚ params/max_depth                                   26 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                       249.849 â”‚
â”‚ params/reg_alpha                           0.00254682 â”‚
â”‚ params/reg_lambda                            0.154152 â”‚
â”‚ params/subsample                             0.662325 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 27 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:35:59. Total running time: 37min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4             13.666                   0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2              0.00106125              0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 22 more TERMINATED
Trial status: 27 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:36:29. Total running time: 37min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6b17a432   RUNNING                 0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917                                                                                                                         â”‚
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092                                                                                                                       â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4             13.666                   0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2              0.00106125              0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 22 more TERMINATED
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051361 seconds.
[36m(RayTrainWorker pid=1628456)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1628456)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.213665 seconds.
[36m(RayTrainWorker pid=1629548)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1629548)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 13x across cluster][0m
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 13x across cluster][0m
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1628456)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 10x across cluster][0m
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 10x across cluster][0m

Trial LightGBMTrainer_6b17a432 completed after 1 iterations at 2025-04-25 16:36:51. Total running time: 37min 56s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6b17a432 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          678.517 â”‚
â”‚ time_total_s                              678.517 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69429 â”‚
â”‚ id_test-average_precision                 0.58483 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66896 â”‚
â”‚ id_test_0-average_precision               0.51676 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69791 â”‚
â”‚ id_test_1-average_precision               0.56968 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68765 â”‚
â”‚ id_test_4-average_precision               0.69283 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67225 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67225 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68848 â”‚
â”‚ new_train-average_precision               0.57595 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67155 â”‚
â”‚ ood_test-average_precision                0.72397 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67102 â”‚
â”‚ ood_test_2-average_precision              0.66454 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66332 â”‚
â”‚ ood_test_3-average_precision               0.7757 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67201 â”‚
â”‚ ood_validation-average_precision          0.72367 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67057 â”‚
â”‚ oracle-average_precision                  0.72259 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68848 â”‚
â”‚ train-average_precision                   0.57595 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68584 â”‚
â”‚ validation-average_precision              0.57733 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_a99fea90 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a99fea90 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.502162 â”‚
â”‚ params/colsample_bytree                      0.744699 â”‚
â”‚ params/learning_rate                        0.0012354 â”‚
â”‚ params/max_depth                                   23 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                   0.000471723 â”‚
â”‚ params/reg_alpha                          2.09367e-05 â”‚
â”‚ params/reg_lambda                               97.82 â”‚
â”‚ params/subsample                              0.71882 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1629548)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 28 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:36:59. Total running time: 38min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c74f6e10   RUNNING                 0.00225169                         2               2.55273                0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092           3            662.497               0.334498      0.709936                 0.606984                 0.334498 â”‚
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16               0.476108               0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 23 more TERMINATED

Trial LightGBMTrainer_c74f6e10 completed after 10 iterations at 2025-04-25 16:37:27. Total running time: 38min 32s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c74f6e10 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    2.10896 â”‚
â”‚ time_total_s                                      689.39339 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71728 â”‚
â”‚ id_test-average_precision                           0.62051 â”‚
â”‚ id_test-binary_error                                0.32837 â”‚
â”‚ id_test_0-auc                                       0.66655 â”‚
â”‚ id_test_0-average_precision                          0.5324 â”‚
â”‚ id_test_0-binary_error                              0.34461 â”‚
â”‚ id_test_1-auc                                       0.71698 â”‚
â”‚ id_test_1-average_precision                         0.60221 â”‚
â”‚ id_test_1-binary_error                                0.324 â”‚
â”‚ id_test_4-auc                                       0.70012 â”‚
â”‚ id_test_4-average_precision                          0.7149 â”‚
â”‚ id_test_4-binary_error                              0.35476 â”‚
â”‚ new_ood_test-auc                                    0.69883 â”‚
â”‚ new_ood_test-average_precision                      0.75156 â”‚
â”‚ new_ood_test-binary_error                           0.36949 â”‚
â”‚ new_ood_test_1-auc                                  0.69883 â”‚
â”‚ new_ood_test_1-average_precision                    0.75156 â”‚
â”‚ new_ood_test_1-binary_error                         0.36949 â”‚
â”‚ new_train-auc                                       0.71844 â”‚
â”‚ new_train-average_precision                          0.6206 â”‚
â”‚ new_train-binary_error                              0.32813 â”‚
â”‚ ood_test-auc                                        0.69836 â”‚
â”‚ ood_test-average_precision                          0.75112 â”‚
â”‚ ood_test-binary_error                               0.36979 â”‚
â”‚ ood_test_2-auc                                      0.68792 â”‚
â”‚ ood_test_2-average_precision                        0.68728 â”‚
â”‚ ood_test_2-binary_error                              0.3899 â”‚
â”‚ ood_test_3-auc                                      0.67533 â”‚
â”‚ ood_test_3-average_precision                        0.79085 â”‚
â”‚ ood_test_3-binary_error                             0.34689 â”‚
â”‚ ood_validation-auc                                   0.6985 â”‚
â”‚ ood_validation-average_precision                    0.74986 â”‚
â”‚ ood_validation-binary_error                         0.36791 â”‚
â”‚ oracle-auc                                           0.6977 â”‚
â”‚ oracle-average_precision                            0.75052 â”‚
â”‚ oracle-binary_error                                 0.37021 â”‚
â”‚ train-auc                                           0.71844 â”‚
â”‚ train-average_precision                              0.6206 â”‚
â”‚ train-binary_error                                  0.32813 â”‚
â”‚ validation-auc                                      0.71268 â”‚
â”‚ validation-average_precision                        0.61462 â”‚
â”‚ validation-binary_error                             0.33274 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_7468169d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7468169d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.677438 â”‚
â”‚ params/colsample_bytree                      0.828385 â”‚
â”‚ params/learning_rate                      6.18404e-05 â”‚
â”‚ params/max_depth                                   30 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                     0.0968358 â”‚
â”‚ params/reg_alpha                              16.5048 â”‚
â”‚ params/reg_lambda                         0.000266245 â”‚
â”‚ params/subsample                             0.807332 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 29 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:37:29. Total running time: 38min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16               0.476108               0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 24 more TERMINATED
Trial status: 29 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:37:59. Total running time: 39min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16               0.476108               0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 24 more TERMINATED
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072630 seconds.
[36m(RayTrainWorker pid=1631595)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1631595)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 29 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:38:29. Total running time: 39min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_249f3f8f   RUNNING                 1.15575e-05                       16               0.476108               0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848                                                                                                                     â”‚
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 24 more TERMINATED
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1631595)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_249f3f8f completed after 10 iterations at 2025-04-25 16:38:54. Total running time: 39min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_249f3f8f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    2.38391 â”‚
â”‚ time_total_s                                      706.27333 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71425 â”‚
â”‚ id_test-average_precision                            0.6141 â”‚
â”‚ id_test-binary_error                                0.33262 â”‚
â”‚ id_test_0-auc                                       0.66642 â”‚
â”‚ id_test_0-average_precision                         0.52424 â”‚
â”‚ id_test_0-binary_error                              0.34918 â”‚
â”‚ id_test_1-auc                                       0.71443 â”‚
â”‚ id_test_1-average_precision                         0.59708 â”‚
â”‚ id_test_1-binary_error                              0.32702 â”‚
â”‚ id_test_4-auc                                        0.6913 â”‚
â”‚ id_test_4-average_precision                         0.70414 â”‚
â”‚ id_test_4-binary_error                              0.36793 â”‚
â”‚ new_ood_test-auc                                    0.69706 â”‚
â”‚ new_ood_test-average_precision                      0.74923 â”‚
â”‚ new_ood_test-binary_error                           0.37058 â”‚
â”‚ new_ood_test_1-auc                                  0.69706 â”‚
â”‚ new_ood_test_1-average_precision                    0.74923 â”‚
â”‚ new_ood_test_1-binary_error                         0.37058 â”‚
â”‚ new_train-auc                                       0.71689 â”‚
â”‚ new_train-average_precision                         0.61841 â”‚
â”‚ new_train-binary_error                              0.33005 â”‚
â”‚ ood_test-auc                                        0.69676 â”‚
â”‚ ood_test-average_precision                          0.74918 â”‚
â”‚ ood_test-binary_error                               0.37073 â”‚
â”‚ ood_test_2-auc                                      0.68607 â”‚
â”‚ ood_test_2-average_precision                         0.6856 â”‚
â”‚ ood_test_2-binary_error                             0.39228 â”‚
â”‚ ood_test_3-auc                                      0.67341 â”‚
â”‚ ood_test_3-average_precision                        0.78848 â”‚
â”‚ ood_test_3-binary_error                             0.34617 â”‚
â”‚ ood_validation-auc                                  0.69694 â”‚
â”‚ ood_validation-average_precision                    0.74973 â”‚
â”‚ ood_validation-binary_error                         0.37095 â”‚
â”‚ oracle-auc                                          0.69635 â”‚
â”‚ oracle-average_precision                             0.7491 â”‚
â”‚ oracle-binary_error                                 0.37094 â”‚
â”‚ train-auc                                           0.71689 â”‚
â”‚ train-average_precision                             0.61841 â”‚
â”‚ train-binary_error                                  0.33005 â”‚
â”‚ validation-auc                                      0.71096 â”‚
â”‚ validation-average_precision                        0.61181 â”‚
â”‚ validation-binary_error                             0.33222 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bf7b9d3b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bf7b9d3b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.623055 â”‚
â”‚ params/colsample_bytree                      0.774935 â”‚
â”‚ params/learning_rate                      0.000303917 â”‚
â”‚ params/max_depth                                    8 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   3.37759e-05 â”‚
â”‚ params/reg_alpha                             0.316246 â”‚
â”‚ params/reg_lambda                         3.12707e-07 â”‚
â”‚ params/subsample                              0.76776 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:38:59. Total running time: 40min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:39:29. Total running time: 40min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:39:59. Total running time: 41min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:40:29. Total running time: 41min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:40:59. Total running time: 42min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:41:29. Total running time: 42min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
Trial status: 30 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:41:59. Total running time: 43min 4s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_919001a7   RUNNING                 8.19642e-05                        4              13.666                  0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 25 more TERMINATED
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063791 seconds.
[36m(RayTrainWorker pid=1652230)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1652230)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1652230)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_919001a7 completed after 1 iterations at 2025-04-25 16:42:22. Total running time: 43min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_919001a7 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          684.471 â”‚
â”‚ time_total_s                              684.471 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69758 â”‚
â”‚ id_test-average_precision                 0.58723 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66195 â”‚
â”‚ id_test_0-average_precision               0.51595 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70145 â”‚
â”‚ id_test_1-average_precision               0.57189 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6898 â”‚
â”‚ id_test_4-average_precision               0.69595 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67558 â”‚
â”‚ new_ood_test-average_precision            0.72675 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67558 â”‚
â”‚ new_ood_test_1-average_precision          0.72675 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69193 â”‚
â”‚ new_train-average_precision               0.57826 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67478 â”‚
â”‚ ood_test-average_precision                0.72586 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                             0.6739 â”‚
â”‚ ood_test_2-average_precision              0.66612 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66585 â”‚
â”‚ ood_test_3-average_precision              0.77744 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67444 â”‚
â”‚ ood_validation-average_precision          0.72455 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67368 â”‚
â”‚ oracle-average_precision                  0.72461 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69193 â”‚
â”‚ train-average_precision                   0.57826 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68978 â”‚
â”‚ validation-average_precision              0.57961 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_55e23ad1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_55e23ad1 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.570524 â”‚
â”‚ params/colsample_bytree                        0.5734 â”‚
â”‚ params/learning_rate                      3.14916e-05 â”‚
â”‚ params/max_depth                                   11 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    0.00449586 â”‚
â”‚ params/reg_alpha                           0.00041493 â”‚
â”‚ params/reg_lambda                             2.75059 â”‚
â”‚ params/subsample                             0.592565 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 31 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:42:29. Total running time: 43min 34s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32               0.00333306             0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 26 more TERMINATED
Trial status: 31 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:43:00. Total running time: 44min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_243f756b   RUNNING                 0.000181923                        2               0.00106125             0.672682                    4                 0.74978                  0.687784          0.000343458          10.808                                                                                                                          â”‚
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32               0.00333306             0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 26 more TERMINATED
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070448 seconds.
[36m(RayTrainWorker pid=1653624)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1653624)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1653624)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_243f756b completed after 1 iterations at 2025-04-25 16:43:18. Total running time: 44min 23s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_243f756b result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          689.532 â”‚
â”‚ time_total_s                              689.532 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ad8c22d8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ad8c22d8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.74418 â”‚
â”‚ params/colsample_bytree                      0.500995 â”‚
â”‚ params/learning_rate                       0.00665708 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                    0.00030478 â”‚
â”‚ params/reg_alpha                              6.01063 â”‚
â”‚ params/reg_lambda                         1.41863e-06 â”‚
â”‚ params/subsample                              0.54196 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 32 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:43:30. Total running time: 44min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32               0.00333306             0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16             249.849                  0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 27 more TERMINATED
Trial status: 32 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:44:00. Total running time: 45min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32               0.00333306             0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16             249.849                  0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 27 more TERMINATED
Trial status: 32 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:44:30. Total running time: 45min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32            1173.54                   0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4               0.113362               0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_0df713ef   RUNNING                 0.0141836                          2              14.2339                 0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32               0.00333306             0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16             249.849                  0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 27 more TERMINATED
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.368583 seconds.
[36m(RayTrainWorker pid=1674062)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.651823 seconds.
[36m(RayTrainWorker pid=1655269)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1674062)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_0df713ef completed after 1 iterations at 2025-04-25 16:44:56. Total running time: 46min 1s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0df713ef result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          635.625 â”‚
â”‚ time_total_s                              635.625 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_a7780331 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a7780331 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.846097 â”‚
â”‚ params/colsample_bytree                      0.94194 â”‚
â”‚ params/learning_rate                       0.0206556 â”‚
â”‚ params/max_depth                                  16 â”‚
â”‚ params/min_child_samples                           8 â”‚
â”‚ params/min_child_weight                      7033.82 â”‚
â”‚ params/reg_alpha                          6.9489e-05 â”‚
â”‚ params/reg_lambda                            8.34741 â”‚
â”‚ params/subsample                            0.636979 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m

Trial status: 33 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:45:00. Total running time: 46min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32           1173.54                    0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531                                                                                                                    â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4              0.113362                0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32              0.00333306              0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16            249.849                   0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 28 more TERMINATED
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1655269)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 33 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:45:30. Total running time: 46min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8a2e57f4   RUNNING                 0.00212471                        32           1173.54                    0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531        3            736.282               0.346729      0.70453                  0.600281                 0.346729 â”‚
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4              0.113362                0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32              0.00333306              0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16            249.849                   0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 28 more TERMINATED

Trial LightGBMTrainer_8a2e57f4 completed after 4 iterations at 2025-04-25 16:45:30. Total running time: 46min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a2e57f4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          3.00093 â”‚
â”‚ time_total_s                              739.283 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71007 â”‚
â”‚ id_test-average_precision                 0.60927 â”‚
â”‚ id_test-binary_error                      0.34038 â”‚
â”‚ id_test_0-auc                             0.67875 â”‚
â”‚ id_test_0-average_precision               0.54622 â”‚
â”‚ id_test_0-binary_error                    0.33364 â”‚
â”‚ id_test_1-auc                             0.70952 â”‚
â”‚ id_test_1-average_precision               0.58958 â”‚
â”‚ id_test_1-binary_error                    0.33673 â”‚
â”‚ id_test_4-auc                             0.68858 â”‚
â”‚ id_test_4-average_precision               0.69885 â”‚
â”‚ id_test_4-binary_error                    0.36954 â”‚
â”‚ new_ood_test-auc                          0.69324 â”‚
â”‚ new_ood_test-average_precision             0.7441 â”‚
â”‚ new_ood_test-binary_error                   0.406 â”‚
â”‚ new_ood_test_1-auc                        0.69324 â”‚
â”‚ new_ood_test_1-average_precision           0.7441 â”‚
â”‚ new_ood_test_1-binary_error                 0.406 â”‚
â”‚ new_train-auc                             0.70711 â”‚
â”‚ new_train-average_precision               0.60333 â”‚
â”‚ new_train-binary_error                    0.34128 â”‚
â”‚ ood_test-auc                              0.69262 â”‚
â”‚ ood_test-average_precision                0.74313 â”‚
â”‚ ood_test-binary_error                      0.4061 â”‚
â”‚ ood_test_2-auc                            0.68174 â”‚
â”‚ ood_test_2-average_precision               0.6792 â”‚
â”‚ ood_test_2-binary_error                   0.42019 â”‚
â”‚ ood_test_3-auc                            0.66819 â”‚
â”‚ ood_test_3-average_precision              0.78074 â”‚
â”‚ ood_test_3-binary_error                   0.39006 â”‚
â”‚ ood_validation-auc                        0.69266 â”‚
â”‚ ood_validation-average_precision          0.74226 â”‚
â”‚ ood_validation-binary_error                0.4039 â”‚
â”‚ oracle-auc                                0.69177 â”‚
â”‚ oracle-average_precision                  0.74179 â”‚
â”‚ oracle-binary_error                       0.40625 â”‚
â”‚ train-auc                                 0.70711 â”‚
â”‚ train-average_precision                   0.60333 â”‚
â”‚ train-binary_error                        0.34128 â”‚
â”‚ validation-auc                            0.70622 â”‚
â”‚ validation-average_precision               0.6055 â”‚
â”‚ validation-binary_error                   0.34121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_90ea7a9d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_90ea7a9d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.655999 â”‚
â”‚ params/colsample_bytree                      0.807043 â”‚
â”‚ params/learning_rate                      0.000752593 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                      0.370036 â”‚
â”‚ params/reg_alpha                              67.6218 â”‚
â”‚ params/reg_lambda                         6.68211e-06 â”‚
â”‚ params/subsample                             0.927555 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 34 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:46:00. Total running time: 47min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8c1c2fa6   RUNNING                 0.00450874                         4              0.113362                0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576                                                                                                                      â”‚
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32              0.00333306              0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16            249.849                   0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 29 more TERMINATED
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095828 seconds.
[36m(RayTrainWorker pid=1665060)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1665060)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_8c1c2fa6 completed after 1 iterations at 2025-04-25 16:46:19. Total running time: 47min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8c1c2fa6 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          746.332 â”‚
â”‚ time_total_s                              746.332 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6479 â”‚
â”‚ id_test-average_precision                 0.51312 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.61638 â”‚
â”‚ id_test_0-average_precision               0.44807 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.66099 â”‚
â”‚ id_test_1-average_precision               0.50951 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.61505 â”‚
â”‚ id_test_4-average_precision               0.60364 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                           0.6057 â”‚
â”‚ new_ood_test-average_precision              0.656 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                         0.6057 â”‚
â”‚ new_ood_test_1-average_precision            0.656 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.64063 â”‚
â”‚ new_train-average_precision                0.5064 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.60497 â”‚
â”‚ ood_test-average_precision                0.65537 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.62687 â”‚
â”‚ ood_test_2-average_precision              0.60842 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.59521 â”‚
â”‚ ood_test_3-average_precision              0.72012 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.60479 â”‚
â”‚ ood_validation-average_precision           0.6542 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.60395 â”‚
â”‚ oracle-average_precision                  0.65448 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.64063 â”‚
â”‚ train-average_precision                    0.5064 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.64259 â”‚
â”‚ validation-average_precision              0.50965 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_0cd97143 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0cd97143 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.714153 â”‚
â”‚ params/colsample_bytree                     0.688227 â”‚
â”‚ params/learning_rate                      0.00214014 â”‚
â”‚ params/max_depth                                  12 â”‚
â”‚ params/min_child_samples                          16 â”‚
â”‚ params/min_child_weight                      61.7974 â”‚
â”‚ params/reg_alpha                           0.0307413 â”‚
â”‚ params/reg_lambda                           0.824774 â”‚
â”‚ params/subsample                            0.978608 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129706 seconds.
[36m(RayTrainWorker pid=1679323)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] Total Bins 368
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 14x across cluster][0m
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 14x across cluster][0m
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.255537 seconds.
[36m(RayTrainWorker pid=1678034)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial status: 35 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:46:30. Total running time: 47min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_12006abf   RUNNING                 0.000188708                       32              0.00333306              0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_cb5815b7   RUNNING                 1.58635e-05                       16            249.849                   0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152                                                                                                                       â”‚
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 30 more TERMINATED
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1678034)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial LightGBMTrainer_12006abf completed after 1 iterations at 2025-04-25 16:46:42. Total running time: 47min 47s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_12006abf result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          693.943 â”‚
â”‚ time_total_s                              693.943 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69401 â”‚
â”‚ id_test-average_precision                 0.58447 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66832 â”‚
â”‚ id_test_0-average_precision               0.51552 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69778 â”‚
â”‚ id_test_1-average_precision               0.56939 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68673 â”‚
â”‚ id_test_4-average_precision               0.69257 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67239 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67239 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68854 â”‚
â”‚ new_train-average_precision               0.57584 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67168 â”‚
â”‚ ood_test-average_precision                0.72399 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67132 â”‚
â”‚ ood_test_2-average_precision              0.66463 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66351 â”‚
â”‚ ood_test_3-average_precision              0.77578 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67191 â”‚
â”‚ ood_validation-average_precision          0.72344 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67069 â”‚
â”‚ oracle-average_precision                  0.72262 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68854 â”‚
â”‚ train-average_precision                   0.57584 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68669 â”‚
â”‚ validation-average_precision              0.57768 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_711ed9ae started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_711ed9ae config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.793338 â”‚
â”‚ params/colsample_bytree                      0.874217 â”‚
â”‚ params/learning_rate                      0.000419176 â”‚
â”‚ params/max_depth                                    5 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                       6.97643 â”‚
â”‚ params/reg_alpha                           0.00335045 â”‚
â”‚ params/reg_lambda                           0.0078045 â”‚
â”‚ params/subsample                             0.674741 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1679323)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_cb5815b7 completed after 1 iterations at 2025-04-25 16:46:48. Total running time: 47min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_cb5815b7 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          660.105 â”‚
â”‚ time_total_s                              660.105 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.67312 â”‚
â”‚ id_test-average_precision                 0.56543 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.63924 â”‚
â”‚ id_test_0-average_precision               0.48628 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.67384 â”‚
â”‚ id_test_1-average_precision               0.54893 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.67256 â”‚
â”‚ id_test_4-average_precision               0.67788 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.66524 â”‚
â”‚ new_ood_test-average_precision            0.71958 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.66524 â”‚
â”‚ new_ood_test_1-average_precision          0.71958 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.67098 â”‚
â”‚ new_train-average_precision               0.56172 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.66516 â”‚
â”‚ ood_test-average_precision                 0.7195 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.65817 â”‚
â”‚ ood_test_2-average_precision              0.65505 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.65683 â”‚
â”‚ ood_test_3-average_precision              0.77198 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.66703 â”‚
â”‚ ood_validation-average_precision          0.72249 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66504 â”‚
â”‚ oracle-average_precision                  0.71939 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.67098 â”‚
â”‚ train-average_precision                   0.56172 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.66745 â”‚
â”‚ validation-average_precision              0.55905 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bd2b95eb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd2b95eb config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.628246 â”‚
â”‚ params/colsample_bytree                      0.731458 â”‚
â”‚ params/learning_rate                      9.70933e-05 â”‚
â”‚ params/max_depth                                    9 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                     0.0241063 â”‚
â”‚ params/reg_alpha                              3.83833 â”‚
â”‚ params/reg_lambda                         1.84097e-08 â”‚
â”‚ params/subsample                             0.714905 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 37 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:47:00. Total running time: 48min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 32 more TERMINATED
Trial status: 37 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:47:30. Total running time: 48min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 32 more TERMINATED
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099275 seconds.
[36m(RayTrainWorker pid=1680865)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1680865)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 37 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:48:00. Total running time: 49min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a99fea90   RUNNING                 0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82                                                                                                                           â”‚
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 32 more TERMINATED
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1680865)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_a99fea90 completed after 1 iterations at 2025-04-25 16:48:13. Total running time: 49min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a99fea90 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          681.367 â”‚
â”‚ time_total_s                              681.367 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69429 â”‚
â”‚ id_test-average_precision                 0.58483 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66896 â”‚
â”‚ id_test_0-average_precision               0.51676 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69791 â”‚
â”‚ id_test_1-average_precision               0.56968 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68765 â”‚
â”‚ id_test_4-average_precision               0.69283 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67225 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67225 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68848 â”‚
â”‚ new_train-average_precision               0.57595 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67155 â”‚
â”‚ ood_test-average_precision                0.72397 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67102 â”‚
â”‚ ood_test_2-average_precision              0.66454 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66332 â”‚
â”‚ ood_test_3-average_precision               0.7757 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67201 â”‚
â”‚ ood_validation-average_precision          0.72367 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67057 â”‚
â”‚ oracle-average_precision                  0.72259 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68848 â”‚
â”‚ train-average_precision                   0.57595 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68584 â”‚
â”‚ validation-average_precision              0.57733 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_0ed3b06c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0ed3b06c config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.755786 â”‚
â”‚ params/colsample_bytree                      0.524227 â”‚
â”‚ params/learning_rate                        0.0199172 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   1.02572e-07 â”‚
â”‚ params/reg_alpha                          1.76495e-05 â”‚
â”‚ params/reg_lambda                          0.00136674 â”‚
â”‚ params/subsample                             0.754421 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 38 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:48:30. Total running time: 49min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 33 more TERMINATED
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.312622 seconds.
[36m(RayTrainWorker pid=1682205)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 38 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:49:00. Total running time: 50min 5s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 33 more TERMINATED
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1682205)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 38 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:49:30. Total running time: 50min 35s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7468169d   RUNNING                 6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245        8            721.372               0.329073      0.717255                 0.618245                 0.329073 â”‚
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 33 more TERMINATED

Trial LightGBMTrainer_7468169d completed after 10 iterations at 2025-04-25 16:49:40. Total running time: 50min 45s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7468169d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    3.94776 â”‚
â”‚ time_total_s                                      731.86404 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71728 â”‚
â”‚ id_test-average_precision                           0.62051 â”‚
â”‚ id_test-binary_error                                0.32837 â”‚
â”‚ id_test_0-auc                                       0.66655 â”‚
â”‚ id_test_0-average_precision                          0.5324 â”‚
â”‚ id_test_0-binary_error                              0.34461 â”‚
â”‚ id_test_1-auc                                       0.71698 â”‚
â”‚ id_test_1-average_precision                         0.60221 â”‚
â”‚ id_test_1-binary_error                                0.324 â”‚
â”‚ id_test_4-auc                                       0.70012 â”‚
â”‚ id_test_4-average_precision                          0.7149 â”‚
â”‚ id_test_4-binary_error                              0.35476 â”‚
â”‚ new_ood_test-auc                                    0.69883 â”‚
â”‚ new_ood_test-average_precision                      0.75156 â”‚
â”‚ new_ood_test-binary_error                           0.36949 â”‚
â”‚ new_ood_test_1-auc                                  0.69883 â”‚
â”‚ new_ood_test_1-average_precision                    0.75156 â”‚
â”‚ new_ood_test_1-binary_error                         0.36949 â”‚
â”‚ new_train-auc                                       0.71844 â”‚
â”‚ new_train-average_precision                          0.6206 â”‚
â”‚ new_train-binary_error                              0.32813 â”‚
â”‚ ood_test-auc                                        0.69836 â”‚
â”‚ ood_test-average_precision                          0.75112 â”‚
â”‚ ood_test-binary_error                               0.36979 â”‚
â”‚ ood_test_2-auc                                      0.68792 â”‚
â”‚ ood_test_2-average_precision                        0.68728 â”‚
â”‚ ood_test_2-binary_error                              0.3899 â”‚
â”‚ ood_test_3-auc                                      0.67533 â”‚
â”‚ ood_test_3-average_precision                        0.79085 â”‚
â”‚ ood_test_3-binary_error                             0.34689 â”‚
â”‚ ood_validation-auc                                   0.6985 â”‚
â”‚ ood_validation-average_precision                    0.74986 â”‚
â”‚ ood_validation-binary_error                         0.36791 â”‚
â”‚ oracle-auc                                           0.6977 â”‚
â”‚ oracle-average_precision                            0.75052 â”‚
â”‚ oracle-binary_error                                 0.37021 â”‚
â”‚ train-auc                                           0.71844 â”‚
â”‚ train-average_precision                              0.6206 â”‚
â”‚ train-binary_error                                  0.32813 â”‚
â”‚ validation-auc                                      0.71268 â”‚
â”‚ validation-average_precision                        0.61462 â”‚
â”‚ validation-binary_error                             0.33274 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8b25b4b6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8b25b4b6 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.701146 â”‚
â”‚ params/colsample_bytree                      0.650786 â”‚
â”‚ params/learning_rate                       0.00136998 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                   4.18887e-06 â”‚
â”‚ params/reg_alpha                          1.90333e-06 â”‚
â”‚ params/reg_lambda                         6.20618e-08 â”‚
â”‚ params/subsample                             0.611699 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 39 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:50:00. Total running time: 51min 6s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1              0.370036                0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 34 more TERMINATED
Trial status: 39 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:50:31. Total running time: 51min 36s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bf7b9d3b   RUNNING                 0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1              0.370036                0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 34 more TERMINATED
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055367 seconds.
[36m(RayTrainWorker pid=1693467)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1693467)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1693467)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_bf7b9d3b completed after 4 iterations at 2025-04-25 16:50:55. Total running time: 52min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bf7b9d3b result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          2.15821 â”‚
â”‚ time_total_s                              720.495 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71163 â”‚
â”‚ id_test-average_precision                 0.61193 â”‚
â”‚ id_test-binary_error                      0.33299 â”‚
â”‚ id_test_0-auc                             0.66514 â”‚
â”‚ id_test_0-average_precision               0.51404 â”‚
â”‚ id_test_0-binary_error                    0.36197 â”‚
â”‚ id_test_1-auc                             0.71148 â”‚
â”‚ id_test_1-average_precision               0.59276 â”‚
â”‚ id_test_1-binary_error                    0.32763 â”‚
â”‚ id_test_4-auc                              0.6923 â”‚
â”‚ id_test_4-average_precision               0.70875 â”‚
â”‚ id_test_4-binary_error                    0.36215 â”‚
â”‚ new_ood_test-auc                          0.69461 â”‚
â”‚ new_ood_test-average_precision            0.74591 â”‚
â”‚ new_ood_test-binary_error                 0.38096 â”‚
â”‚ new_ood_test_1-auc                        0.69461 â”‚
â”‚ new_ood_test_1-average_precision          0.74591 â”‚
â”‚ new_ood_test_1-binary_error               0.38096 â”‚
â”‚ new_train-auc                             0.71083 â”‚
â”‚ new_train-average_precision               0.60906 â”‚
â”‚ new_train-binary_error                    0.33427 â”‚
â”‚ ood_test-auc                              0.69425 â”‚
â”‚ ood_test-average_precision                0.74555 â”‚
â”‚ ood_test-binary_error                     0.38104 â”‚
â”‚ ood_test_2-auc                            0.68275 â”‚
â”‚ ood_test_2-average_precision              0.68168 â”‚
â”‚ ood_test_2-binary_error                   0.39751 â”‚
â”‚ ood_test_3-auc                            0.67083 â”‚
â”‚ ood_test_3-average_precision              0.78379 â”‚
â”‚ ood_test_3-binary_error                   0.36227 â”‚
â”‚ ood_validation-auc                        0.69432 â”‚
â”‚ ood_validation-average_precision          0.74434 â”‚
â”‚ ood_validation-binary_error               0.38003 â”‚
â”‚ oracle-auc                                0.69374 â”‚
â”‚ oracle-average_precision                  0.74508 â”‚
â”‚ oracle-binary_error                       0.38114 â”‚
â”‚ train-auc                                 0.71083 â”‚
â”‚ train-average_precision                   0.60906 â”‚
â”‚ train-binary_error                        0.33427 â”‚
â”‚ validation-auc                            0.70795 â”‚
â”‚ validation-average_precision              0.60894 â”‚
â”‚ validation-binary_error                   0.33566 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_8a514a06 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a514a06 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.830921 â”‚
â”‚ params/colsample_bytree                    0.706426 â”‚
â”‚ params/learning_rate                       0.958042 â”‚
â”‚ params/max_depth                                 17 â”‚
â”‚ params/min_child_samples                         16 â”‚
â”‚ params/min_child_weight                   0.0061224 â”‚
â”‚ params/reg_alpha                           0.275953 â”‚
â”‚ params/reg_lambda                          0.197261 â”‚
â”‚ params/subsample                           0.860065 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:51:01. Total running time: 52min 6s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:51:31. Total running time: 52min 36s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:52:01. Total running time: 53min 6s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:52:31. Total running time: 53min 36s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:53:01. Total running time: 54min 6s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:53:31. Total running time: 54min 36s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:54:01. Total running time: 55min 6s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148502 seconds.
[36m(RayTrainWorker pid=1703795)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1703795)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] Total Bins 373
Trial status: 40 TERMINATED | 10 RUNNING
Current time: 2025-04-25 16:54:31. Total running time: 55min 36s
Logical resource usage: 10.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_55e23ad1   RUNNING                 3.14916e-05                        2               0.00449586             0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059                                                                                                                        â”‚
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
5 more RUNNING, 35 more TERMINATED
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1703795)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_55e23ad1 completed after 1 iterations at 2025-04-25 16:54:53. Total running time: 55min 58s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_55e23ad1 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          750.519 â”‚
â”‚ time_total_s                              750.519 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69758 â”‚
â”‚ id_test-average_precision                 0.58723 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66195 â”‚
â”‚ id_test_0-average_precision               0.51595 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70145 â”‚
â”‚ id_test_1-average_precision               0.57189 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6898 â”‚
â”‚ id_test_4-average_precision               0.69595 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67558 â”‚
â”‚ new_ood_test-average_precision            0.72675 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67558 â”‚
â”‚ new_ood_test_1-average_precision          0.72675 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69193 â”‚
â”‚ new_train-average_precision               0.57826 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67478 â”‚
â”‚ ood_test-average_precision                0.72586 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                             0.6739 â”‚
â”‚ ood_test_2-average_precision              0.66612 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66585 â”‚
â”‚ ood_test_3-average_precision              0.77744 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67444 â”‚
â”‚ ood_validation-average_precision          0.72455 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67368 â”‚
â”‚ oracle-average_precision                  0.72461 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69193 â”‚
â”‚ train-average_precision                   0.57826 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68978 â”‚
â”‚ validation-average_precision              0.57961 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131257 seconds.
[36m(RayTrainWorker pid=1705187)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1705187)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 41 TERMINATED | 9 RUNNING
Current time: 2025-04-25 16:55:01. Total running time: 56min 6s
Logical resource usage: 9.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ad8c22d8   RUNNING                 0.00665708                         4               0.00030478             0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_711ed9ae   RUNNING                 0.000419176                       64               6.97643                0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045                                                                                                                      â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
4 more RUNNING, 36 more TERMINATED
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1705187)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_ad8c22d8 completed after 1 iterations at 2025-04-25 16:55:11. Total running time: 56min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ad8c22d8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          712.334 â”‚
â”‚ time_total_s                              712.334 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 42 TERMINATED | 8 RUNNING
Current time: 2025-04-25 16:55:31. Total running time: 56min 36s
Logical resource usage: 8.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_711ed9ae   RUNNING                 0.000419176                       64               6.97643                0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045                                                                                                                      â”‚
â”‚ LightGBMTrainer_bd2b95eb   RUNNING                 9.70933e-05                       32               0.0241063              0.714905                    9                 0.731458                 0.628246          3.83833               1.84097e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
3 more RUNNING, 37 more TERMINATED
Trial status: 42 TERMINATED | 8 RUNNING
Current time: 2025-04-25 16:56:01. Total running time: 57min 6s
Logical resource usage: 8.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_711ed9ae   RUNNING                 0.000419176                       64               6.97643                0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045                                                                                                                      â”‚
â”‚ LightGBMTrainer_bd2b95eb   RUNNING                 9.70933e-05                       32               0.0241063              0.714905                    9                 0.731458                 0.628246          3.83833               1.84097e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
3 more RUNNING, 37 more TERMINATED
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080239 seconds.
[36m(RayTrainWorker pid=1727414)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092846 seconds.
[36m(RayTrainWorker pid=1724676)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1724676)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] Total Bins 372[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129367 seconds.
[36m(RayTrainWorker pid=1726011)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1726011)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 26x across cluster][0m
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 26x across cluster][0m
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Trial status: 42 TERMINATED | 8 RUNNING
Current time: 2025-04-25 16:56:31. Total running time: 57min 36s
Logical resource usage: 8.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a7780331   RUNNING                 0.0206556                          8            7033.82                   0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741                                                                                                                        â”‚
â”‚ LightGBMTrainer_90ea7a9d   RUNNING                 0.000752593                        1               0.370036               0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_0cd97143   RUNNING                 0.00214014                        16              61.7974                 0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774                                                                                                                       â”‚
â”‚ LightGBMTrainer_711ed9ae   RUNNING                 0.000419176                       64               6.97643                0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045                                                                                                                      â”‚
â”‚ LightGBMTrainer_bd2b95eb   RUNNING                 9.70933e-05                       32               0.0241063              0.714905                    9                 0.731458                 0.628246          3.83833               1.84097e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
3 more RUNNING, 37 more TERMINATED

Trial LightGBMTrainer_0cd97143 completed after 1 iterations at 2025-04-25 16:56:32. Total running time: 57min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0cd97143 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          612.892 â”‚
â”‚ time_total_s                              612.892 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6479 â”‚
â”‚ id_test-average_precision                 0.51312 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.61638 â”‚
â”‚ id_test_0-average_precision               0.44807 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.66099 â”‚
â”‚ id_test_1-average_precision               0.50951 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.61505 â”‚
â”‚ id_test_4-average_precision               0.60364 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                           0.6057 â”‚
â”‚ new_ood_test-average_precision              0.656 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                         0.6057 â”‚
â”‚ new_ood_test_1-average_precision            0.656 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.64063 â”‚
â”‚ new_train-average_precision                0.5064 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.60497 â”‚
â”‚ ood_test-average_precision                0.65537 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.62687 â”‚
â”‚ ood_test_2-average_precision              0.60842 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.59521 â”‚
â”‚ ood_test_3-average_precision              0.72012 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.60479 â”‚
â”‚ ood_validation-average_precision           0.6542 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.60395 â”‚
â”‚ oracle-average_precision                  0.65448 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.64063 â”‚
â”‚ train-average_precision                    0.5064 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.64259 â”‚
â”‚ validation-average_precision              0.50965 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1727414)[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf

Trial LightGBMTrainer_a7780331 completed after 1 iterations at 2025-04-25 16:56:35. Total running time: 57min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a7780331 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          699.231 â”‚
â”‚ time_total_s                              699.231 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 8x across cluster][0m
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1724676)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1726011)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_90ea7a9d completed after 4 iterations at 2025-04-25 16:56:48. Total running time: 57min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_90ea7a9d result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           1.4705 â”‚
â”‚ time_total_s                              677.894 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71007 â”‚
â”‚ id_test-average_precision                 0.60927 â”‚
â”‚ id_test-binary_error                      0.34038 â”‚
â”‚ id_test_0-auc                             0.67875 â”‚
â”‚ id_test_0-average_precision               0.54622 â”‚
â”‚ id_test_0-binary_error                    0.33364 â”‚
â”‚ id_test_1-auc                             0.70952 â”‚
â”‚ id_test_1-average_precision               0.58958 â”‚
â”‚ id_test_1-binary_error                    0.33673 â”‚
â”‚ id_test_4-auc                             0.68858 â”‚
â”‚ id_test_4-average_precision               0.69885 â”‚
â”‚ id_test_4-binary_error                    0.36954 â”‚
â”‚ new_ood_test-auc                          0.69324 â”‚
â”‚ new_ood_test-average_precision             0.7441 â”‚
â”‚ new_ood_test-binary_error                   0.406 â”‚
â”‚ new_ood_test_1-auc                        0.69324 â”‚
â”‚ new_ood_test_1-average_precision           0.7441 â”‚
â”‚ new_ood_test_1-binary_error                 0.406 â”‚
â”‚ new_train-auc                             0.70711 â”‚
â”‚ new_train-average_precision               0.60333 â”‚
â”‚ new_train-binary_error                    0.34128 â”‚
â”‚ ood_test-auc                              0.69262 â”‚
â”‚ ood_test-average_precision                0.74313 â”‚
â”‚ ood_test-binary_error                      0.4061 â”‚
â”‚ ood_test_2-auc                            0.68174 â”‚
â”‚ ood_test_2-average_precision               0.6792 â”‚
â”‚ ood_test_2-binary_error                   0.42019 â”‚
â”‚ ood_test_3-auc                            0.66819 â”‚
â”‚ ood_test_3-average_precision              0.78074 â”‚
â”‚ ood_test_3-binary_error                   0.39006 â”‚
â”‚ ood_validation-auc                        0.69266 â”‚
â”‚ ood_validation-average_precision          0.74226 â”‚
â”‚ ood_validation-binary_error                0.4039 â”‚
â”‚ oracle-auc                                0.69177 â”‚
â”‚ oracle-average_precision                  0.74179 â”‚
â”‚ oracle-binary_error                       0.40625 â”‚
â”‚ train-auc                                 0.70711 â”‚
â”‚ train-average_precision                   0.60333 â”‚
â”‚ train-binary_error                        0.34128 â”‚
â”‚ validation-auc                            0.70622 â”‚
â”‚ validation-average_precision               0.6055 â”‚
â”‚ validation-binary_error                   0.34121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 45 TERMINATED | 5 RUNNING
Current time: 2025-04-25 16:57:02. Total running time: 58min 7s
Logical resource usage: 5.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_711ed9ae   RUNNING                 0.000419176                       64              6.97643                 0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045                                                                                                                      â”‚
â”‚ LightGBMTrainer_bd2b95eb   RUNNING                 9.70933e-05                       32              0.0241063               0.714905                    9                 0.731458                 0.628246          3.83833               1.84097e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_0ed3b06c   RUNNING                 0.0199172                          2              1.02572e-07             0.754421                   19                 0.524227                 0.755786          1.76495e-05           0.00136674                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b25b4b6   RUNNING                 0.00136998                         8              4.18887e-06             0.611699                   27                 0.650786                 0.701146          1.90333e-06           6.20618e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8a514a06   RUNNING                 0.958042                          16              0.0061224               0.860065                   17                 0.706426                 0.830921          0.275953              0.197261                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049637 seconds.
[36m(RayTrainWorker pid=1728749)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1728749)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 18x across cluster][0m
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 18x across cluster][0m
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047000 seconds.
[36m(RayTrainWorker pid=1728846)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1728846)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] Total Bins 368
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_711ed9ae completed after 1 iterations at 2025-04-25 16:57:20. Total running time: 58min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_711ed9ae result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          638.171 â”‚
â”‚ time_total_s                              638.171 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69401 â”‚
â”‚ id_test-average_precision                 0.58447 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66832 â”‚
â”‚ id_test_0-average_precision               0.51552 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69778 â”‚
â”‚ id_test_1-average_precision               0.56939 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68673 â”‚
â”‚ id_test_4-average_precision               0.69257 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67239 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67239 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68854 â”‚
â”‚ new_train-average_precision               0.57584 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67168 â”‚
â”‚ ood_test-average_precision                0.72399 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67132 â”‚
â”‚ ood_test_2-average_precision              0.66463 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66351 â”‚
â”‚ ood_test_3-average_precision              0.77578 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67191 â”‚
â”‚ ood_validation-average_precision          0.72344 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67069 â”‚
â”‚ oracle-average_precision                  0.72262 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68854 â”‚
â”‚ train-average_precision                   0.57584 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68669 â”‚
â”‚ validation-average_precision              0.57768 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bd2b95eb completed after 1 iterations at 2025-04-25 16:57:22. Total running time: 58min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd2b95eb result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          633.874 â”‚
â”‚ time_total_s                              633.874 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.67312 â”‚
â”‚ id_test-average_precision                 0.56543 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.63924 â”‚
â”‚ id_test_0-average_precision               0.48628 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.67384 â”‚
â”‚ id_test_1-average_precision               0.54893 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.67256 â”‚
â”‚ id_test_4-average_precision               0.67788 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.66524 â”‚
â”‚ new_ood_test-average_precision            0.71958 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.66524 â”‚
â”‚ new_ood_test_1-average_precision          0.71958 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.67098 â”‚
â”‚ new_train-average_precision               0.56172 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.66516 â”‚
â”‚ ood_test-average_precision                 0.7195 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.65817 â”‚
â”‚ ood_test_2-average_precision              0.65505 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.65683 â”‚
â”‚ ood_test_3-average_precision              0.77198 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.66703 â”‚
â”‚ ood_validation-average_precision          0.72249 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66504 â”‚
â”‚ oracle-average_precision                  0.71939 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.67098 â”‚
â”‚ train-average_precision                   0.56172 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.66745 â”‚
â”‚ validation-average_precision              0.55905 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=1728749)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1728846)[0m [LightGBM] [Info] Start training from score -0.400412

Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:57:32. Total running time: 58min 37s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0ed3b06c   RUNNING                 0.0199172                          2              1.02572e-07             0.754421                   19                 0.524227                 0.755786          1.76495e-05           0.00136674                                                                                                                     â”‚
â”‚ LightGBMTrainer_8b25b4b6   RUNNING                 0.00136998                         8              4.18887e-06             0.611699                   27                 0.650786                 0.701146          1.90333e-06           6.20618e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_8a514a06   RUNNING                 0.958042                          16              0.0061224               0.860065                   17                 0.706426                 0.830921          0.275953              0.197261                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043711 seconds.
[36m(RayTrainWorker pid=1731623)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1731623)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=7) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=128) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1731623)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_0ed3b06c completed after 1 iterations at 2025-04-25 16:57:42. Total running time: 58min 47s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0ed3b06c result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           569.02 â”‚
â”‚ time_total_s                               569.02 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69429 â”‚
â”‚ id_test-average_precision                 0.58483 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66896 â”‚
â”‚ id_test_0-average_precision               0.51676 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69791 â”‚
â”‚ id_test_1-average_precision               0.56968 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68765 â”‚
â”‚ id_test_4-average_precision               0.69283 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67225 â”‚
â”‚ new_ood_test-average_precision            0.72496 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67225 â”‚
â”‚ new_ood_test_1-average_precision          0.72496 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68848 â”‚
â”‚ new_train-average_precision               0.57595 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67155 â”‚
â”‚ ood_test-average_precision                0.72397 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67102 â”‚
â”‚ ood_test_2-average_precision              0.66454 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66332 â”‚
â”‚ ood_test_3-average_precision               0.7757 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67201 â”‚
â”‚ ood_validation-average_precision          0.72367 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67057 â”‚
â”‚ oracle-average_precision                  0.72259 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68848 â”‚
â”‚ train-average_precision                   0.57595 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68584 â”‚
â”‚ validation-average_precision              0.57733 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040908 seconds.
[36m(RayTrainWorker pid=1751038)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1751038)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=12) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=4096) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1751038)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039995 seconds.
[36m(RayTrainWorker pid=1752496)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=1752496)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=1752496)[0m [LightGBM] [Info] Start training from score -0.400412

Trial status: 48 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:58:02. Total running time: 59min 7s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_8b25b4b6   RUNNING                 0.00136998                         8              4.18887e-06             0.611699                   27                 0.650786                 0.701146          1.90333e-06           6.20618e-08        9            500.63                0.328468      0.717937                 0.619263                 0.328468 â”‚
â”‚ LightGBMTrainer_8a514a06   RUNNING                 0.958042                          16              0.0061224               0.860065                   17                 0.706426                 0.830921          0.275953              0.197261                                                                                                                       â”‚
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
43 more TERMINATED

Trial LightGBMTrainer_8b25b4b6 completed after 10 iterations at 2025-04-25 16:58:03. Total running time: 59min 8s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8b25b4b6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.59869 â”‚
â”‚ time_total_s                                       501.2285 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71728 â”‚
â”‚ id_test-average_precision                           0.62051 â”‚
â”‚ id_test-binary_error                                0.32837 â”‚
â”‚ id_test_0-auc                                       0.66655 â”‚
â”‚ id_test_0-average_precision                          0.5324 â”‚
â”‚ id_test_0-binary_error                              0.34461 â”‚
â”‚ id_test_1-auc                                       0.71698 â”‚
â”‚ id_test_1-average_precision                         0.60221 â”‚
â”‚ id_test_1-binary_error                                0.324 â”‚
â”‚ id_test_4-auc                                       0.70012 â”‚
â”‚ id_test_4-average_precision                          0.7149 â”‚
â”‚ id_test_4-binary_error                              0.35476 â”‚
â”‚ new_ood_test-auc                                    0.69883 â”‚
â”‚ new_ood_test-average_precision                      0.75156 â”‚
â”‚ new_ood_test-binary_error                           0.36949 â”‚
â”‚ new_ood_test_1-auc                                  0.69883 â”‚
â”‚ new_ood_test_1-average_precision                    0.75156 â”‚
â”‚ new_ood_test_1-binary_error                         0.36949 â”‚
â”‚ new_train-auc                                       0.71844 â”‚
â”‚ new_train-average_precision                          0.6206 â”‚
â”‚ new_train-binary_error                              0.32813 â”‚
â”‚ ood_test-auc                                        0.69836 â”‚
â”‚ ood_test-average_precision                          0.75112 â”‚
â”‚ ood_test-binary_error                               0.36979 â”‚
â”‚ ood_test_2-auc                                      0.68792 â”‚
â”‚ ood_test_2-average_precision                        0.68728 â”‚
â”‚ ood_test_2-binary_error                              0.3899 â”‚
â”‚ ood_test_3-auc                                      0.67533 â”‚
â”‚ ood_test_3-average_precision                        0.79085 â”‚
â”‚ ood_test_3-binary_error                             0.34689 â”‚
â”‚ ood_validation-auc                                   0.6985 â”‚
â”‚ ood_validation-average_precision                    0.74986 â”‚
â”‚ ood_validation-binary_error                         0.36791 â”‚
â”‚ oracle-auc                                           0.6977 â”‚
â”‚ oracle-average_precision                            0.75052 â”‚
â”‚ oracle-binary_error                                 0.37021 â”‚
â”‚ train-auc                                           0.71844 â”‚
â”‚ train-average_precision                              0.6206 â”‚
â”‚ train-binary_error                                  0.32813 â”‚
â”‚ validation-auc                                      0.71268 â”‚
â”‚ validation-average_precision                        0.61462 â”‚
â”‚ validation-binary_error                             0.33274 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff029eeb9ff7eadc00b49d7b1501000000 Worker ID: b7e9a3c65432afe1053a67db5e11b49b73d32ae59996098540ccf980 Node ID: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 Worker IP address: 10.164.10.39 Worker port: 37401 Worker PID: 1751133 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM.

Trial LightGBMTrainer_8a514a06 completed after 4 iterations at 2025-04-25 16:58:04. Total running time: 59min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_8a514a06 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           0.5712 â”‚
â”‚ time_total_s                              428.869 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.71163 â”‚
â”‚ id_test-average_precision                 0.61193 â”‚
â”‚ id_test-binary_error                      0.33299 â”‚
â”‚ id_test_0-auc                             0.66514 â”‚
â”‚ id_test_0-average_precision               0.51404 â”‚
â”‚ id_test_0-binary_error                    0.36197 â”‚
â”‚ id_test_1-auc                             0.71148 â”‚
â”‚ id_test_1-average_precision               0.59276 â”‚
â”‚ id_test_1-binary_error                    0.32763 â”‚
â”‚ id_test_4-auc                              0.6923 â”‚
â”‚ id_test_4-average_precision               0.70875 â”‚
â”‚ id_test_4-binary_error                    0.36215 â”‚
â”‚ new_ood_test-auc                          0.69461 â”‚
â”‚ new_ood_test-average_precision            0.74591 â”‚
â”‚ new_ood_test-binary_error                 0.38096 â”‚
â”‚ new_ood_test_1-auc                        0.69461 â”‚
â”‚ new_ood_test_1-average_precision          0.74591 â”‚
â”‚ new_ood_test_1-binary_error               0.38096 â”‚
â”‚ new_train-auc                             0.71083 â”‚
â”‚ new_train-average_precision               0.60906 â”‚
â”‚ new_train-binary_error                    0.33427 â”‚
â”‚ ood_test-auc                              0.69425 â”‚
â”‚ ood_test-average_precision                0.74555 â”‚
â”‚ ood_test-binary_error                     0.38104 â”‚
â”‚ ood_test_2-auc                            0.68275 â”‚
â”‚ ood_test_2-average_precision              0.68169 â”‚
â”‚ ood_test_2-binary_error                   0.39751 â”‚
â”‚ ood_test_3-auc                            0.67083 â”‚
â”‚ ood_test_3-average_precision              0.78379 â”‚
â”‚ ood_test_3-binary_error                   0.36227 â”‚
â”‚ ood_validation-auc                        0.69432 â”‚
â”‚ ood_validation-average_precision          0.74434 â”‚
â”‚ ood_validation-binary_error               0.38003 â”‚
â”‚ oracle-auc                                0.69374 â”‚
â”‚ oracle-average_precision                  0.74508 â”‚
â”‚ oracle-binary_error                       0.38114 â”‚
â”‚ train-auc                                 0.71083 â”‚
â”‚ train-average_precision                   0.60906 â”‚
â”‚ train-binary_error                        0.33427 â”‚
â”‚ validation-auc                            0.70795 â”‚
â”‚ validation-average_precision              0.60894 â”‚
â”‚ validation-binary_error                   0.33566 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 50 TERMINATED
Current time: 2025-04-25 16:58:04. Total running time: 59min 9s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...rain-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_67999564   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299         10            568.747               0.401213      0.701815                 0.595072                 0.401213 â”‚
â”‚ LightGBMTrainer_96a913ea   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05        10            545.809               0.401213      0.701732                 0.593421                 0.401213 â”‚
â”‚ LightGBMTrainer_876c42c0   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            593.49                0.331282      0.713343                 0.613306                 0.331282 â”‚
â”‚ LightGBMTrainer_382bb831   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            626.217               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_0ab5550e   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            610.482               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c6c17020   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            650.196               0.401213      0.701285                 0.590113                 0.401213 â”‚
â”‚ LightGBMTrainer_ebe8995a   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            667.416               0.401213      0.69262                  0.592625                 0.401213 â”‚
â”‚ LightGBMTrainer_dd34c228   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            699.689               0.33593       0.710433                 0.608013                 0.33593  â”‚
â”‚ LightGBMTrainer_8849c856   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07       10            697.337               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_f2e40a84   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06        10            703.296               0.330053      0.716894                 0.618409                 0.330053 â”‚
â”‚ LightGBMTrainer_f16fc5ce   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        1            677.567               0.401213      0.691923                 0.578257                 0.401213 â”‚
â”‚ LightGBMTrainer_1c4edb24   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08        1            677.857               0.401213      0.687708                 0.575028                 0.401213 â”‚
â”‚ LightGBMTrainer_2ef46010   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          4            715.454               0.341281      0.707107                 0.603329                 0.341281 â”‚
â”‚ LightGBMTrainer_f970a727   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           1            665.011               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_5e3069a8   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        1            676.067               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_2259c7ba   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07        1            668.09                0.401213      0.688537                 0.575839                 0.401213 â”‚
â”‚ LightGBMTrainer_708d9519   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08        1            664.644               0.401213      0.670979                 0.561721                 0.401213 â”‚
â”‚ LightGBMTrainer_efa753b8   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442         1            677.053               0.401213      0.688478                 0.575948                 0.401213 â”‚
â”‚ LightGBMTrainer_d81ba0dc   TERMINATED              0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08       10            671.441               0.327765      0.71853                  0.620229                 0.327765 â”‚
â”‚ LightGBMTrainer_7f258857   TERMINATED              5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961           10            690.309               0.330053      0.716894                 0.618409                 0.330053 â”‚
â”‚ LightGBMTrainer_d783e720   TERMINATED              0.969558                           2              1.0684e-06              0.809168                   28                 0.917927                 0.994394          1.21829e-08          35.4744             1            674.894               0.401213      0.691923                 0.578257                 0.401213 â”‚
â”‚ LightGBMTrainer_d7e0cfeb   TERMINATED              0.428903                           2              1.176e-08               0.515165                    6                 0.914079                 0.959597          1.39166e-08           0.0574304          1            720.716               0.401213      0.687708                 0.575028                 0.401213 â”‚
â”‚ LightGBMTrainer_31bee9ea   TERMINATED              0.2008                            16              7.92478e-05             0.829095                   22                 0.893839                 0.866885          7.90088e-08          64.7894             4            658.756               0.341281      0.707107                 0.603329                 0.341281 â”‚
â”‚ LightGBMTrainer_d2fc64b0   TERMINATED              0.00524715                         2              4.75495e-07             0.563555                   -1                 0.999599                 0.873135          0.00108905            0.0308342          1            711.384               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_d733d922   TERMINATED              0.164328                          32              0.000103335             0.887153                    3                 0.783773                 0.981189          0.0812618             0.000325247        1            667.889               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_c74839c4   TERMINATED              0.0108039                         16              1.02432                 0.692643                   20                 0.892371                 0.957726          0.00406788            2.53758e-05        1            684.814               0.401213      0.688537                 0.575839                 0.401213 â”‚
â”‚ LightGBMTrainer_b83ad2d4   TERMINATED              0.34828                            4              3.46644e-07             0.84732                     1                 0.952761                 0.849415          8.71542e-08           0.103845           1            680.342               0.401213      0.670979                 0.561721                 0.401213 â”‚
â”‚ LightGBMTrainer_6b17a432   TERMINATED              0.0878197                         16              1.36874e-05             0.775132                    6                 0.853667                 0.952287          1.62106              18.1917             1            678.517               0.401213      0.688478                 0.575948                 0.401213 â”‚
â”‚ LightGBMTrainer_c74f6e10   TERMINATED              0.00225169                         2              2.55273                 0.781356                   25                 0.608417                 0.552012          0.0168175             0.391092          10            689.393               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_249f3f8f   TERMINATED              1.15575e-05                       16              0.476108                0.570887                   25                 0.506629                 0.582712          0.00882842            0.00342848        10            706.273               0.330053      0.716894                 0.618409                 0.330053 â”‚
â”‚ LightGBMTrainer_919001a7   TERMINATED              8.19642e-05                        4             13.666                   0.937946                   15                 0.799372                 0.64991          82.2433                7.80862e-08        1            684.471               0.401213      0.69193                  0.578256                 0.401213 â”‚
â”‚ LightGBMTrainer_243f756b   TERMINATED              0.000181923                        2              0.00106125              0.672682                    4                 0.74978                  0.687784          0.000343458          10.808              1            689.532               0.401213      0.687708                 0.575028                 0.401213 â”‚
â”‚ LightGBMTrainer_8a2e57f4   TERMINATED              0.00212471                        32           1173.54                    0.733873                   29                 0.673041                 0.504082          0.11748               0.000810531        4            739.283               0.341281      0.707107                 0.603329                 0.341281 â”‚
â”‚ LightGBMTrainer_8c1c2fa6   TERMINATED              0.00450874                         4              0.113362                0.597137                   18                 0.626013                 0.533251          0.000144952           0.0197576          1            746.332               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_0df713ef   TERMINATED              0.0141836                          2             14.2339                  0.854055                   10                 0.864236                 0.626549          0.0233874             8.62385e-05        1            635.625               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_12006abf   TERMINATED              0.000188708                       32              0.00333306              0.550467                    2                 0.647569                 0.778579          1.10238               7.4399e-06         1            693.943               0.401213      0.688537                 0.575839                 0.401213 â”‚
â”‚ LightGBMTrainer_cb5815b7   TERMINATED              1.58635e-05                       16            249.849                   0.662325                   26                 0.59729                  0.905995          0.00254682            0.154152           1            660.105               0.401213      0.670979                 0.561721                 0.401213 â”‚
â”‚ LightGBMTrainer_a99fea90   TERMINATED              0.0012354                          8              0.000471723             0.71882                    23                 0.744699                 0.502162          2.09367e-05          97.82               1            681.367               0.401213      0.688478                 0.575948                 0.401213 â”‚
â”‚ LightGBMTrainer_7468169d   TERMINATED              6.18404e-05                       16              0.0968358               0.807332                   30                 0.828385                 0.677438         16.5048                0.000266245       10            731.864               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_bf7b9d3b   TERMINATED              0.000303917                        1              3.37759e-05             0.76776                     8                 0.774935                 0.623055          0.316246              3.12707e-07        4            720.495               0.334267      0.710834                 0.609065                 0.334267 â”‚
â”‚ LightGBMTrainer_55e23ad1   TERMINATED              3.14916e-05                        2              0.00449586              0.592565                   11                 0.5734                   0.570524          0.00041493            2.75059            1            750.519               0.401213      0.69193                  0.578256                 0.401213 â”‚
â”‚ LightGBMTrainer_ad8c22d8   TERMINATED              0.00665708                         4              0.00030478              0.54196                    25                 0.500995                 0.74418           6.01063               1.41863e-06        1            712.334               0.401213      0.687708                 0.575028                 0.401213 â”‚
â”‚ LightGBMTrainer_a7780331   TERMINATED              0.0206556                          8           7033.82                    0.636979                   16                 0.94194                  0.846097          6.9489e-05            8.34741            1            699.231               0.401213      0.685804                 0.573718                 0.401213 â”‚
â”‚ LightGBMTrainer_90ea7a9d   TERMINATED              0.000752593                        1              0.370036                0.927555                    6                 0.807043                 0.655999         67.6218                6.68211e-06        4            677.895               0.341281      0.707107                 0.603329                 0.341281 â”‚
â”‚ LightGBMTrainer_0cd97143   TERMINATED              0.00214014                        16             61.7974                  0.978608                   12                 0.688227                 0.714153          0.0307413             0.824774           1            612.892               0.401213      0.640629                 0.5064                   0.401213 â”‚
â”‚ LightGBMTrainer_711ed9ae   TERMINATED              0.000419176                       64              6.97643                 0.674741                    5                 0.874217                 0.793338          0.00335045            0.0078045          1            638.171               0.401213      0.688537                 0.575839                 0.401213 â”‚
â”‚ LightGBMTrainer_bd2b95eb   TERMINATED              9.70933e-05                       32              0.0241063               0.714905                    9                 0.731458                 0.628246          3.83833               1.84097e-08        1            633.874               0.401213      0.670979                 0.561721                 0.401213 â”‚
â”‚ LightGBMTrainer_0ed3b06c   TERMINATED              0.0199172                          2              1.02572e-07             0.754421                   19                 0.524227                 0.755786          1.76495e-05           0.00136674         1            569.02                0.401213      0.688478                 0.575948                 0.401213 â”‚
â”‚ LightGBMTrainer_8b25b4b6   TERMINATED              0.00136998                         8              4.18887e-06             0.611699                   27                 0.650786                 0.701146          1.90333e-06           6.20618e-08       10            501.229               0.328126      0.718437                 0.620602                 0.328126 â”‚
â”‚ LightGBMTrainer_8a514a06   TERMINATED              0.958042                          16              0.0061224               0.860065                   17                 0.706426                 0.830921          0.275953              0.197261           4            428.869               0.334267      0.710834                 0.609065                 0.334267 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffb44ab02f5d5582ec21f4308101000000 Worker ID: c708b58757e128ec48c193a7421bd12f711d4bc585bb2f4e53df3eda Node ID: 7547f1e01475afca624df4872c029639f57b214dc7f1ed775f0c40e1 Worker IP address: 10.164.10.39 Worker port: 36495 Worker PID: 1752623 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM.[32m [repeated 3x across cluster][0m
    train-auc  ...  domain_split_id_values
0    0.701815  ...         ['0', '1', '4']
1    0.701732  ...         ['0', '1', '4']
2    0.713343  ...         ['0', '1', '4']
3    0.685804  ...         ['0', '1', '4']
4    0.640629  ...         ['0', '1', '4']
5    0.701285  ...         ['0', '1', '4']
6    0.692620  ...         ['0', '1', '4']
7    0.710433  ...         ['0', '1', '4']
8    0.718437  ...         ['0', '1', '4']
9    0.716894  ...         ['0', '1', '4']
10   0.691923  ...         ['0', '1', '4']
11   0.687708  ...         ['0', '1', '4']
12   0.707107  ...         ['0', '1', '4']
13   0.685804  ...         ['0', '1', '4']
14   0.640629  ...         ['0', '1', '4']
15   0.688537  ...         ['0', '1', '4']
16   0.670979  ...         ['0', '1', '4']
17   0.688478  ...         ['0', '1', '4']
18   0.718530  ...         ['0', '1', '4']
19   0.716894  ...         ['0', '1', '4']
20   0.691923  ...         ['0', '1', '4']
21   0.687708  ...         ['0', '1', '4']
22   0.707107  ...         ['0', '1', '4']
23   0.685804  ...         ['0', '1', '4']
24   0.640629  ...         ['0', '1', '4']
25   0.688537  ...         ['0', '1', '4']
26   0.670979  ...         ['0', '1', '4']
27   0.688478  ...         ['0', '1', '4']
28   0.718437  ...         ['0', '1', '4']
29   0.716894  ...         ['0', '1', '4']
30   0.691930  ...         ['0', '1', '4']
31   0.687708  ...         ['0', '1', '4']
32   0.707107  ...         ['0', '1', '4']
33   0.640629  ...         ['0', '1', '4']
34   0.685804  ...         ['0', '1', '4']
35   0.688537  ...         ['0', '1', '4']
36   0.670979  ...         ['0', '1', '4']
37   0.688478  ...         ['0', '1', '4']
38   0.718437  ...         ['0', '1', '4']
39   0.710834  ...         ['0', '1', '4']
40   0.691930  ...         ['0', '1', '4']
41   0.687708  ...         ['0', '1', '4']
42   0.685804  ...         ['0', '1', '4']
43   0.707107  ...         ['0', '1', '4']
44   0.640629  ...         ['0', '1', '4']
45   0.688537  ...         ['0', '1', '4']
46   0.670979  ...         ['0', '1', '4']
47   0.688478  ...         ['0', '1', '4']
48   0.718437  ...         ['0', '1', '4']
49   0.710834  ...         ['0', '1', '4']

[50 rows x 70 columns]
