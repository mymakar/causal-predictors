â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     tableshift              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator         â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler â”‚
â”‚ Number of trials                 50                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/rjsingh/ray_results/tableshift
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-04-25_15-50-56_265421_2566893/artifacts/2025-04-25_15-51-13/tableshift/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-04-25 15:51:13. Total running time: 0s
Logical resource usage: 0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   PENDING               0.000164587                        8                  31.1567             0.795395                    6                  0.72302                 0.925513               11.443             0.0032299 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ac0b048c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ac0b048c config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.925513 â”‚
â”‚ params/colsample_bytree                       0.72302 â”‚
â”‚ params/learning_rate                      0.000164587 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                       31.1567 â”‚
â”‚ params/reg_alpha                               11.443 â”‚
â”‚ params/reg_lambda                           0.0032299 â”‚
â”‚ params/subsample                             0.795395 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_9e09426a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_9e09426a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.91828 â”‚
â”‚ params/colsample_bytree                      0.963194 â”‚
â”‚ params/learning_rate                      0.000121064 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                       88.6536 â”‚
â”‚ params/reg_alpha                          3.15908e-05 â”‚
â”‚ params/reg_lambda                          1.9731e-05 â”‚
â”‚ params/subsample                             0.995723 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_6fa3bf75 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6fa3bf75 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.995475 â”‚
â”‚ params/colsample_bytree                      0.890752 â”‚
â”‚ params/learning_rate                         0.285296 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    1.5737e-05 â”‚
â”‚ params/reg_alpha                          0.000468379 â”‚
â”‚ params/reg_lambda                             2.79121 â”‚
â”‚ params/subsample                             0.799768 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-04-25 15:51:43. Total running time: 30s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   PENDING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-04-25 15:52:13. Total running time: 1min 0s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   PENDING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 145 PYTHON worker processes have been started on node: 6a2810168eebbb29d9812342170c9ee7ed185941125d7e376a513ab4 with address: 10.164.8.128. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).

Trial LightGBMTrainer_cf475c9c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_cf475c9c config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.903575 â”‚
â”‚ params/colsample_bytree                      0.841159 â”‚
â”‚ params/learning_rate                      0.000988995 â”‚
â”‚ params/max_depth                                    5 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                    0.00324906 â”‚
â”‚ params/reg_alpha                           5.8573e-05 â”‚
â”‚ params/reg_lambda                         0.000552809 â”‚
â”‚ params/subsample                             0.652433 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 4 RUNNING
Current time: 2025-04-25 15:52:43. Total running time: 1min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:53:13. Total running time: 2min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:53:43. Total running time: 2min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:54:13. Total running time: 3min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:54:43. Total running time: 3min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:55:13. Total running time: 4min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:55:43. Total running time: 4min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 RUNNING
Current time: 2025-04-25 15:56:13. Total running time: 5min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status       params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   RUNNING               0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299   â”‚
â”‚ LightGBMTrainer_9e09426a   RUNNING               0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05  â”‚
â”‚ LightGBMTrainer_6fa3bf75   RUNNING               0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121     â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING               0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048061 seconds.
[36m(RayTrainWorker pid=2571403)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2571403)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045687 seconds.
[36m(RayTrainWorker pid=2570109)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2570109)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] Total Bins 368
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2571403)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_ac0b048c completed after 1 iterations at 2025-04-25 15:56:29. Total running time: 5min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ac0b048c result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          311.287 â”‚
â”‚ time_total_s                              311.287 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_21eedc41 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_21eedc41 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.815193 â”‚
â”‚ params/colsample_bytree                    0.657187 â”‚
â”‚ params/learning_rate                      0.0415284 â”‚
â”‚ params/max_depth                                 17 â”‚
â”‚ params/min_child_samples                         32 â”‚
â”‚ params/min_child_weight                     5054.73 â”‚
â”‚ params/reg_alpha                            22.4911 â”‚
â”‚ params/reg_lambda                           3.52364 â”‚
â”‚ params/subsample                           0.570107 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[33m(raylet)[0m WARNING: 186 PYTHON worker processes have been started on node: 6a2810168eebbb29d9812342170c9ee7ed185941125d7e376a513ab4 with address: 10.164.8.128. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044291 seconds.
[36m(RayTrainWorker pid=2570256)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2570256)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2570109)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2570256)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_9e09426a completed after 1 iterations at 2025-04-25 15:56:39. Total running time: 5min 26s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_9e09426a result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                            316.9 â”‚
â”‚ time_total_s                                316.9 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69766 â”‚
â”‚ id_test-average_precision                 0.58726 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66195 â”‚
â”‚ id_test_0-average_precision               0.51595 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70155 â”‚
â”‚ id_test_1-average_precision               0.57193 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6898 â”‚
â”‚ id_test_4-average_precision               0.69595 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67553 â”‚
â”‚ new_ood_test-average_precision            0.72674 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67553 â”‚
â”‚ new_ood_test_1-average_precision          0.72674 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69192 â”‚
â”‚ new_train-average_precision               0.57826 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67473 â”‚
â”‚ ood_test-average_precision                0.72584 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67381 â”‚
â”‚ ood_test_2-average_precision               0.6661 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66585 â”‚
â”‚ ood_test_3-average_precision              0.77744 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67437 â”‚
â”‚ ood_validation-average_precision          0.72453 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67361 â”‚
â”‚ oracle-average_precision                  0.72459 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69192 â”‚
â”‚ train-average_precision                   0.57826 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68984 â”‚
â”‚ validation-average_precision              0.57964 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_46451abb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_46451abb config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.998595 â”‚
â”‚ params/colsample_bytree                      0.846572 â”‚
â”‚ params/learning_rate                      0.000408737 â”‚
â”‚ params/max_depth                                   16 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0240841 â”‚
â”‚ params/reg_alpha                          7.19007e-06 â”‚
â”‚ params/reg_lambda                         2.22449e-06 â”‚
â”‚ params/subsample                             0.902369 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054977 seconds.
[36m(RayTrainWorker pid=2579100)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2579100)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100

Trial status: 2 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:56:43. Total running time: 5min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_6fa3bf75   RUNNING                 0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121            5            307.729               0.337709      0.708931                 0.606225                 0.414449 â”‚
â”‚ LightGBMTrainer_cf475c9c   RUNNING                 0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809                                                                                                                    â”‚
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_cf475c9c completed after 1 iterations at 2025-04-25 15:56:54. Total running time: 5min 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_cf475c9c result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          252.317 â”‚
â”‚ time_total_s                              252.317 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                               0.69194 â”‚
â”‚ id_test-average_precision                 0.58032 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.66143 â”‚
â”‚ id_test_0-average_precision               0.52091 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69506 â”‚
â”‚ id_test_1-average_precision               0.56536 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                              0.6855 â”‚
â”‚ id_test_4-average_precision               0.68814 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67229 â”‚
â”‚ new_ood_test-average_precision            0.72486 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67229 â”‚
â”‚ new_ood_test_1-average_precision          0.72486 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                              0.6858 â”‚
â”‚ new_train-average_precision               0.57372 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67143 â”‚
â”‚ ood_test-average_precision                0.72411 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.66885 â”‚
â”‚ ood_test_2-average_precision              0.66182 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66423 â”‚
â”‚ ood_test_3-average_precision              0.77839 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67144 â”‚
â”‚ ood_validation-average_precision          0.72444 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.67022 â”‚
â”‚ oracle-average_precision                  0.72308 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                  0.6858 â”‚
â”‚ train-average_precision                   0.57372 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68368 â”‚
â”‚ validation-average_precision              0.57381 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ede88318 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ede88318 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.667537 â”‚
â”‚ params/colsample_bytree                      0.541613 â”‚
â”‚ params/learning_rate                      0.000722629 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                     0.0899496 â”‚
â”‚ params/reg_alpha                          3.73583e-05 â”‚
â”‚ params/reg_lambda                         1.60174e-05 â”‚
â”‚ params/subsample                             0.997766 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=2579100)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m

Trial LightGBMTrainer_6fa3bf75 completed after 10 iterations at 2025-04-25 15:57:06. Total running time: 5min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_6fa3bf75 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    1.53645 â”‚
â”‚ time_total_s                                      327.29217 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_dc87a4e0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_dc87a4e0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.760773 â”‚
â”‚ params/colsample_bytree                     0.771388 â”‚
â”‚ params/learning_rate                        0.173267 â”‚
â”‚ params/max_depth                                   7 â”‚
â”‚ params/min_child_samples                           1 â”‚
â”‚ params/min_child_weight                   0.00108024 â”‚
â”‚ params/reg_alpha                             6.15976 â”‚
â”‚ params/reg_lambda                            3.35489 â”‚
â”‚ params/subsample                            0.618161 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:57:13. Total running time: 6min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:57:43. Total running time: 6min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:58:14. Total running time: 7min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:58:44. Total running time: 7min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:59:14. Total running time: 8min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 15:59:44. Total running time: 8min 30s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:00:14. Total running time: 9min 0s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 4 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:00:44. Total running time: 9min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_21eedc41   RUNNING                 0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364                                                                                                                        â”‚
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8               0.0240841              0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64               0.0899496              0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1               0.00108024             0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046533 seconds.
[36m(RayTrainWorker pid=2591073)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2591073)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2591073)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_21eedc41 completed after 1 iterations at 2025-04-25 16:01:05. Total running time: 9min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_21eedc41 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          275.778 â”‚
â”‚ time_total_s                              275.778 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_ed939181 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ed939181 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.646288 â”‚
â”‚ params/colsample_bytree                      0.967027 â”‚
â”‚ params/learning_rate                         0.659853 â”‚
â”‚ params/max_depth                                   12 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000106202 â”‚
â”‚ params/reg_alpha                             0.558068 â”‚
â”‚ params/reg_lambda                         8.42149e-07 â”‚
â”‚ params/subsample                             0.696157 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 5 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:01:14. Total running time: 10min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_46451abb   RUNNING                 0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06                                                                                                                    â”‚
â”‚ LightGBMTrainer_ede88318   RUNNING                 0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.625237 seconds.
[36m(RayTrainWorker pid=2592402)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2592402)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053974 seconds.
[36m(RayTrainWorker pid=2591182)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2591182)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2592402)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 14x across cluster][0m
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 14x across cluster][0m

Trial LightGBMTrainer_ede88318 completed after 4 iterations at 2025-04-25 16:01:35. Total running time: 10min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ede88318 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.46822 â”‚
â”‚ time_total_s                              280.173 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5d16f50a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5d16f50a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.935438 â”‚
â”‚ params/colsample_bytree                      0.984963 â”‚
â”‚ params/learning_rate                         0.620081 â”‚
â”‚ params/max_depth                                    6 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                   2.24559e-06 â”‚
â”‚ params/reg_alpha                          3.40549e-08 â”‚
â”‚ params/reg_lambda                          2.1901e-06 â”‚
â”‚ params/subsample                             0.611725 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_46451abb completed after 4 iterations at 2025-04-25 16:01:37. Total running time: 10min 23s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_46451abb result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                           0.7503 â”‚
â”‚ time_total_s                              297.572 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.70445 â”‚
â”‚ id_test-average_precision                 0.59614 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65992 â”‚
â”‚ id_test_0-average_precision               0.51837 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70458 â”‚
â”‚ id_test_1-average_precision               0.57629 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68907 â”‚
â”‚ new_ood_test-average_precision            0.73866 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68907 â”‚
â”‚ new_ood_test_1-average_precision          0.73866 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70093 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68837 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67678 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73652 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70093 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59152 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_e955b5e8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_e955b5e8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.768668 â”‚
â”‚ params/colsample_bytree                      0.553555 â”‚
â”‚ params/learning_rate                        0.0126689 â”‚
â”‚ params/max_depth                                   17 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   6.10817e-06 â”‚
â”‚ params/reg_alpha                          4.03624e-07 â”‚
â”‚ params/reg_lambda                         5.15125e-07 â”‚
â”‚ params/subsample                             0.643136 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2591182)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial status: 7 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:01:44. Total running time: 10min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.808752 seconds.
[36m(RayTrainWorker pid=2593303)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 7 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:02:14. Total running time: 11min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_dc87a4e0   RUNNING                 0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489                                                                                                                        â”‚
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2593303)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_dc87a4e0 completed after 10 iterations at 2025-04-25 16:02:33. Total running time: 11min 20s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_dc87a4e0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.98276 â”‚
â”‚ time_total_s                                       324.6857 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bd9dda0a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd9dda0a config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.596556 â”‚
â”‚ params/colsample_bytree                      0.729611 â”‚
â”‚ params/learning_rate                      0.000556346 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   5.41365e-06 â”‚
â”‚ params/reg_alpha                          5.19352e-06 â”‚
â”‚ params/reg_lambda                         1.21963e-08 â”‚
â”‚ params/subsample                              0.74617 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:02:44. Total running time: 11min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:03:14. Total running time: 12min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:03:44. Total running time: 12min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:04:14. Total running time: 13min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:04:45. Total running time: 13min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 8 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:05:15. Total running time: 14min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ed939181   RUNNING                 0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043283 seconds.
[36m(RayTrainWorker pid=2608349)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2608349)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2608349)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_ed939181 completed after 1 iterations at 2025-04-25 16:05:42. Total running time: 14min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_ed939181 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          277.228 â”‚
â”‚ time_total_s                              277.228 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b5b99116 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b5b99116 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.811766 â”‚
â”‚ params/colsample_bytree                    0.983905 â”‚
â”‚ params/learning_rate                      0.0355334 â”‚
â”‚ params/max_depth                                  7 â”‚
â”‚ params/min_child_samples                          8 â”‚
â”‚ params/min_child_weight                     41339.5 â”‚
â”‚ params/reg_alpha                          0.0912562 â”‚
â”‚ params/reg_lambda                         0.0032698 â”‚
â”‚ params/subsample                           0.627821 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 9 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:05:45. Total running time: 14min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5d16f50a   RUNNING                 0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06                                                                                                                     â”‚
â”‚ LightGBMTrainer_e955b5e8   RUNNING                 0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062902 seconds.
[36m(RayTrainWorker pid=2609846)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2609846)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 15x across cluster][0m
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 15x across cluster][0m
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044939 seconds.
[36m(RayTrainWorker pid=2609889)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2609889)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2609846)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial LightGBMTrainer_5d16f50a completed after 4 iterations at 2025-04-25 16:06:12. Total running time: 14min 58s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5d16f50a result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.47077 â”‚
â”‚ time_total_s                              277.058 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_02971b8d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_02971b8d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.722537 â”‚
â”‚ params/colsample_bytree                      0.551055 â”‚
â”‚ params/learning_rate                        0.0466036 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                         41181 â”‚
â”‚ params/reg_alpha                          0.000152476 â”‚
â”‚ params/reg_lambda                            0.527264 â”‚
â”‚ params/subsample                             0.517158 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_e955b5e8 completed after 4 iterations at 2025-04-25 16:06:12. Total running time: 14min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_e955b5e8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.63603 â”‚
â”‚ time_total_s                              275.645 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b8ef9918 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b8ef9918 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.53918 â”‚
â”‚ params/colsample_bytree                      0.705943 â”‚
â”‚ params/learning_rate                       0.00106088 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                     0.0172776 â”‚
â”‚ params/reg_alpha                          3.50454e-06 â”‚
â”‚ params/reg_lambda                         0.000103861 â”‚
â”‚ params/subsample                             0.741189 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 11 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:06:15. Total running time: 15min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2609889)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 11 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:06:45. Total running time: 15min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 11 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:07:15. Total running time: 16min 1s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088828 seconds.
[36m(RayTrainWorker pid=2612812)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2612812)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2612812)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 11 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:07:45. Total running time: 16min 31s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bd9dda0a   RUNNING                 0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bd9dda0a completed after 10 iterations at 2025-04-25 16:07:59. Total running time: 16min 45s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bd9dda0a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.79392 â”‚
â”‚ time_total_s                                      324.06024 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71064 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_802a76bf started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_802a76bf config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.803075 â”‚
â”‚ params/colsample_bytree                       0.71708 â”‚
â”‚ params/learning_rate                      0.000306402 â”‚
â”‚ params/max_depth                                   14 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                     0.0131405 â”‚
â”‚ params/reg_alpha                           0.00116657 â”‚
â”‚ params/reg_lambda                         1.41736e-07 â”‚
â”‚ params/subsample                             0.703283 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 12 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:08:15. Total running time: 17min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:08:45. Total running time: 17min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:09:15. Total running time: 18min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:09:45. Total running time: 18min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 12 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:10:15. Total running time: 19min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b5b99116   RUNNING                 0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698                                                                                                                      â”‚
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_b8ef9918   RUNNING                 0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861                                                                                                                    â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063170 seconds.
[36m(RayTrainWorker pid=2629507)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2629507)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 4x across cluster][0m
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.517050 seconds.
[36m(RayTrainWorker pid=2630825)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 6x across cluster][0m
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047825 seconds.
[36m(RayTrainWorker pid=2630819)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2630819)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2629507)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 23x across cluster][0m
[36m(RayTrainWorker pid=2630825)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 23x across cluster][0m

Trial LightGBMTrainer_b5b99116 completed after 1 iterations at 2025-04-25 16:10:41. Total running time: 19min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b5b99116 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          299.057 â”‚
â”‚ time_total_s                              299.057 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_0102a201 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0102a201 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.703184 â”‚
â”‚ params/colsample_bytree                      0.687447 â”‚
â”‚ params/learning_rate                         0.038339 â”‚
â”‚ params/max_depth                                   21 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                        197.21 â”‚
â”‚ params/reg_alpha                          8.53002e-06 â”‚
â”‚ params/reg_lambda                         3.04949e-08 â”‚
â”‚ params/subsample                             0.993056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b8ef9918 completed after 4 iterations at 2025-04-25 16:10:43. Total running time: 19min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b8ef9918 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.47832 â”‚
â”‚ time_total_s                              270.764 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.70445 â”‚
â”‚ id_test-average_precision                 0.59614 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65992 â”‚
â”‚ id_test_0-average_precision               0.51837 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70458 â”‚
â”‚ id_test_1-average_precision               0.57629 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68907 â”‚
â”‚ new_ood_test-average_precision            0.73866 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68907 â”‚
â”‚ new_ood_test_1-average_precision          0.73866 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70093 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68837 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67678 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73652 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70093 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59152 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_e41b2b42 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_e41b2b42 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.604319 â”‚
â”‚ params/colsample_bytree                      0.621564 â”‚
â”‚ params/learning_rate                      2.58761e-05 â”‚
â”‚ params/max_depth                                   24 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.22199e-08 â”‚
â”‚ params/reg_alpha                          1.17838e-06 â”‚
â”‚ params/reg_lambda                          0.00859442 â”‚
â”‚ params/subsample                             0.953705 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 14 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:10:45. Total running time: 19min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_02971b8d   RUNNING                 0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264                                                                                                                       â”‚
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Info] Start training from score -0.400412[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2630819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 11x across cluster][0m

Trial LightGBMTrainer_02971b8d completed after 4 iterations at 2025-04-25 16:10:48. Total running time: 19min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_02971b8d result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.57059 â”‚
â”‚ time_total_s                               276.28 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_a8d48a37 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a8d48a37 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.637239 â”‚
â”‚ params/colsample_bytree                      0.691992 â”‚
â”‚ params/learning_rate                      0.000406627 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                           16 â”‚
â”‚ params/min_child_weight                      0.223195 â”‚
â”‚ params/reg_alpha                            0.0096948 â”‚
â”‚ params/reg_lambda                         2.09777e-08 â”‚
â”‚ params/subsample                             0.621653 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 15 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:11:15. Total running time: 20min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 15 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:11:45. Total running time: 20min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 15 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:12:15. Total running time: 21min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07                                                                                                                    â”‚
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048056 seconds.
[36m(RayTrainWorker pid=2634181)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2634181)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2634181)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 15 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:12:45. Total running time: 21min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_802a76bf   RUNNING                 0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07        9            286.291               0.332372      0.712446                 0.612144                 0.399637 â”‚
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_802a76bf completed after 10 iterations at 2025-04-25 16:12:47. Total running time: 21min 34s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_802a76bf result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.63889 â”‚
â”‚ time_total_s                                      286.93024 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_7583531c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7583531c config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.733572 â”‚
â”‚ params/colsample_bytree                      0.819417 â”‚
â”‚ params/learning_rate                       5.2365e-05 â”‚
â”‚ params/max_depth                                   13 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                   4.97276e-08 â”‚
â”‚ params/reg_alpha                          4.79278e-07 â”‚
â”‚ params/reg_lambda                             1.41961 â”‚
â”‚ params/subsample                             0.882547 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 16 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:13:15. Total running time: 22min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:13:46. Total running time: 22min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:14:16. Total running time: 23min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:14:46. Total running time: 23min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
Trial status: 16 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:15:16. Total running time: 24min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_0102a201   RUNNING                 0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_a8d48a37   RUNNING                 0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08                                                                                                                    â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108844 seconds.
[36m(RayTrainWorker pid=2648137)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2648137)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057154 seconds.
[36m(RayTrainWorker pid=2649329)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2649329)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2648137)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_0102a201 completed after 1 iterations at 2025-04-25 16:15:27. Total running time: 24min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_0102a201 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          285.544 â”‚
â”‚ time_total_s                              285.544 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_c5d78e0d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c5d78e0d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.969746 â”‚
â”‚ params/colsample_bytree                      0.905728 â”‚
â”‚ params/learning_rate                          0.20716 â”‚
â”‚ params/max_depth                                   26 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   0.000257846 â”‚
â”‚ params/reg_alpha                           0.00479202 â”‚
â”‚ params/reg_lambda                             95.1868 â”‚
â”‚ params/subsample                             0.809168 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 15x across cluster][0m
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 15x across cluster][0m
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=2649329)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m

Trial LightGBMTrainer_a8d48a37 completed after 4 iterations at 2025-04-25 16:15:37. Total running time: 24min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a8d48a37 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          1.70973 â”‚
â”‚ time_total_s                              288.938 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_f0e023f4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f0e023f4 config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.871404 â”‚
â”‚ params/colsample_bytree                    0.792455 â”‚
â”‚ params/learning_rate                       0.153735 â”‚
â”‚ params/max_depth                                  4 â”‚
â”‚ params/min_child_samples                          2 â”‚
â”‚ params/min_child_weight                     1.26818 â”‚
â”‚ params/reg_alpha                           0.346621 â”‚
â”‚ params/reg_lambda                         0.0679295 â”‚
â”‚ params/subsample                           0.526094 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190091 seconds.
[36m(RayTrainWorker pid=2648157)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial status: 18 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:15:46. Total running time: 24min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442                                                                                                                     â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
13 more TERMINATED
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2648157)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 18 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:16:16. Total running time: 25min 2s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_e41b2b42   RUNNING                 2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442         1            330.799               0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
13 more TERMINATED

Trial LightGBMTrainer_e41b2b42 completed after 4 iterations at 2025-04-25 16:16:20. Total running time: 25min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_e41b2b42 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.75186 â”‚
â”‚ time_total_s                              336.221 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_c8a0ba1f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c8a0ba1f config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.856849 â”‚
â”‚ params/colsample_bytree                      0.893839 â”‚
â”‚ params/learning_rate                       0.00544341 â”‚
â”‚ params/max_depth                                   22 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000170553 â”‚
â”‚ params/reg_alpha                              4.73203 â”‚
â”‚ params/reg_lambda                             85.3003 â”‚
â”‚ params/subsample                             0.829095 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 19 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:16:46. Total running time: 25min 32s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
14 more TERMINATED
Trial status: 19 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:17:16. Total running time: 26min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961                                                                                                                        â”‚
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
14 more TERMINATED
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050020 seconds.
[36m(RayTrainWorker pid=2652990)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2652990)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2652990)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 19 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:17:46. Total running time: 26min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_7583531c   RUNNING                 5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961            6            295.544               0.33502       0.710027                 0.60812                  0.407766 â”‚
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
14 more TERMINATED

Trial LightGBMTrainer_7583531c completed after 10 iterations at 2025-04-25 16:17:54. Total running time: 26min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_7583531c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.75464 â”‚
â”‚ time_total_s                                      304.23532 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                          0.5427 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71437 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37483 â”‚
â”‚ ood_test_2-auc                                      0.68585 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39695 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69624 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_97eb69d5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_97eb69d5 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.504539 â”‚
â”‚ params/colsample_bytree                      0.777786 â”‚
â”‚ params/learning_rate                         0.265352 â”‚
â”‚ params/max_depth                                    8 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   2.55049e-07 â”‚
â”‚ params/reg_alpha                            0.0248841 â”‚
â”‚ params/reg_lambda                             14.5551 â”‚
â”‚ params/subsample                             0.571816 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 20 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:18:16. Total running time: 27min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:18:46. Total running time: 27min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:19:16. Total running time: 28min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
Trial status: 20 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:19:46. Total running time: 28min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054308 seconds.
[36m(RayTrainWorker pid=2667495)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2667495)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 20 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:20:16. Total running time: 29min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c5d78e0d   RUNNING                 0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868                                                                                                                         â”‚
â”‚ LightGBMTrainer_f0e023f4   RUNNING                 0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295                                                                                                                      â”‚
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 7x across cluster][0m
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045990 seconds.
[36m(RayTrainWorker pid=2667591)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2667591)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2667495)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_c5d78e0d completed after 1 iterations at 2025-04-25 16:20:20. Total running time: 29min 7s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c5d78e0d result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          293.141 â”‚
â”‚ time_total_s                              293.141 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_06e29a47 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_06e29a47 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.997656 â”‚
â”‚ params/colsample_bytree                     0.902631 â”‚
â”‚ params/learning_rate                        0.109943 â”‚
â”‚ params/max_depth                                  11 â”‚
â”‚ params/min_child_samples                          32 â”‚
â”‚ params/min_child_weight                   0.00141702 â”‚
â”‚ params/reg_alpha                             91.8973 â”‚
â”‚ params/reg_lambda                           0.112889 â”‚
â”‚ params/subsample                            0.689328 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 13x across cluster][0m
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 13x across cluster][0m
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2667591)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051930 seconds.
[36m(RayTrainWorker pid=2670168)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2670168)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101

Trial LightGBMTrainer_f0e023f4 completed after 4 iterations at 2025-04-25 16:20:26. Total running time: 29min 12s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_f0e023f4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.54014 â”‚
â”‚ time_total_s                              288.558 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b2a3eb8c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b2a3eb8c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.548451 â”‚
â”‚ params/colsample_bytree                     0.610727 â”‚
â”‚ params/learning_rate                        0.994912 â”‚
â”‚ params/max_depth                                  30 â”‚
â”‚ params/min_child_samples                           4 â”‚
â”‚ params/min_child_weight                       2.3533 â”‚
â”‚ params/reg_alpha                          0.00115674 â”‚
â”‚ params/reg_lambda                            18.0094 â”‚
â”‚ params/subsample                            0.887527 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 5x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m

Trial status: 22 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:20:46. Total running time: 29min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_c8a0ba1f   RUNNING                 0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003                                                                                                                         â”‚
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
17 more TERMINATED
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 3x across cluster][0m
[36m(RayTrainWorker pid=2670168)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 3x across cluster][0m

Trial LightGBMTrainer_c8a0ba1f completed after 4 iterations at 2025-04-25 16:20:56. Total running time: 29min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_c8a0ba1f result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.98341 â”‚
â”‚ time_total_s                              276.376 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_12f7c3e4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_12f7c3e4 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.781389 â”‚
â”‚ params/colsample_bytree                      0.762971 â”‚
â”‚ params/learning_rate                         0.010953 â”‚
â”‚ params/max_depth                                    2 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                    3.7798e-05 â”‚
â”‚ params/reg_alpha                          1.11727e-08 â”‚
â”‚ params/reg_lambda                           0.0512731 â”‚
â”‚ params/subsample                             0.775533 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 23 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:21:16. Total running time: 30min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
Trial status: 23 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:21:46. Total running time: 30min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
Trial status: 23 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:22:16. Total running time: 31min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049627 seconds.
[36m(RayTrainWorker pid=2672099)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2672099)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 23 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:22:47. Total running time: 31min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_97eb69d5   RUNNING                 0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551                                                                                                                         â”‚
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2672099)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_97eb69d5 completed after 10 iterations at 2025-04-25 16:23:00. Total running time: 31min 46s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_97eb69d5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                     1.0674 â”‚
â”‚ time_total_s                                      304.57905 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71064 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_a3a6ff7c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a3a6ff7c config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.852323 â”‚
â”‚ params/colsample_bytree                      0.867583 â”‚
â”‚ params/learning_rate                       0.00287042 â”‚
â”‚ params/max_depth                                   23 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   4.73904e-07 â”‚
â”‚ params/reg_alpha                          0.000322737 â”‚
â”‚ params/reg_lambda                              10.806 â”‚
â”‚ params/subsample                             0.848383 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 24 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:23:17. Total running time: 32min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:23:47. Total running time: 32min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:24:17. Total running time: 33min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
Trial status: 24 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:24:47. Total running time: 33min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_06e29a47   RUNNING                 0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889                                                                                                                       â”‚
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058815 seconds.
[36m(RayTrainWorker pid=2686705)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2686705)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2686705)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_06e29a47 completed after 1 iterations at 2025-04-25 16:25:05. Total running time: 33min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_06e29a47 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          285.416 â”‚
â”‚ time_total_s                              285.416 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_1fb0f074 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1fb0f074 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.960624 â”‚
â”‚ params/colsample_bytree                      0.935799 â”‚
â”‚ params/learning_rate                         0.451279 â”‚
â”‚ params/max_depth                                   28 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   2.22671e-05 â”‚
â”‚ params/reg_alpha                              1.96653 â”‚
â”‚ params/reg_lambda                            0.230377 â”‚
â”‚ params/subsample                             0.781356 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109389 seconds.
[36m(RayTrainWorker pid=2688274)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2688274)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 11x across cluster][0m
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 11x across cluster][0m

Trial status: 25 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:25:17. Total running time: 34min 3s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b2a3eb8c   RUNNING                 0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094                                                                                                                         â”‚
â”‚ LightGBMTrainer_12f7c3e4   RUNNING                 0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731                                                                                                                      â”‚
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
20 more TERMINATED
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056344 seconds.
[36m(RayTrainWorker pid=2686820)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2686820)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] Total Bins 367
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 9x across cluster][0m
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2688274)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2686820)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_12f7c3e4 completed after 4 iterations at 2025-04-25 16:25:41. Total running time: 34min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_12f7c3e4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.56678 â”‚
â”‚ time_total_s                              284.798 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.70445 â”‚
â”‚ id_test-average_precision                 0.59614 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65992 â”‚
â”‚ id_test_0-average_precision               0.51837 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70458 â”‚
â”‚ id_test_1-average_precision               0.57629 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68907 â”‚
â”‚ new_ood_test-average_precision            0.73866 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68907 â”‚
â”‚ new_ood_test_1-average_precision          0.73866 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70093 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68837 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67678 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73652 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70093 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59152 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_49861b35 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_49861b35 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.686965 â”‚
â”‚ params/colsample_bytree                     0.748428 â”‚
â”‚ params/learning_rate                       0.0916704 â”‚
â”‚ params/max_depth                                  20 â”‚
â”‚ params/min_child_samples                           4 â”‚
â”‚ params/min_child_weight                   0.00128307 â”‚
â”‚ params/reg_alpha                             36.9928 â”‚
â”‚ params/reg_lambda                            1.63558 â”‚
â”‚ params/subsample                            0.570614 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b2a3eb8c completed after 4 iterations at 2025-04-25 16:25:43. Total running time: 34min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b2a3eb8c result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.45793 â”‚
â”‚ time_total_s                              316.757 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3a747344 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3a747344 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                      0.88375 â”‚
â”‚ params/colsample_bytree                      0.807232 â”‚
â”‚ params/learning_rate                       0.00268677 â”‚
â”‚ params/max_depth                                   15 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   1.52971e-08 â”‚
â”‚ params/reg_alpha                            0.0535184 â”‚
â”‚ params/reg_lambda                           0.0152581 â”‚
â”‚ params/subsample                             0.937946 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 27 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:25:47. Total running time: 34min 33s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
Trial status: 27 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:26:17. Total running time: 35min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
Trial status: 27 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:26:47. Total running time: 35min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
Trial status: 27 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:27:17. Total running time: 36min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 27 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:27:47. Total running time: 36min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_a3a6ff7c   RUNNING                 0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806                                                                                                                          â”‚
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058458 seconds.
[36m(RayTrainWorker pid=2691286)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2691286)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] Total Bins 370
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2691286)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_a3a6ff7c completed after 10 iterations at 2025-04-25 16:28:17. Total running time: 37min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_a3a6ff7c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.76116 â”‚
â”‚ time_total_s                                      315.37428 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71064 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_100711e1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_100711e1 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.934131 â”‚
â”‚ params/colsample_bytree                      0.944413 â”‚
â”‚ params/learning_rate                        0.0168798 â”‚
â”‚ params/max_depth                                   -1 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                       8.87413 â”‚
â”‚ params/reg_alpha                            0.0023856 â”‚
â”‚ params/reg_lambda                         0.000265596 â”‚
â”‚ params/subsample                             0.726019 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 28 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:28:17. Total running time: 37min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
Trial status: 28 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:28:47. Total running time: 37min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
Trial status: 28 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:29:17. Total running time: 38min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
Trial status: 28 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:29:47. Total running time: 38min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1fb0f074   RUNNING                 0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377                                                                                                                       â”‚
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079516 seconds.
[36m(RayTrainWorker pid=2705727)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2705727)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584

Trial LightGBMTrainer_1fb0f074 completed after 1 iterations at 2025-04-25 16:30:05. Total running time: 38min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1fb0f074 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          299.892 â”‚
â”‚ time_total_s                              299.892 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_76202fc9 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_76202fc9 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.829058 â”‚
â”‚ params/colsample_bytree                      0.861472 â”‚
â”‚ params/learning_rate                         0.944078 â”‚
â”‚ params/max_depth                                    9 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                      0.368615 â”‚
â”‚ params/reg_alpha                          0.000187504 â”‚
â”‚ params/reg_lambda                             88.4449 â”‚
â”‚ params/subsample                              0.85096 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.591047 seconds.
[36m(RayTrainWorker pid=2707275)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 29 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:30:17. Total running time: 39min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_49861b35   RUNNING                 0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558                                                                                                                        â”‚
â”‚ LightGBMTrainer_3a747344   RUNNING                 0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581                                                                                                                      â”‚
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4              0.368615                0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2707275)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106381 seconds.
[36m(RayTrainWorker pid=2707295)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial LightGBMTrainer_49861b35 completed after 4 iterations at 2025-04-25 16:30:29. Total running time: 39min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_49861b35 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          2.89019 â”‚
â”‚ time_total_s                              287.416 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_fb95afc8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fb95afc8 config              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.904 â”‚
â”‚ params/colsample_bytree                   0.651472 â”‚
â”‚ params/learning_rate                      0.351576 â”‚
â”‚ params/max_depth                                18 â”‚
â”‚ params/min_child_samples                         2 â”‚
â”‚ params/min_child_weight                    238.421 â”‚
â”‚ params/reg_alpha                          0.356399 â”‚
â”‚ params/reg_lambda                         0.500213 â”‚
â”‚ params/subsample                          0.672705 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2707295)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_3a747344 completed after 4 iterations at 2025-04-25 16:30:47. Total running time: 39min 33s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3a747344 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          2.04494 â”‚
â”‚ time_total_s                              303.745 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3b82f6fc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b82f6fc config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.764215 â”‚
â”‚ params/colsample_bytree                     0.829519 â”‚
â”‚ params/learning_rate                       0.0817725 â”‚
â”‚ params/max_depth                                  10 â”‚
â”‚ params/min_child_samples                           1 â”‚
â”‚ params/min_child_weight                    0.0027319 â”‚
â”‚ params/reg_alpha                             8.25766 â”‚
â”‚ params/reg_lambda                         0.00179269 â”‚
â”‚ params/subsample                            0.598393 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 31 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:30:47. Total running time: 39min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32               8.87413                0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
Trial status: 31 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:31:18. Total running time: 40min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32               8.87413                0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
Trial status: 31 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:31:48. Total running time: 40min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32               8.87413                0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
Trial status: 31 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:32:18. Total running time: 41min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32               8.87413                0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
Trial status: 31 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:32:48. Total running time: 41min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_100711e1   RUNNING                 0.0168798                         32               8.87413                0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596                                                                                                                    â”‚
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047749 seconds.
[36m(RayTrainWorker pid=2710693)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2710693)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2710693)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_100711e1 completed after 10 iterations at 2025-04-25 16:33:14. Total running time: 42min 1s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_100711e1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                       0.72 â”‚
â”‚ time_total_s                                      295.68997 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bdf133bc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bdf133bc config               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                   0.999156 â”‚
â”‚ params/colsample_bytree                    0.874399 â”‚
â”‚ params/learning_rate                      0.0189679 â”‚
â”‚ params/max_depth                                  6 â”‚
â”‚ params/min_child_samples                         32 â”‚
â”‚ params/min_child_weight                   1.269e-06 â”‚
â”‚ params/reg_alpha                          0.0211605 â”‚
â”‚ params/reg_lambda                             4.403 â”‚
â”‚ params/subsample                           0.545037 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 32 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:33:18. Total running time: 42min 4s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32               1.269e-06              0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
Trial status: 32 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:33:48. Total running time: 42min 34s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32               1.269e-06              0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
Trial status: 32 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:34:18. Total running time: 43min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32               1.269e-06              0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.288348 seconds.
[36m(RayTrainWorker pid=2723950)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2723950)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 32 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:34:48. Total running time: 43min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_76202fc9   RUNNING                 0.944078                           4               0.368615               0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449                                                                                                                         â”‚
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32               1.269e-06              0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2723950)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_76202fc9 completed after 1 iterations at 2025-04-25 16:34:58. Total running time: 43min 44s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_76202fc9 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          292.291 â”‚
â”‚ time_total_s                              292.291 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b170508b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b170508b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.968069 â”‚
â”‚ params/colsample_bytree                      0.506933 â”‚
â”‚ params/learning_rate                       0.00612233 â”‚
â”‚ params/max_depth                                    1 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                    0.00067453 â”‚
â”‚ params/reg_alpha                          7.38577e-08 â”‚
â”‚ params/reg_lambda                         4.44201e-05 â”‚
â”‚ params/subsample                             0.662325 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047985 seconds.
[36m(RayTrainWorker pid=2725258)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2725258)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 33 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:35:18. Total running time: 44min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fb95afc8   RUNNING                 0.351576                           2             238.421                  0.672705                   18                 0.651472                 0.904             0.356399              0.500213                                                                                                                       â”‚
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1               0.0027319              0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32               1.269e-06              0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8               0.00067453             0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
28 more TERMINATED
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2725258)[0m [LightGBM] [Info] Start training from score -0.400412
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial LightGBMTrainer_fb95afc8 completed after 4 iterations at 2025-04-25 16:35:31. Total running time: 44min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fb95afc8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.98822 â”‚
â”‚ time_total_s                              302.268 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_bf4adf72 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bf4adf72 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.588331 â”‚
â”‚ params/colsample_bytree                      0.930236 â”‚
â”‚ params/learning_rate                      1.16285e-05 â”‚
â”‚ params/max_depth                                    3 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   3.52829e-05 â”‚
â”‚ params/reg_alpha                          2.09367e-05 â”‚
â”‚ params/reg_lambda                           0.0209557 â”‚
â”‚ params/subsample                             0.717971 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055981 seconds.
[36m(RayTrainWorker pid=2726544)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2726544)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 34 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:35:48. Total running time: 44min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_3b82f6fc   RUNNING                 0.0817725                          1              0.0027319               0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269                                                                                                                     â”‚
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2726544)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_3b82f6fc completed after 4 iterations at 2025-04-25 16:35:55. Total running time: 44min 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3b82f6fc result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.60727 â”‚
â”‚ time_total_s                              308.018 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_b1f50172 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b1f50172 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.657191 â”‚
â”‚ params/colsample_bytree                     0.742876 â”‚
â”‚ params/learning_rate                      0.00157208 â”‚
â”‚ params/max_depth                                   6 â”‚
â”‚ params/min_child_samples                          16 â”‚
â”‚ params/min_child_weight                   0.00891782 â”‚
â”‚ params/reg_alpha                              1.6837 â”‚
â”‚ params/reg_lambda                            38.4219 â”‚
â”‚ params/subsample                            0.799196 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 35 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:36:18. Total running time: 45min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
Trial status: 35 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:36:48. Total running time: 45min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
Trial status: 35 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:37:18. Total running time: 46min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051331 seconds.
[36m(RayTrainWorker pid=2728782)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2728782)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 35 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:37:48. Total running time: 46min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403                                                                                                                          â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2728782)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 35 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:38:18. Total running time: 47min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bdf133bc   RUNNING                 0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403             10            298.564               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED

Trial LightGBMTrainer_bdf133bc completed after 10 iterations at 2025-04-25 16:38:19. Total running time: 47min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bdf133bc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                      2.046 â”‚
â”‚ time_total_s                                      298.56399 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_fa84763d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fa84763d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.742015 â”‚
â”‚ params/colsample_bytree                      0.794599 â”‚
â”‚ params/learning_rate                         0.629245 â”‚
â”‚ params/max_depth                                   16 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                        29.699 â”‚
â”‚ params/reg_alpha                          6.94106e-05 â”‚
â”‚ params/reg_lambda                         0.000464206 â”‚
â”‚ params/subsample                             0.764339 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 36 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:38:48. Total running time: 47min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
Trial status: 36 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:39:18. Total running time: 48min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045227 seconds.
[36m(RayTrainWorker pid=2743133)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2743133)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 36 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:39:48. Total running time: 48min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b170508b   RUNNING                 0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2743133)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_b170508b completed after 1 iterations at 2025-04-25 16:39:57. Total running time: 48min 44s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b170508b result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          299.078 â”‚
â”‚ time_total_s                              299.078 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_002727bc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_002727bc config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.501633 â”‚
â”‚ params/colsample_bytree                      0.836194 â”‚
â”‚ params/learning_rate                      0.000172774 â”‚
â”‚ params/max_depth                                   29 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   2.06063e-07 â”‚
â”‚ params/reg_alpha                              43.6926 â”‚
â”‚ params/reg_lambda                             4.64604 â”‚
â”‚ params/subsample                             0.931723 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212444 seconds.
[36m(RayTrainWorker pid=2744576)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] Total Bins 374
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101

Trial status: 37 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:40:18. Total running time: 49min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_bf4adf72   RUNNING                 1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557                                                                                                                      â”‚
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
32 more TERMINATED
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2744576)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_bf4adf72 completed after 4 iterations at 2025-04-25 16:40:31. Total running time: 49min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_bf4adf72 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.59744 â”‚
â”‚ time_total_s                               299.49 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_910a868b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_910a868b config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.837346 â”‚
â”‚ params/colsample_bytree                      0.997936 â”‚
â”‚ params/learning_rate                        0.0611678 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                            4 â”‚
â”‚ params/min_child_weight                   4.05784e-06 â”‚
â”‚ params/reg_alpha                             0.152169 â”‚
â”‚ params/reg_lambda                           0.0043381 â”‚
â”‚ params/subsample                             0.643212 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048645 seconds.
[36m(RayTrainWorker pid=2745827)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2745827)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.

Trial status: 38 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:40:48. Total running time: 49min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_b1f50172   RUNNING                 0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219                                                                                                                         â”‚
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2745827)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_b1f50172 completed after 4 iterations at 2025-04-25 16:41:04. Total running time: 49min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_b1f50172 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.72288 â”‚
â”‚ time_total_s                              309.197 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_aad9df94 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_aad9df94 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.794869 â”‚
â”‚ params/colsample_bytree                      0.962538 â”‚
â”‚ params/learning_rate                        0.0250033 â”‚
â”‚ params/max_depth                                   12 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                   2.54441e-05 â”‚
â”‚ params/reg_alpha                          0.000389491 â”‚
â”‚ params/reg_lambda                            0.913272 â”‚
â”‚ params/subsample                             0.594122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 39 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:41:19. Total running time: 50min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
Trial status: 39 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:41:49. Total running time: 50min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
Trial status: 39 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:42:19. Total running time: 51min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
Trial status: 39 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:42:49. Total running time: 51min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206                                                                                                                    â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081853 seconds.
[36m(RayTrainWorker pid=2748121)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2748121)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 39 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:43:19. Total running time: 52min 5s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_fa84763d   RUNNING                 0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206        2            299.808               0.358161      0.700862                 0.594422                 0.443773 â”‚
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
34 more TERMINATED

Trial LightGBMTrainer_fa84763d completed after 10 iterations at 2025-04-25 16:43:43. Total running time: 52min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_fa84763d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    2.67871 â”‚
â”‚ time_total_s                                      323.09885 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_1dfeddf8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1dfeddf8 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.909383 â”‚
â”‚ params/colsample_bytree                      0.662231 â”‚
â”‚ params/learning_rate                         0.160303 â”‚
â”‚ params/max_depth                                   19 â”‚
â”‚ params/min_child_samples                           32 â”‚
â”‚ params/min_child_weight                       2046.88 â”‚
â”‚ params/reg_alpha                           0.00693226 â”‚
â”‚ params/reg_lambda                         1.31376e-05 â”‚
â”‚ params/subsample                             0.827037 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 40 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:43:49. Total running time: 52min 35s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
Trial status: 40 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:44:19. Total running time: 53min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046852 seconds.
[36m(RayTrainWorker pid=2762481)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2762481)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2762481)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 40 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:44:49. Total running time: 53min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_002727bc   RUNNING                 0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604                                                                                                                        â”‚
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED

Trial LightGBMTrainer_002727bc completed after 1 iterations at 2025-04-25 16:44:49. Total running time: 53min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_002727bc result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          292.225 â”‚
â”‚ time_total_s                              292.225 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_11a478fa started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_11a478fa config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.619234 â”‚
â”‚ params/colsample_bytree                     0.591924 â”‚
â”‚ params/learning_rate                      0.00553359 â”‚
â”‚ params/max_depth                                   5 â”‚
â”‚ params/min_child_samples                           1 â”‚
â”‚ params/min_child_weight                      0.08099 â”‚
â”‚ params/reg_alpha                          2.3346e-05 â”‚
â”‚ params/reg_lambda                           0.263059 â”‚
â”‚ params/subsample                            0.978608 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 41 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:45:19. Total running time: 54min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_910a868b   RUNNING                 0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381                                                                                                                      â”‚
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1              0.08099                 0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
36 more TERMINATED
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055719 seconds.
[36m(RayTrainWorker pid=2764000)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2764000)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2764000)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_910a868b completed after 4 iterations at 2025-04-25 16:45:31. Total running time: 54min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_910a868b result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          1.70449 â”‚
â”‚ time_total_s                              300.293 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_333f353f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_333f353f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                    0.710393 â”‚
â”‚ params/colsample_bytree                     0.761905 â”‚
â”‚ params/learning_rate                        0.312478 â”‚
â”‚ params/max_depth                                  17 â”‚
â”‚ params/min_child_samples                          16 â”‚
â”‚ params/min_child_weight                   0.00557031 â”‚
â”‚ params/reg_alpha                             1.23057 â”‚
â”‚ params/reg_lambda                            31.2606 â”‚
â”‚ params/subsample                            0.507655 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 42 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:45:49. Total running time: 54min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_aad9df94   RUNNING                 0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272                                                                                                                       â”‚
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1              0.08099                 0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16              0.00557031              0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
37 more TERMINATED
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085580 seconds.
[36m(RayTrainWorker pid=2765398)[0m You can set `force_col_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2765398)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_aad9df94 completed after 4 iterations at 2025-04-25 16:46:14. Total running time: 55min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_aad9df94 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.81721 â”‚
â”‚ time_total_s                              309.437 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_26147f95 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_26147f95 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.683126 â”‚
â”‚ params/colsample_bytree                      0.856989 â”‚
â”‚ params/learning_rate                       0.00940788 â”‚
â”‚ params/max_depth                                   14 â”‚
â”‚ params/min_child_samples                           64 â”‚
â”‚ params/min_child_weight                     0.0422841 â”‚
â”‚ params/reg_alpha                          1.15817e-07 â”‚
â”‚ params/reg_lambda                              4.0866 â”‚
â”‚ params/subsample                             0.682389 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:46:19. Total running time: 55min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:46:49. Total running time: 55min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:47:19. Total running time: 56min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:47:49. Total running time: 56min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:48:19. Total running time: 57min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05                                                                                                                    â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054331 seconds.
[36m(RayTrainWorker pid=2770511)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2770511)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2770511)[0m [LightGBM] [Info] Start training from score -0.400412
Trial status: 43 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:48:49. Total running time: 57min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_1dfeddf8   RUNNING                 0.160303                          32            2046.88                   0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05        8            305.498               0.33277       0.711799                 0.611145                 0.39888  â”‚
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1               0.08099                0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16               0.00557031             0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64               0.0422841              0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8              31.1567                 0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4              88.6536                 0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2               1.5737e-05             0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64               0.00324906             0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32            5054.73                   0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED

Trial LightGBMTrainer_1dfeddf8 completed after 10 iterations at 2025-04-25 16:48:53. Total running time: 57min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_1dfeddf8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.73817 â”‚
â”‚ time_total_s                                       307.6877 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5430dae5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5430dae5 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.561342 â”‚
â”‚ params/colsample_bytree                      0.920855 â”‚
â”‚ params/learning_rate                        0.0320186 â”‚
â”‚ params/max_depth                                   27 â”‚
â”‚ params/min_child_samples                            2 â”‚
â”‚ params/min_child_weight                   9.51042e-06 â”‚
â”‚ params/reg_alpha                          1.95265e-06 â”‚
â”‚ params/reg_lambda                           0.0306473 â”‚
â”‚ params/subsample                             0.752059 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 44 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:49:19. Total running time: 58min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1              0.08099                 0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16              0.00557031              0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64              0.0422841               0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048144 seconds.
[36m(RayTrainWorker pid=2781555)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2781555)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 44 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:49:49. Total running time: 58min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_11a478fa   RUNNING                 0.00553359                         1              0.08099                 0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059                                                                                                                       â”‚
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16              0.00557031              0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64              0.0422841               0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2781555)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_11a478fa completed after 1 iterations at 2025-04-25 16:49:56. Total running time: 58min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_11a478fa result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          306.643 â”‚
â”‚ time_total_s                              306.643 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_5834e8d6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5834e8d6 config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.951942 â”‚
â”‚ params/colsample_bytree                       0.72594 â”‚
â”‚ params/learning_rate                         0.942117 â”‚
â”‚ params/max_depth                                    7 â”‚
â”‚ params/min_child_samples                            8 â”‚
â”‚ params/min_child_weight                   1.80199e-06 â”‚
â”‚ params/reg_alpha                           0.00284424 â”‚
â”‚ params/reg_lambda                           0.0011101 â”‚
â”‚ params/subsample                             0.543482 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.323069 seconds.
[36m(RayTrainWorker pid=2783058)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2783058)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] Total Bins 372
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101

Trial status: 45 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:50:19. Total running time: 59min 6s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_333f353f   RUNNING                 0.312478                          16              0.00557031              0.507655                   17                 0.761905                 0.710393          1.23057              31.2606                                                                                                                         â”‚
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64              0.0422841               0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2783058)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_333f353f completed after 4 iterations at 2025-04-25 16:50:29. Total running time: 59min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_333f353f result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.53195 â”‚
â”‚ time_total_s                              297.589 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.70445 â”‚
â”‚ id_test-average_precision                 0.59614 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65992 â”‚
â”‚ id_test_0-average_precision               0.51837 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70458 â”‚
â”‚ id_test_1-average_precision               0.57629 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68907 â”‚
â”‚ new_ood_test-average_precision            0.73866 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68907 â”‚
â”‚ new_ood_test_1-average_precision          0.73866 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70093 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68837 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67678 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73652 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70093 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59152 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial LightGBMTrainer_3f502e7d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3f502e7d config                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ params/colsample_bylevel                     0.757567 â”‚
â”‚ params/colsample_bytree                      0.968304 â”‚
â”‚ params/learning_rate                        0.0645171 â”‚
â”‚ params/max_depth                                   25 â”‚
â”‚ params/min_child_samples                            1 â”‚
â”‚ params/min_child_weight                   0.000358938 â”‚
â”‚ params/reg_alpha                          8.33987e-05 â”‚
â”‚ params/reg_lambda                            0.155997 â”‚
â”‚ params/subsample                             0.718718 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.317419 seconds.
[36m(RayTrainWorker pid=2784543)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2784543)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] Total Bins 369
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 100

Trial status: 46 TERMINATED | 4 RUNNING
Current time: 2025-04-25 16:50:50. Total running time: 59min 36s
Logical resource usage: 4.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_26147f95   RUNNING                 0.00940788                        64              0.0422841               0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866                                                                                                                         â”‚
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
41 more TERMINATED
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2784543)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_26147f95 completed after 4 iterations at 2025-04-25 16:51:06. Total running time: 59min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_26147f95 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          1.52202 â”‚
â”‚ time_total_s                              292.129 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                               0.69958 â”‚
â”‚ id_test-average_precision                 0.59425 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                              0.6589 â”‚
â”‚ id_test_0-average_precision               0.52188 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69916 â”‚
â”‚ id_test_1-average_precision               0.57396 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68873 â”‚
â”‚ id_test_4-average_precision               0.69738 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68647 â”‚
â”‚ new_ood_test-average_precision            0.73956 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68647 â”‚
â”‚ new_ood_test_1-average_precision          0.73956 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.69539 â”‚
â”‚ new_train-average_precision               0.58787 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68563 â”‚
â”‚ ood_test-average_precision                0.73857 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67265 â”‚
â”‚ ood_test_2-average_precision              0.66898 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66825 â”‚
â”‚ ood_test_3-average_precision              0.78164 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68586 â”‚
â”‚ ood_validation-average_precision          0.73747 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.68445 â”‚
â”‚ oracle-average_precision                   0.7372 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.69539 â”‚
â”‚ train-average_precision                   0.58787 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.69361 â”‚
â”‚ validation-average_precision              0.58811 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:51:20. Total running time: 1hr 0min 6s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:51:50. Total running time: 1hr 0min 36s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:52:20. Total running time: 1hr 1min 6s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:52:50. Total running time: 1hr 1min 37s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.555669 seconds.
[36m(RayTrainWorker pid=2795819)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2795819)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
Trial status: 47 TERMINATED | 3 RUNNING
Current time: 2025-04-25 16:53:20. Total running time: 1hr 2min 7s
Logical resource usage: 3.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5430dae5   RUNNING                 0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473                                                                                                                      â”‚
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2795819)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_5430dae5 completed after 10 iterations at 2025-04-25 16:53:33. Total running time: 1hr 2min 20s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5430dae5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                       checkpoint_000000 â”‚
â”‚ time_this_iter_s                                    0.60807 â”‚
â”‚ time_total_s                                      278.61269 â”‚
â”‚ training_iteration                                       10 â”‚
â”‚ id_test-auc                                         0.71445 â”‚
â”‚ id_test-average_precision                           0.61653 â”‚
â”‚ id_test-binary_error                                 0.3301 â”‚
â”‚ id_test_0-auc                                       0.67655 â”‚
â”‚ id_test_0-average_precision                         0.54269 â”‚
â”‚ id_test_0-binary_error                              0.33912 â”‚
â”‚ id_test_1-auc                                       0.71436 â”‚
â”‚ id_test_1-average_precision                          0.5993 â”‚
â”‚ id_test_1-binary_error                              0.32583 â”‚
â”‚ id_test_4-auc                                       0.69333 â”‚
â”‚ id_test_4-average_precision                         0.70737 â”‚
â”‚ id_test_4-binary_error                              0.35829 â”‚
â”‚ new_ood_test-auc                                    0.69688 â”‚
â”‚ new_ood_test-average_precision                      0.75003 â”‚
â”‚ new_ood_test-binary_error                           0.37488 â”‚
â”‚ new_ood_test_1-auc                                  0.69688 â”‚
â”‚ new_ood_test_1-average_precision                    0.75003 â”‚
â”‚ new_ood_test_1-binary_error                         0.37488 â”‚
â”‚ new_train-auc                                       0.71334 â”‚
â”‚ new_train-average_precision                         0.61331 â”‚
â”‚ new_train-binary_error                              0.33128 â”‚
â”‚ ood_test-auc                                        0.69635 â”‚
â”‚ ood_test-average_precision                           0.7493 â”‚
â”‚ ood_test-binary_error                               0.37482 â”‚
â”‚ ood_test_2-auc                                      0.68586 â”‚
â”‚ ood_test_2-average_precision                        0.68532 â”‚
â”‚ ood_test_2-binary_error                             0.39694 â”‚
â”‚ ood_test_3-auc                                      0.67274 â”‚
â”‚ ood_test_3-average_precision                        0.78891 â”‚
â”‚ ood_test_3-binary_error                             0.34962 â”‚
â”‚ ood_validation-auc                                  0.69625 â”‚
â”‚ ood_validation-average_precision                     0.7489 â”‚
â”‚ ood_validation-binary_error                         0.37425 â”‚
â”‚ oracle-auc                                          0.69561 â”‚
â”‚ oracle-average_precision                            0.74828 â”‚
â”‚ oracle-binary_error                                 0.37475 â”‚
â”‚ train-auc                                           0.71334 â”‚
â”‚ train-average_precision                             0.61331 â”‚
â”‚ train-binary_error                                  0.33128 â”‚
â”‚ validation-auc                                      0.71065 â”‚
â”‚ validation-average_precision                        0.61234 â”‚
â”‚ validation-binary_error                              0.3316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 48 TERMINATED | 2 RUNNING
Current time: 2025-04-25 16:53:50. Total running time: 1hr 2min 37s
Logical resource usage: 2.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_5834e8d6   RUNNING                 0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101                                                                                                                      â”‚
â”‚ LightGBMTrainer_3f502e7d   RUNNING                 0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997                                                                                                                       â”‚
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
43 more TERMINATED
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062835 seconds.
[36m(RayTrainWorker pid=2800896)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2800896)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] Total Bins 373
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2800896)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_5834e8d6 completed after 1 iterations at 2025-04-25 16:54:04. Total running time: 1hr 2min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_5834e8d6 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          248.311 â”‚
â”‚ time_total_s                              248.311 â”‚
â”‚ training_iteration                              1 â”‚
â”‚ id_test-auc                                0.6938 â”‚
â”‚ id_test-average_precision                 0.58285 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.67137 â”‚
â”‚ id_test_0-average_precision               0.51895 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.69773 â”‚
â”‚ id_test_1-average_precision               0.56859 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68561 â”‚
â”‚ id_test_4-average_precision               0.69123 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.67115 â”‚
â”‚ new_ood_test-average_precision            0.72425 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.67115 â”‚
â”‚ new_ood_test_1-average_precision          0.72425 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.68771 â”‚
â”‚ new_train-average_precision               0.57503 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.67042 â”‚
â”‚ ood_test-average_precision                0.72353 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67052 â”‚
â”‚ ood_test_2-average_precision              0.66409 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66194 â”‚
â”‚ ood_test_3-average_precision              0.77627 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.67082 â”‚
â”‚ ood_validation-average_precision          0.72291 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                0.66939 â”‚
â”‚ oracle-average_precision                  0.72255 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.68771 â”‚
â”‚ train-average_precision                   0.57503 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.68646 â”‚
â”‚ validation-average_precision               0.5781 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] Number of positive: 86827, number of negative: 129584
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 2x across cluster][0m
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043114 seconds.
[36m(RayTrainWorker pid=2802322)[0m You can set `force_row_wise=true` to remove the overhead.
[36m(RayTrainWorker pid=2802322)[0m And if memory is not enough, you can set `force_col_wise=true`.
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] Total Bins 371
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] Number of data points in the train set: 216411, number of used features: 101
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.[32m [repeated 12x across cluster][0m
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401213 -> initscore=-0.400412
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Info] Start training from score -0.400412

Trial LightGBMTrainer_3f502e7d completed after 4 iterations at 2025-04-25 16:54:12. Total running time: 1hr 2min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial LightGBMTrainer_3f502e7d result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                               â”‚
â”‚ time_this_iter_s                          0.44131 â”‚
â”‚ time_total_s                              223.718 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ id_test-auc                                0.7045 â”‚
â”‚ id_test-average_precision                 0.59616 â”‚
â”‚ id_test-binary_error                      0.40197 â”‚
â”‚ id_test_0-auc                             0.65995 â”‚
â”‚ id_test_0-average_precision               0.51838 â”‚
â”‚ id_test_0-binary_error                    0.36837 â”‚
â”‚ id_test_1-auc                             0.70464 â”‚
â”‚ id_test_1-average_precision               0.57631 â”‚
â”‚ id_test_1-binary_error                    0.38716 â”‚
â”‚ id_test_4-auc                             0.68588 â”‚
â”‚ id_test_4-average_precision               0.69308 â”‚
â”‚ id_test_4-binary_error                    0.52249 â”‚
â”‚ new_ood_test-auc                          0.68908 â”‚
â”‚ new_ood_test-average_precision            0.73867 â”‚
â”‚ new_ood_test-binary_error                 0.58445 â”‚
â”‚ new_ood_test_1-auc                        0.68908 â”‚
â”‚ new_ood_test_1-average_precision          0.73867 â”‚
â”‚ new_ood_test_1-binary_error               0.58445 â”‚
â”‚ new_train-auc                             0.70094 â”‚
â”‚ new_train-average_precision               0.58939 â”‚
â”‚ new_train-binary_error                    0.40121 â”‚
â”‚ ood_test-auc                              0.68838 â”‚
â”‚ ood_test-average_precision                0.73777 â”‚
â”‚ ood_test-binary_error                     0.58429 â”‚
â”‚ ood_test_2-auc                            0.67677 â”‚
â”‚ ood_test_2-average_precision              0.67006 â”‚
â”‚ ood_test_2-binary_error                   0.51538 â”‚
â”‚ ood_test_3-auc                            0.66648 â”‚
â”‚ ood_test_3-average_precision              0.77763 â”‚
â”‚ ood_test_3-binary_error                    0.6628 â”‚
â”‚ ood_validation-auc                        0.68821 â”‚
â”‚ ood_validation-average_precision          0.73686 â”‚
â”‚ ood_validation-binary_error               0.58351 â”‚
â”‚ oracle-auc                                 0.6874 â”‚
â”‚ oracle-average_precision                  0.73653 â”‚
â”‚ oracle-binary_error                       0.58407 â”‚
â”‚ train-auc                                 0.70094 â”‚
â”‚ train-average_precision                   0.58939 â”‚
â”‚ train-binary_error                        0.40121 â”‚
â”‚ validation-auc                            0.70026 â”‚
â”‚ validation-average_precision              0.59153 â”‚
â”‚ validation-binary_error                    0.4022 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 50 TERMINATED
Current time: 2025-04-25 16:54:13. Total running time: 1hr 2min 59s
Logical resource usage: 1.0/36 CPUs, 0/0 GPUs
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name                 status         params/learning_rate     ...min_child_samples     .../min_child_weight     params/subsample     params/max_depth     .../colsample_bytree     ...colsample_bylevel     params/reg_alpha     params/reg_lambda     iter     total time (s)     train-binary_error     train-auc     ...average_precision     ...st_2-binary_error â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LightGBMTrainer_ac0b048c   TERMINATED              0.000164587                        8             31.1567                  0.795395                    6                 0.72302                  0.925513         11.443                 0.0032299          1            311.287               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_9e09426a   TERMINATED              0.000121064                        4             88.6536                  0.995723                   19                 0.963194                 0.91828           3.15908e-05           1.9731e-05         1            316.9                 0.401213      0.691923                 0.578257                 0.515382 â”‚
â”‚ LightGBMTrainer_6fa3bf75   TERMINATED              0.285296                           2              1.5737e-05              0.799768                    6                 0.890752                 0.995475          0.000468379           2.79121           10            327.292               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_cf475c9c   TERMINATED              0.000988995                       64              0.00324906              0.652433                    5                 0.841159                 0.903575          5.8573e-05            0.000552809        1            252.317               0.401213      0.685804                 0.573718                 0.515382 â”‚
â”‚ LightGBMTrainer_21eedc41   TERMINATED              0.0415284                         32           5054.73                    0.570107                   17                 0.657187                 0.815193         22.4911                3.52364            1            275.778               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_46451abb   TERMINATED              0.000408737                        8              0.0240841               0.902369                   16                 0.846572                 0.998595          7.19007e-06           2.22449e-06        4            297.572               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_ede88318   TERMINATED              0.000722629                       64              0.0899496               0.997766                    7                 0.541613                 0.667537          3.73583e-05           1.60174e-05        4            280.172               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_dc87a4e0   TERMINATED              0.173267                           1              0.00108024              0.618161                    7                 0.771388                 0.760773          6.15976               3.35489           10            324.686               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_ed939181   TERMINATED              0.659853                           1              0.000106202             0.696157                   12                 0.967027                 0.646288          0.558068              8.42149e-07        1            277.228               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_5d16f50a   TERMINATED              0.620081                          16              2.24559e-06             0.611725                    6                 0.984963                 0.935438          3.40549e-08           2.1901e-06         4            277.058               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_e955b5e8   TERMINATED              0.0126689                          1              6.10817e-06             0.643136                   17                 0.553555                 0.768668          4.03624e-07           5.15125e-07        4            275.645               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_bd9dda0a   TERMINATED              0.000556346                        1              5.41365e-06             0.74617                    19                 0.729611                 0.596556          5.19352e-06           1.21963e-08       10            324.06                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b5b99116   TERMINATED              0.0355334                          8          41339.5                     0.627821                    7                 0.983905                 0.811766          0.0912562             0.0032698          1            299.056               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_02971b8d   TERMINATED              0.0466036                          2          41181                       0.517158                    7                 0.551055                 0.722537          0.000152476           0.527264           4            276.28                0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_b8ef9918   TERMINATED              0.00106088                        16              0.0172776               0.741189                   27                 0.705943                 0.53918           3.50454e-06           0.000103861        4            270.764               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_802a76bf   TERMINATED              0.000306402                        8              0.0131405               0.703283                   14                 0.71708                  0.803075          0.00116657            1.41736e-07       10            286.93                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_0102a201   TERMINATED              0.038339                          64            197.21                    0.993056                   21                 0.687447                 0.703184          8.53002e-06           3.04949e-08        1            285.544               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_e41b2b42   TERMINATED              2.58761e-05                       64              4.22199e-08             0.953705                   24                 0.621564                 0.604319          1.17838e-06           0.00859442         4            336.221               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_a8d48a37   TERMINATED              0.000406627                       16              0.223195                0.621653                   25                 0.691992                 0.637239          0.0096948             2.09777e-08        4            288.938               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_7583531c   TERMINATED              5.2365e-05                        64              4.97276e-08             0.882547                   13                 0.819417                 0.733572          4.79278e-07           1.41961           10            304.235               0.331282      0.713343                 0.613306                 0.396947 â”‚
â”‚ LightGBMTrainer_c5d78e0d   TERMINATED              0.20716                            2              0.000257846             0.809168                   26                 0.905728                 0.969746          0.00479202           95.1868             1            293.141               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_f0e023f4   TERMINATED              0.153735                           2              1.26818                 0.526094                    4                 0.792455                 0.871404          0.346621              0.0679295          4            288.558               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_c8a0ba1f   TERMINATED              0.00544341                         1              0.000170553             0.829095                   22                 0.893839                 0.856849          4.73203              85.3003             4            276.376               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_97eb69d5   TERMINATED              0.265352                           2              2.55049e-07             0.571816                    8                 0.777786                 0.504539          0.0248841            14.5551            10            304.579               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_06e29a47   TERMINATED              0.109943                          32              0.00141702              0.689328                   11                 0.902631                 0.997656         91.8973                0.112889           1            285.416               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_b2a3eb8c   TERMINATED              0.994912                           4              2.3533                  0.887527                   30                 0.610727                 0.548451          0.00115674           18.0094             4            316.757               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_12f7c3e4   TERMINATED              0.010953                           2              3.7798e-05              0.775533                    2                 0.762971                 0.781389          1.11727e-08           0.0512731          4            284.798               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_a3a6ff7c   TERMINATED              0.00287042                         1              4.73904e-07             0.848383                   23                 0.867583                 0.852323          0.000322737          10.806             10            315.374               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_1fb0f074   TERMINATED              0.451279                           2              2.22671e-05             0.781356                   28                 0.935799                 0.960624          1.96653               0.230377           1            299.892               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_49861b35   TERMINATED              0.0916704                          4              0.00128307              0.570614                   20                 0.748428                 0.686965         36.9928                1.63558            4            287.416               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_3a747344   TERMINATED              0.00268677                         1              1.52971e-08             0.937946                   15                 0.807232                 0.88375           0.0535184             0.0152581          4            303.745               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_100711e1   TERMINATED              0.0168798                         32              8.87413                 0.726019                   -1                 0.944413                 0.934131          0.0023856             0.000265596       10            295.69                0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_76202fc9   TERMINATED              0.944078                           4              0.368615                0.85096                     9                 0.861472                 0.829058          0.000187504          88.4449             1            292.291               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_fb95afc8   TERMINATED              0.351576                           2            238.421                   0.672705                   18                 0.651472                 0.904             0.356399              0.500213           4            302.268               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_3b82f6fc   TERMINATED              0.0817725                          1              0.0027319               0.598393                   10                 0.829519                 0.764215          8.25766               0.00179269         4            308.018               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_bdf133bc   TERMINATED              0.0189679                         32              1.269e-06               0.545037                    6                 0.874399                 0.999156          0.0211605             4.403             10            298.564               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_b170508b   TERMINATED              0.00612233                         8              0.00067453              0.662325                    1                 0.506933                 0.968069          7.38577e-08           4.44201e-05        1            299.078               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_bf4adf72   TERMINATED              1.16285e-05                        1              3.52829e-05             0.717971                    3                 0.930236                 0.588331          2.09367e-05           0.0209557          4            299.49                0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_b1f50172   TERMINATED              0.00157208                        16              0.00891782              0.799196                    6                 0.742876                 0.657191          1.6837               38.4219             4            309.197               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_fa84763d   TERMINATED              0.629245                           2             29.699                   0.764339                   16                 0.794599                 0.742015          6.94106e-05           0.000464206       10            323.099               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_002727bc   TERMINATED              0.000172774                        1              2.06063e-07             0.931723                   29                 0.836194                 0.501633         43.6926                4.64604            1            292.225               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_910a868b   TERMINATED              0.0611678                          4              4.05784e-06             0.643212                    7                 0.997936                 0.837346          0.152169              0.0043381          4            300.293               0.401213      0.700944                 0.589393                 0.515382 â”‚
â”‚ LightGBMTrainer_aad9df94   TERMINATED              0.0250033                          8              2.54441e-05             0.594122                   12                 0.962538                 0.794869          0.000389491           0.913272           4            309.437               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_1dfeddf8   TERMINATED              0.160303                          32           2046.88                    0.827037                   19                 0.662231                 0.909383          0.00693226            1.31376e-05       10            307.688               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_11a478fa   TERMINATED              0.00553359                         1              0.08099                 0.978608                    5                 0.591924                 0.619234          2.3346e-05            0.263059           1            306.643               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_333f353f   TERMINATED              0.312478                          16              0.00557031              0.507655                   17                 0.761905                 0.710393          1.23057              31.2606             4            297.589               0.401213      0.700932                 0.589387                 0.515382 â”‚
â”‚ LightGBMTrainer_26147f95   TERMINATED              0.00940788                        64              0.0422841               0.682389                   14                 0.856989                 0.683126          1.15817e-07           4.0866             4            292.129               0.401213      0.695392                 0.587872                 0.515382 â”‚
â”‚ LightGBMTrainer_5430dae5   TERMINATED              0.0320186                          2              9.51042e-06             0.752059                   27                 0.920855                 0.561342          1.95265e-06           0.0306473         10            278.613               0.331282      0.713343                 0.613306                 0.396943 â”‚
â”‚ LightGBMTrainer_5834e8d6   TERMINATED              0.942117                           8              1.80199e-06             0.543482                    7                 0.72594                  0.951942          0.00284424            0.0011101          1            248.311               0.401213      0.687708                 0.575028                 0.515382 â”‚
â”‚ LightGBMTrainer_3f502e7d   TERMINATED              0.0645171                          1              0.000358938             0.718718                   25                 0.968304                 0.757567          8.33987e-05           0.155997           4            223.718               0.401213      0.700944                 0.589393                 0.515382 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff15009c956046d9877d0d6e9f01000000 Worker ID: 54af090889426b8f3c87314e905e949e786956ae1891e315c50b6ac7 Node ID: 6a2810168eebbb29d9812342170c9ee7ed185941125d7e376a513ab4 Worker IP address: 10.164.8.128 Worker port: 33457 Worker PID: 2802435 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM.
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Unknown parameter: colsample_bylevel
[36m(RayTrainWorker pid=2802322)[0m [LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=19) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=524288) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.
    train-auc  ...  domain_split_id_values
0    0.687708  ...         ['0', '1', '4']
1    0.691923  ...         ['0', '1', '4']
2    0.713343  ...         ['0', '1', '4']
3    0.685804  ...         ['0', '1', '4']
4    0.687708  ...         ['0', '1', '4']
5    0.700932  ...         ['0', '1', '4']
6    0.695392  ...         ['0', '1', '4']
7    0.713343  ...         ['0', '1', '4']
8    0.687708  ...         ['0', '1', '4']
9    0.695392  ...         ['0', '1', '4']
10   0.700944  ...         ['0', '1', '4']
11   0.713343  ...         ['0', '1', '4']
12   0.687708  ...         ['0', '1', '4']
13   0.695392  ...         ['0', '1', '4']
14   0.700932  ...         ['0', '1', '4']
15   0.713343  ...         ['0', '1', '4']
16   0.687708  ...         ['0', '1', '4']
17   0.700944  ...         ['0', '1', '4']
18   0.695392  ...         ['0', '1', '4']
19   0.713343  ...         ['0', '1', '4']
20   0.687708  ...         ['0', '1', '4']
21   0.695392  ...         ['0', '1', '4']
22   0.700944  ...         ['0', '1', '4']
23   0.713343  ...         ['0', '1', '4']
24   0.687708  ...         ['0', '1', '4']
25   0.695392  ...         ['0', '1', '4']
26   0.700932  ...         ['0', '1', '4']
27   0.713343  ...         ['0', '1', '4']
28   0.687708  ...         ['0', '1', '4']
29   0.700944  ...         ['0', '1', '4']
30   0.695392  ...         ['0', '1', '4']
31   0.713343  ...         ['0', '1', '4']
32   0.687708  ...         ['0', '1', '4']
33   0.700944  ...         ['0', '1', '4']
34   0.695392  ...         ['0', '1', '4']
35   0.713343  ...         ['0', '1', '4']
36   0.687708  ...         ['0', '1', '4']
37   0.700944  ...         ['0', '1', '4']
38   0.695392  ...         ['0', '1', '4']
39   0.713343  ...         ['0', '1', '4']
40   0.687708  ...         ['0', '1', '4']
41   0.700944  ...         ['0', '1', '4']
42   0.695392  ...         ['0', '1', '4']
43   0.713343  ...         ['0', '1', '4']
44   0.687708  ...         ['0', '1', '4']
45   0.700932  ...         ['0', '1', '4']
46   0.695392  ...         ['0', '1', '4']
47   0.713343  ...         ['0', '1', '4']
48   0.687708  ...         ['0', '1', '4']
49   0.700944  ...         ['0', '1', '4']

[50 rows x 70 columns]
